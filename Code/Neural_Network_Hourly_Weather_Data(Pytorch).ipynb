{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for CLA Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import errno\n",
    "import os\n",
    "import sys\n",
    "import Constants\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "sample_bias = 0     # adjust the difference in the number of the two types of samples (no algae vs algae)\n",
    "test_size = 0.2\n",
    "batch_size = 96    # batch size for the DataLoaders. previously was 100\n",
    "\n",
    "# NN model\n",
    "num_features = 13\n",
    "input_size = num_features     # size of input layer\n",
    "multiplier = 100         # multiplied by num_features to determine the size of each hidden layer. previously was 100\n",
    "hidden_size = multiplier * input_size\n",
    "output_size = 1\n",
    "learning_rate = 0.001         # learning rate of optimizer. previously was 0.01\n",
    "num_epochs = 100                # number of epochs\n",
    "\n",
    "# training the model\n",
    "use_previous_best_model = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)  # prints a full matrix rather than an abbreviated matrix\n",
    "\n",
    "# define data and destination paths\n",
    "data_path_hourly = \"/Users/Alliot/Documents/CLA-Project/Data/hourly-data-sets/\"\n",
    "# data_path = \"/Users/Alliot/Documents/CLA-Project/Data/data-sets/\"\n",
    "# data_set_hourly = \"hourly_data_2017\"\n",
    "# data_set = \"all_data_summer\"\n",
    "# data_path = \"../Data/data/\"\n",
    "X_2015 = np.load(data_path_hourly + 'hourly_X_2015.npy')\n",
    "X_2016 = np.load(data_path_hourly + 'hourly_X_2016.npy')\n",
    "X_2017 = np.load(data_path_hourly + 'hourly_X_2017.npy')\n",
    "X_2018 = np.load(data_path_hourly + 'hourly_X_2018.npy')  # WHAT IS THE FIRST COLUMN??? WHERE IS THE ''??????\n",
    "\n",
    "y_2015 = np.load(data_path_hourly + 'hourly_y_2015.npy')\n",
    "y_2016 = np.load(data_path_hourly + 'hourly_y_2016.npy')\n",
    "y_2017 = np.load(data_path_hourly + 'hourly_y_2017.npy')\n",
    "y_2018 = np.load(data_path_hourly + 'hourly_y_2018.npy')\n",
    "\n",
    "X = np.vstack((X_2015, X_2016, X_2017, X_2018))\n",
    "y = np.hstack((y_2015, y_2016, y_2017, y_2018))\n",
    "# manipulate data set. labels are converted to 0, +1 for binary classification; samples are removed uniformly \n",
    "# from the data set so that the disproportionately large number of negative samples (no algae) does \n",
    "# not bias the model.\n",
    "\n",
    "num_alg = 0  # count the number of algae instances\n",
    "num_no_alg = 0  # count the number of no algae instances\n",
    "\n",
    "# Convert labels to binary: -1 for no algae and 1 for algae\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == 0:\n",
    "        num_no_alg += 1\n",
    "    if y[i] == 1 or y[i] == 2:\n",
    "        y[i] = 1\n",
    "        num_alg += 1\n",
    "\n",
    "# oversample the data set by randomly adding occurences of algae until the difference between the number of algae\n",
    "# samples and no algae samples equals sample_bias (defined below)\n",
    "# idx = 0\n",
    "# sample_bias = 0\n",
    "# length_y = len(y)\n",
    "# while num_alg != (num_no_alg + sample_bias):\n",
    "#     # circle through the data sets until the difference of num_no_alg and num_alg equals\n",
    "#     # the value specified by sample_bias\n",
    "#     if idx == (length_y - 1):\n",
    "#         idx = 0\n",
    "\n",
    "#     if y[idx] == 1:\n",
    "#         if np.random.rand() >= 0.5:  # add this sample with some probability\n",
    "#             y = np.append(y, y[idx])\n",
    "#             X = np.append(X, np.reshape(X[idx, :], newshape=(1, num_features)), axis=0)\n",
    "#             num_alg += 1\n",
    "#         else:\n",
    "#             idx += 1\n",
    "#     else:\n",
    "#         idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alliot/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype <U100 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/Alliot/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:590: DataConversionWarning: Data with input dtype <U100 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# standardize data: remove the mean and variance in each sample\n",
    "num_splits = 2   # do not change\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=num_splits, test_size=test_size)\n",
    "\n",
    "idx, _ = sss.split(X, y)\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "X_train = preprocessing.scale(X_train, axis=1, with_mean=True, with_std=True)\n",
    "X_test = preprocessing.scale(X_test, axis=1, with_mean=True, with_std=True)\n",
    "\n",
    "# convert numpy arrays to pytorch tensors\n",
    "train_set_size = X_train.shape\n",
    "test_set_size = X_test.shape\n",
    "X_train, X_test = torch.from_numpy(X_train), torch.from_numpy(X_test)\n",
    "y_train, y_test = torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "\n",
    "# convert pytorch tensors to pytorch TensorDataset\n",
    "train_set = utils.TensorDataset(X_train, y_train)\n",
    "test_set = utils.TensorDataset(X_test, y_test)\n",
    "\n",
    "# create DataLoaders\n",
    "train_loader = utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = utils.DataLoader(test_set, batch_size=test_set_size[0], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLANet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CLANet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tanh2 = nn.Tanh()\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.tanh4 = nn.Tanh()\n",
    "        self.fc5 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc6 = nn.Linear(hidden_size, output_size)     # previously, this was output_size\n",
    "#         self.tanh6 = nn.Tanh()                             # previously, this was the line which was commented out\n",
    "#         self.fc7 = nn.Linear(hidden_size, output_size)\n",
    "#         self.relu7 = nn.ReLU()\n",
    "#         self.fc8 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu8 = nn.ReLU()\n",
    "#         self.fc9 = nn.Linear(hidden_size, output_size)\n",
    "#         self.relu9 = nn.ReLU()\n",
    "#         self.fc10 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu10 = nn.ReLU()\n",
    "#         self.fc11 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu11 = nn.ReLU()\n",
    "#         self.fc12 = nn.Linear(hidden_size, output_size)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.tanh2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.tanh4(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.fc6(out)\n",
    "#         out = self.tanh6(out)\n",
    "#         out = self.fc7(out)\n",
    "#         out = self.relu7(out)\n",
    "#         out = self.fc8(out)\n",
    "#         out = self.relu8(out)\n",
    "#         out = self.fc9(out)\n",
    "#         out = self.relu9(out)\n",
    "#         out = self.fc10(out)\n",
    "#         out = self.relu10(out)\n",
    "#         out = self.fc11(out)\n",
    "#         out = self.relu11(out)\n",
    "#         out = self.fc12(out)\n",
    "        out = self.sig1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLANet(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, nesterov=True, momentum=1, dampening=0)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-8)\n",
    "model.double();     # cast model parameters to double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "  Iteration: 1/35, Loss: 0.691201, Error: 0.3229\n",
      "  Iteration: 2/35, Loss: 0.641502, Error: 0.2708\n",
      "  Iteration: 3/35, Loss: 0.842457, Error: 0.7812\n",
      "  Iteration: 4/35, Loss: 0.668202, Error: 0.3229\n",
      "  Iteration: 5/35, Loss: 0.643493, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.661187, Error: 0.3125\n",
      "  Iteration: 7/35, Loss: 0.554163, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.518997, Error: 0.2083\n",
      "  Iteration: 9/35, Loss: 0.612928, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.609014, Error: 0.2917\n",
      "  Iteration: 11/35, Loss: 0.560078, Error: 0.1771\n",
      "  Iteration: 12/35, Loss: 0.643872, Error: 0.3229\n",
      "  Iteration: 13/35, Loss: 0.484322, Error: 0.1875\n",
      "  Iteration: 14/35, Loss: 0.595428, Error: 0.2604\n",
      "  Iteration: 15/35, Loss: 0.575631, Error: 0.2604\n",
      "  Iteration: 16/35, Loss: 0.562487, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.647038, Error: 0.3438\n",
      "  Iteration: 18/35, Loss: 0.561655, Error: 0.1979\n",
      "  Iteration: 19/35, Loss: 0.591695, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.491457, Error: 0.1875\n",
      "  Iteration: 21/35, Loss: 0.618182, Error: 0.2708\n",
      "  Iteration: 22/35, Loss: 0.610689, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.604586, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.534445, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.586932, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.579796, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.555136, Error: 0.2188\n",
      "  Iteration: 28/35, Loss: 0.664768, Error: 0.3438\n",
      "  Iteration: 29/35, Loss: 0.594117, Error: 0.2812\n",
      "  Iteration: 30/35, Loss: 0.583986, Error: 0.2708\n",
      "  Iteration: 31/35, Loss: 0.538308, Error: 0.2083\n",
      "  Iteration: 32/35, Loss: 0.51168, Error: 0.2188\n",
      "  Iteration: 33/35, Loss: 0.584385, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.734951, Error: 0.3646\n",
      "  Iteration: 35/35, Loss: 0.615176, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2806\n",
      "found a better model!\n",
      "Epoch: 2/100\n",
      "  Iteration: 1/35, Loss: 0.538056, Error: 0.2083\n",
      "  Iteration: 2/35, Loss: 0.674346, Error: 0.3958\n",
      "  Iteration: 3/35, Loss: 0.635567, Error: 0.3229\n",
      "  Iteration: 4/35, Loss: 0.584373, Error: 0.1875\n",
      "  Iteration: 5/35, Loss: 0.626281, Error: 0.3021\n",
      "  Iteration: 6/35, Loss: 0.596264, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.517528, Error: 0.1771\n",
      "  Iteration: 8/35, Loss: 0.62696, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.521584, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.650909, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.681046, Error: 0.3333\n",
      "  Iteration: 12/35, Loss: 0.523931, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.523219, Error: 0.2083\n",
      "  Iteration: 14/35, Loss: 0.583237, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.544308, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.575496, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.575293, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.512186, Error: 0.2083\n",
      "  Iteration: 19/35, Loss: 0.552773, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.628009, Error: 0.3125\n",
      "  Iteration: 21/35, Loss: 0.697704, Error: 0.3542\n",
      "  Iteration: 22/35, Loss: 0.518662, Error: 0.1875\n",
      "  Iteration: 23/35, Loss: 0.629285, Error: 0.3125\n",
      "  Iteration: 24/35, Loss: 0.54187, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.554953, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.640622, Error: 0.3438\n",
      "  Iteration: 27/35, Loss: 0.559092, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.62279, Error: 0.3333\n",
      "  Iteration: 29/35, Loss: 0.496682, Error: 0.1979\n",
      "  Iteration: 30/35, Loss: 0.617484, Error: 0.3021\n",
      "  Iteration: 31/35, Loss: 0.635043, Error: 0.3229\n",
      "  Iteration: 32/35, Loss: 0.501189, Error: 0.1875\n",
      "  Iteration: 33/35, Loss: 0.560909, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.536191, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.534308, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2637\n",
      "found a better model!\n",
      "Epoch: 3/100\n",
      "  Iteration: 1/35, Loss: 0.536956, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.572968, Error: 0.2604\n",
      "  Iteration: 3/35, Loss: 0.668242, Error: 0.3333\n",
      "  Iteration: 4/35, Loss: 0.591846, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.576027, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.566959, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.580282, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.571375, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.519195, Error: 0.1979\n",
      "  Iteration: 10/35, Loss: 0.545351, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.577982, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.610473, Error: 0.2917\n",
      "  Iteration: 13/35, Loss: 0.495611, Error: 0.1979\n",
      "  Iteration: 14/35, Loss: 0.518771, Error: 0.2188\n",
      "  Iteration: 15/35, Loss: 0.515672, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.579752, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.505208, Error: 0.2083\n",
      "  Iteration: 18/35, Loss: 0.476761, Error: 0.1771\n",
      "  Iteration: 19/35, Loss: 0.587312, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.595213, Error: 0.2812\n",
      "  Iteration: 21/35, Loss: 0.580414, Error: 0.2708\n",
      "  Iteration: 22/35, Loss: 0.521128, Error: 0.1979\n",
      "  Iteration: 23/35, Loss: 0.63078, Error: 0.3438\n",
      "  Iteration: 24/35, Loss: 0.58236, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.64262, Error: 0.3438\n",
      "  Iteration: 26/35, Loss: 0.561368, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.647562, Error: 0.3542\n",
      "  Iteration: 28/35, Loss: 0.549, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.61695, Error: 0.3125\n",
      "  Iteration: 30/35, Loss: 0.623736, Error: 0.3125\n",
      "  Iteration: 31/35, Loss: 0.570285, Error: 0.2708\n",
      "  Iteration: 32/35, Loss: 0.577048, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.662092, Error: 0.3438\n",
      "  Iteration: 34/35, Loss: 0.521714, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.41862, Error: 0.1000\n",
      "Average Error for this Epoch: 0.2576\n",
      "found a better model!\n",
      "Epoch: 4/100\n",
      "  Iteration: 1/35, Loss: 0.546037, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.55427, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.596635, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.608639, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.62431, Error: 0.3021\n",
      "  Iteration: 6/35, Loss: 0.665083, Error: 0.3438\n",
      "  Iteration: 7/35, Loss: 0.580919, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.54176, Error: 0.1875\n",
      "  Iteration: 9/35, Loss: 0.600721, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.587779, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.566498, Error: 0.2083\n",
      "  Iteration: 12/35, Loss: 0.612678, Error: 0.3021\n",
      "  Iteration: 13/35, Loss: 0.615168, Error: 0.3021\n",
      "  Iteration: 14/35, Loss: 0.553015, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.523736, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.564899, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.430705, Error: 0.1667\n",
      "  Iteration: 18/35, Loss: 0.640952, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.583821, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.496233, Error: 0.1979\n",
      "  Iteration: 21/35, Loss: 0.53329, Error: 0.2188\n",
      "  Iteration: 22/35, Loss: 0.524955, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.554462, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.703081, Error: 0.3958\n",
      "  Iteration: 25/35, Loss: 0.602268, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.591973, Error: 0.2812\n",
      "  Iteration: 27/35, Loss: 0.601874, Error: 0.2917\n",
      "  Iteration: 28/35, Loss: 0.53447, Error: 0.2083\n",
      "  Iteration: 29/35, Loss: 0.648888, Error: 0.3542\n",
      "  Iteration: 30/35, Loss: 0.516907, Error: 0.2083\n",
      "  Iteration: 31/35, Loss: 0.521055, Error: 0.2083\n",
      "  Iteration: 32/35, Loss: 0.694532, Error: 0.3646\n",
      "  Iteration: 33/35, Loss: 0.53593, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.58635, Error: 0.2917\n",
      "  Iteration: 35/35, Loss: 0.524994, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2604\n",
      "Epoch: 5/100\n",
      "  Iteration: 1/35, Loss: 0.742768, Error: 0.4167\n",
      "  Iteration: 2/35, Loss: 0.604976, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.602711, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.560729, Error: 0.2396\n",
      "  Iteration: 5/35, Loss: 0.627245, Error: 0.3333\n",
      "  Iteration: 6/35, Loss: 0.538299, Error: 0.2292\n",
      "  Iteration: 7/35, Loss: 0.56121, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.568474, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.50841, Error: 0.1979\n",
      "  Iteration: 10/35, Loss: 0.574116, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.630912, Error: 0.3021\n",
      "  Iteration: 12/35, Loss: 0.543407, Error: 0.2396\n",
      "  Iteration: 13/35, Loss: 0.558367, Error: 0.2500\n",
      "  Iteration: 14/35, Loss: 0.578072, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.49547, Error: 0.1667\n",
      "  Iteration: 16/35, Loss: 0.513041, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.55351, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.591545, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.530052, Error: 0.2292\n",
      "  Iteration: 20/35, Loss: 0.578954, Error: 0.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 21/35, Loss: 0.445633, Error: 0.1667\n",
      "  Iteration: 22/35, Loss: 0.603219, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.661158, Error: 0.3333\n",
      "  Iteration: 24/35, Loss: 0.536153, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.489218, Error: 0.1979\n",
      "  Iteration: 26/35, Loss: 0.582709, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.563678, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.661656, Error: 0.3438\n",
      "  Iteration: 29/35, Loss: 0.544322, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.543223, Error: 0.2396\n",
      "  Iteration: 31/35, Loss: 0.566812, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.47861, Error: 0.1771\n",
      "  Iteration: 33/35, Loss: 0.622612, Error: 0.3229\n",
      "  Iteration: 34/35, Loss: 0.597996, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.668794, Error: 0.4000\n",
      "Average Error for this Epoch: 0.2632\n",
      "Epoch: 6/100\n",
      "  Iteration: 1/35, Loss: 0.477985, Error: 0.1667\n",
      "  Iteration: 2/35, Loss: 0.514566, Error: 0.2188\n",
      "  Iteration: 3/35, Loss: 0.601133, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.577875, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.583513, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.587034, Error: 0.2812\n",
      "  Iteration: 7/35, Loss: 0.566425, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.611563, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.527058, Error: 0.2083\n",
      "  Iteration: 10/35, Loss: 0.564413, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.584563, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.68204, Error: 0.3854\n",
      "  Iteration: 13/35, Loss: 0.565008, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.599369, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.556382, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.585777, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.56648, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.539255, Error: 0.2188\n",
      "  Iteration: 19/35, Loss: 0.563996, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.603502, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.597951, Error: 0.3021\n",
      "  Iteration: 22/35, Loss: 0.501537, Error: 0.1875\n",
      "  Iteration: 23/35, Loss: 0.53796, Error: 0.2292\n",
      "  Iteration: 24/35, Loss: 0.490438, Error: 0.1979\n",
      "  Iteration: 25/35, Loss: 0.563775, Error: 0.2604\n",
      "  Iteration: 26/35, Loss: 0.525346, Error: 0.2083\n",
      "  Iteration: 27/35, Loss: 0.471685, Error: 0.1875\n",
      "  Iteration: 28/35, Loss: 0.591387, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.599794, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.579514, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.533706, Error: 0.2188\n",
      "  Iteration: 32/35, Loss: 0.57523, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.639587, Error: 0.3542\n",
      "  Iteration: 34/35, Loss: 0.577517, Error: 0.2812\n",
      "  Iteration: 35/35, Loss: 0.506083, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2590\n",
      "Epoch: 7/100\n",
      "  Iteration: 1/35, Loss: 0.553384, Error: 0.2604\n",
      "  Iteration: 2/35, Loss: 0.54761, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.567376, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.668236, Error: 0.3229\n",
      "  Iteration: 5/35, Loss: 0.439797, Error: 0.1458\n",
      "  Iteration: 6/35, Loss: 0.578498, Error: 0.2812\n",
      "  Iteration: 7/35, Loss: 0.492561, Error: 0.1979\n",
      "  Iteration: 8/35, Loss: 0.609739, Error: 0.3021\n",
      "  Iteration: 9/35, Loss: 0.585665, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.630966, Error: 0.3229\n",
      "  Iteration: 11/35, Loss: 0.60328, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.543147, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.63313, Error: 0.3333\n",
      "  Iteration: 14/35, Loss: 0.588528, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.564054, Error: 0.2604\n",
      "  Iteration: 16/35, Loss: 0.577867, Error: 0.3021\n",
      "  Iteration: 17/35, Loss: 0.562974, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.569289, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.541965, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.587041, Error: 0.2708\n",
      "  Iteration: 21/35, Loss: 0.587416, Error: 0.3125\n",
      "  Iteration: 22/35, Loss: 0.523078, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.605347, Error: 0.3229\n",
      "  Iteration: 24/35, Loss: 0.523253, Error: 0.1979\n",
      "  Iteration: 25/35, Loss: 0.452501, Error: 0.1667\n",
      "  Iteration: 26/35, Loss: 0.592966, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.633669, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.632046, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.640645, Error: 0.3125\n",
      "  Iteration: 30/35, Loss: 0.638511, Error: 0.3333\n",
      "  Iteration: 31/35, Loss: 0.540707, Error: 0.1875\n",
      "  Iteration: 32/35, Loss: 0.55534, Error: 0.2083\n",
      "  Iteration: 33/35, Loss: 0.531781, Error: 0.2083\n",
      "  Iteration: 34/35, Loss: 0.535464, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.563047, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2610\n",
      "Epoch: 8/100\n",
      "  Iteration: 1/35, Loss: 0.605065, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.649443, Error: 0.3125\n",
      "  Iteration: 3/35, Loss: 0.521377, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.504815, Error: 0.1979\n",
      "  Iteration: 5/35, Loss: 0.635716, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.63156, Error: 0.3229\n",
      "  Iteration: 7/35, Loss: 0.594222, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.5692, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.585883, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.583718, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.59035, Error: 0.2812\n",
      "  Iteration: 12/35, Loss: 0.653584, Error: 0.3438\n",
      "  Iteration: 13/35, Loss: 0.484069, Error: 0.1875\n",
      "  Iteration: 14/35, Loss: 0.511108, Error: 0.2083\n",
      "  Iteration: 15/35, Loss: 0.545657, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.578111, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.527129, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.565628, Error: 0.2500\n",
      "  Iteration: 19/35, Loss: 0.641302, Error: 0.3333\n",
      "  Iteration: 20/35, Loss: 0.643466, Error: 0.3438\n",
      "  Iteration: 21/35, Loss: 0.585865, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.600689, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.608482, Error: 0.2917\n",
      "  Iteration: 24/35, Loss: 0.563177, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.616361, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.540107, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.563053, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.535023, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.527477, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.628361, Error: 0.3021\n",
      "  Iteration: 31/35, Loss: 0.491385, Error: 0.2083\n",
      "  Iteration: 32/35, Loss: 0.497272, Error: 0.2083\n",
      "  Iteration: 33/35, Loss: 0.60895, Error: 0.2917\n",
      "  Iteration: 34/35, Loss: 0.558888, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.475466, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2602\n",
      "Epoch: 9/100\n",
      "  Iteration: 1/35, Loss: 0.554053, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.542178, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.641189, Error: 0.3021\n",
      "  Iteration: 4/35, Loss: 0.54892, Error: 0.2396\n",
      "  Iteration: 5/35, Loss: 0.612912, Error: 0.3021\n",
      "  Iteration: 6/35, Loss: 0.539763, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.546172, Error: 0.2292\n",
      "  Iteration: 8/35, Loss: 0.609974, Error: 0.3229\n",
      "  Iteration: 9/35, Loss: 0.603452, Error: 0.2917\n",
      "  Iteration: 10/35, Loss: 0.618119, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.577083, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.530165, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.601497, Error: 0.2708\n",
      "  Iteration: 14/35, Loss: 0.57578, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.543457, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.494104, Error: 0.2083\n",
      "  Iteration: 17/35, Loss: 0.696012, Error: 0.3438\n",
      "  Iteration: 18/35, Loss: 0.478271, Error: 0.2083\n",
      "  Iteration: 19/35, Loss: 0.607445, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.567799, Error: 0.2708\n",
      "  Iteration: 21/35, Loss: 0.603034, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.562935, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.595374, Error: 0.3021\n",
      "  Iteration: 24/35, Loss: 0.542251, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.588292, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.535317, Error: 0.2396\n",
      "  Iteration: 27/35, Loss: 0.554826, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.585287, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.629106, Error: 0.3021\n",
      "  Iteration: 30/35, Loss: 0.496755, Error: 0.1979\n",
      "  Iteration: 31/35, Loss: 0.501348, Error: 0.1979\n",
      "  Iteration: 32/35, Loss: 0.63305, Error: 0.3021\n",
      "  Iteration: 33/35, Loss: 0.53411, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.598747, Error: 0.2812\n",
      "  Iteration: 35/35, Loss: 0.531764, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2631\n",
      "Epoch: 10/100\n",
      "  Iteration: 1/35, Loss: 0.577067, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.49257, Error: 0.1875\n",
      "  Iteration: 3/35, Loss: 0.600961, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.520282, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.528901, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.713249, Error: 0.3646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 7/35, Loss: 0.633713, Error: 0.2917\n",
      "  Iteration: 8/35, Loss: 0.533011, Error: 0.2083\n",
      "  Iteration: 9/35, Loss: 0.565918, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.526718, Error: 0.2188\n",
      "  Iteration: 11/35, Loss: 0.578347, Error: 0.2812\n",
      "  Iteration: 12/35, Loss: 0.609703, Error: 0.3229\n",
      "  Iteration: 13/35, Loss: 0.599637, Error: 0.3021\n",
      "  Iteration: 14/35, Loss: 0.585098, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.578598, Error: 0.2812\n",
      "  Iteration: 16/35, Loss: 0.585524, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.514193, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.621122, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.562516, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.535583, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.589282, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.522223, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.596643, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.553198, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.522893, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.540367, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.564697, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.686226, Error: 0.3542\n",
      "  Iteration: 29/35, Loss: 0.613281, Error: 0.3125\n",
      "  Iteration: 30/35, Loss: 0.563775, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.51529, Error: 0.1875\n",
      "  Iteration: 32/35, Loss: 0.567052, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.498924, Error: 0.1979\n",
      "  Iteration: 34/35, Loss: 0.573953, Error: 0.2604\n",
      "  Iteration: 35/35, Loss: 0.604717, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2636\n",
      "Epoch: 11/100\n",
      "  Iteration: 1/35, Loss: 0.579112, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.703561, Error: 0.3438\n",
      "  Iteration: 3/35, Loss: 0.580334, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.552343, Error: 0.2500\n",
      "  Iteration: 5/35, Loss: 0.624863, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.532108, Error: 0.2083\n",
      "  Iteration: 7/35, Loss: 0.60213, Error: 0.3021\n",
      "  Iteration: 8/35, Loss: 0.55939, Error: 0.2188\n",
      "  Iteration: 9/35, Loss: 0.584441, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.531763, Error: 0.2083\n",
      "  Iteration: 11/35, Loss: 0.542953, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.583763, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.524382, Error: 0.2292\n",
      "  Iteration: 14/35, Loss: 0.526793, Error: 0.2292\n",
      "  Iteration: 15/35, Loss: 0.687412, Error: 0.3438\n",
      "  Iteration: 16/35, Loss: 0.608754, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.596981, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.481035, Error: 0.1771\n",
      "  Iteration: 19/35, Loss: 0.540889, Error: 0.2396\n",
      "  Iteration: 20/35, Loss: 0.567221, Error: 0.2604\n",
      "  Iteration: 21/35, Loss: 0.557765, Error: 0.2500\n",
      "  Iteration: 22/35, Loss: 0.58214, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.544207, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.470012, Error: 0.1667\n",
      "  Iteration: 25/35, Loss: 0.618119, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.546951, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.632875, Error: 0.3229\n",
      "  Iteration: 28/35, Loss: 0.486763, Error: 0.1875\n",
      "  Iteration: 29/35, Loss: 0.573918, Error: 0.2812\n",
      "  Iteration: 30/35, Loss: 0.553996, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.620236, Error: 0.3229\n",
      "  Iteration: 32/35, Loss: 0.561785, Error: 0.2708\n",
      "  Iteration: 33/35, Loss: 0.542534, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.554456, Error: 0.2604\n",
      "  Iteration: 35/35, Loss: 0.667171, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2615\n",
      "Epoch: 12/100\n",
      "  Iteration: 1/35, Loss: 0.540613, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.570012, Error: 0.2604\n",
      "  Iteration: 3/35, Loss: 0.642668, Error: 0.3542\n",
      "  Iteration: 4/35, Loss: 0.655648, Error: 0.3438\n",
      "  Iteration: 5/35, Loss: 0.588248, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.562158, Error: 0.2188\n",
      "  Iteration: 7/35, Loss: 0.573447, Error: 0.3021\n",
      "  Iteration: 8/35, Loss: 0.547432, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.527819, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.550976, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.527058, Error: 0.2188\n",
      "  Iteration: 12/35, Loss: 0.6028, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.668696, Error: 0.3125\n",
      "  Iteration: 14/35, Loss: 0.520479, Error: 0.2292\n",
      "  Iteration: 15/35, Loss: 0.563065, Error: 0.2708\n",
      "  Iteration: 16/35, Loss: 0.487501, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.536608, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.583057, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.573772, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.533863, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.480837, Error: 0.1667\n",
      "  Iteration: 22/35, Loss: 0.593902, Error: 0.3021\n",
      "  Iteration: 23/35, Loss: 0.614039, Error: 0.3125\n",
      "  Iteration: 24/35, Loss: 0.59433, Error: 0.2917\n",
      "  Iteration: 25/35, Loss: 0.579728, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.599893, Error: 0.2917\n",
      "  Iteration: 27/35, Loss: 0.580755, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.579511, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.558897, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.530874, Error: 0.1875\n",
      "  Iteration: 31/35, Loss: 0.5689, Error: 0.2708\n",
      "  Iteration: 32/35, Loss: 0.564604, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.495128, Error: 0.2188\n",
      "  Iteration: 34/35, Loss: 0.464872, Error: 0.1875\n",
      "  Iteration: 35/35, Loss: 0.494201, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2590\n",
      "Epoch: 13/100\n",
      "  Iteration: 1/35, Loss: 0.469059, Error: 0.1875\n",
      "  Iteration: 2/35, Loss: 0.574959, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.593924, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.509237, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.512748, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.52447, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.573152, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.571808, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.527771, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.582159, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.564922, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.537496, Error: 0.2396\n",
      "  Iteration: 13/35, Loss: 0.596905, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.636329, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.516079, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.549623, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.597111, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.591855, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.57424, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.579478, Error: 0.2708\n",
      "  Iteration: 21/35, Loss: 0.588698, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.52438, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.615565, Error: 0.3125\n",
      "  Iteration: 24/35, Loss: 0.595355, Error: 0.3021\n",
      "  Iteration: 25/35, Loss: 0.552721, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.64534, Error: 0.3542\n",
      "  Iteration: 27/35, Loss: 0.565387, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.503999, Error: 0.1979\n",
      "  Iteration: 29/35, Loss: 0.537404, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.622841, Error: 0.3125\n",
      "  Iteration: 31/35, Loss: 0.594068, Error: 0.2917\n",
      "  Iteration: 32/35, Loss: 0.481803, Error: 0.2083\n",
      "  Iteration: 33/35, Loss: 0.603603, Error: 0.3021\n",
      "  Iteration: 34/35, Loss: 0.640413, Error: 0.3229\n",
      "  Iteration: 35/35, Loss: 0.499866, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2599\n",
      "Epoch: 14/100\n",
      "  Iteration: 1/35, Loss: 0.616452, Error: 0.3438\n",
      "  Iteration: 2/35, Loss: 0.510826, Error: 0.2292\n",
      "  Iteration: 3/35, Loss: 0.559829, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.579388, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.545811, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.558791, Error: 0.2604\n",
      "  Iteration: 7/35, Loss: 0.556004, Error: 0.2917\n",
      "  Iteration: 8/35, Loss: 0.526129, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.455399, Error: 0.1771\n",
      "  Iteration: 10/35, Loss: 0.665326, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.562444, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.547821, Error: 0.2604\n",
      "  Iteration: 13/35, Loss: 0.536849, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.557039, Error: 0.2604\n",
      "  Iteration: 15/35, Loss: 0.578354, Error: 0.2917\n",
      "  Iteration: 16/35, Loss: 0.549115, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.555033, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.553968, Error: 0.2396\n",
      "  Iteration: 19/35, Loss: 0.439478, Error: 0.1562\n",
      "  Iteration: 20/35, Loss: 0.56725, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.562433, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.653182, Error: 0.3229\n",
      "  Iteration: 23/35, Loss: 0.542038, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.508217, Error: 0.2083\n",
      "  Iteration: 25/35, Loss: 0.629826, Error: 0.3229\n",
      "  Iteration: 26/35, Loss: 0.590011, Error: 0.2812\n",
      "  Iteration: 27/35, Loss: 0.534614, Error: 0.2188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 28/35, Loss: 0.57713, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.659063, Error: 0.3438\n",
      "  Iteration: 30/35, Loss: 0.581916, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.600284, Error: 0.3125\n",
      "  Iteration: 32/35, Loss: 0.566639, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.54074, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.569219, Error: 0.2604\n",
      "  Iteration: 35/35, Loss: 0.528312, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2587\n",
      "Epoch: 15/100\n",
      "  Iteration: 1/35, Loss: 0.5647, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.495414, Error: 0.1875\n",
      "  Iteration: 3/35, Loss: 0.581292, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.575975, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.515543, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.642189, Error: 0.3125\n",
      "  Iteration: 7/35, Loss: 0.609506, Error: 0.3125\n",
      "  Iteration: 8/35, Loss: 0.549837, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.567983, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.603113, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.62204, Error: 0.3229\n",
      "  Iteration: 12/35, Loss: 0.589781, Error: 0.3125\n",
      "  Iteration: 13/35, Loss: 0.543068, Error: 0.2083\n",
      "  Iteration: 14/35, Loss: 0.572302, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.619082, Error: 0.3125\n",
      "  Iteration: 16/35, Loss: 0.569279, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.547775, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.594785, Error: 0.3125\n",
      "  Iteration: 19/35, Loss: 0.591553, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.481114, Error: 0.1875\n",
      "  Iteration: 21/35, Loss: 0.567781, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.598607, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.515518, Error: 0.2292\n",
      "  Iteration: 24/35, Loss: 0.536825, Error: 0.2500\n",
      "  Iteration: 25/35, Loss: 0.576152, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.548719, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.566959, Error: 0.2917\n",
      "  Iteration: 28/35, Loss: 0.531781, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.524646, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.524277, Error: 0.2188\n",
      "  Iteration: 31/35, Loss: 0.544781, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.520644, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.587037, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.492945, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.489206, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2593\n",
      "Epoch: 16/100\n",
      "  Iteration: 1/35, Loss: 0.64493, Error: 0.3229\n",
      "  Iteration: 2/35, Loss: 0.576809, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.614969, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.53795, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.594459, Error: 0.3333\n",
      "  Iteration: 6/35, Loss: 0.571221, Error: 0.2292\n",
      "  Iteration: 7/35, Loss: 0.598268, Error: 0.3021\n",
      "  Iteration: 8/35, Loss: 0.577603, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.528727, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.608793, Error: 0.2917\n",
      "  Iteration: 11/35, Loss: 0.5541, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.547529, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.604267, Error: 0.3229\n",
      "  Iteration: 14/35, Loss: 0.549025, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.556341, Error: 0.2604\n",
      "  Iteration: 16/35, Loss: 0.611268, Error: 0.3229\n",
      "  Iteration: 17/35, Loss: 0.582921, Error: 0.2500\n",
      "  Iteration: 18/35, Loss: 0.559132, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.532359, Error: 0.2188\n",
      "  Iteration: 20/35, Loss: 0.560333, Error: 0.2188\n",
      "  Iteration: 21/35, Loss: 0.612138, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.559795, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.575977, Error: 0.2708\n",
      "  Iteration: 24/35, Loss: 0.587063, Error: 0.2917\n",
      "  Iteration: 25/35, Loss: 0.51241, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.485891, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.492121, Error: 0.1875\n",
      "  Iteration: 28/35, Loss: 0.526638, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.538056, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.600258, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.55885, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.575549, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.540319, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.513598, Error: 0.2083\n",
      "  Iteration: 35/35, Loss: 0.536933, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2604\n",
      "Epoch: 17/100\n",
      "  Iteration: 1/35, Loss: 0.57938, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.591076, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.587782, Error: 0.3021\n",
      "  Iteration: 4/35, Loss: 0.670748, Error: 0.3854\n",
      "  Iteration: 5/35, Loss: 0.510343, Error: 0.1875\n",
      "  Iteration: 6/35, Loss: 0.591406, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.599331, Error: 0.3125\n",
      "  Iteration: 8/35, Loss: 0.563012, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.585228, Error: 0.3229\n",
      "  Iteration: 10/35, Loss: 0.504514, Error: 0.2188\n",
      "  Iteration: 11/35, Loss: 0.499826, Error: 0.1979\n",
      "  Iteration: 12/35, Loss: 0.617153, Error: 0.2917\n",
      "  Iteration: 13/35, Loss: 0.511976, Error: 0.2083\n",
      "  Iteration: 14/35, Loss: 0.565166, Error: 0.2604\n",
      "  Iteration: 15/35, Loss: 0.623718, Error: 0.3438\n",
      "  Iteration: 16/35, Loss: 0.538802, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.527316, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.538067, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.624296, Error: 0.3229\n",
      "  Iteration: 20/35, Loss: 0.499023, Error: 0.2188\n",
      "  Iteration: 21/35, Loss: 0.627829, Error: 0.3229\n",
      "  Iteration: 22/35, Loss: 0.560093, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.580939, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.562833, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.478668, Error: 0.1771\n",
      "  Iteration: 26/35, Loss: 0.568484, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.568217, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.516502, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.511171, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.466186, Error: 0.1771\n",
      "  Iteration: 31/35, Loss: 0.576811, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.526215, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.530659, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.618889, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.421483, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2588\n",
      "Epoch: 18/100\n",
      "  Iteration: 1/35, Loss: 0.482147, Error: 0.1875\n",
      "  Iteration: 2/35, Loss: 0.646017, Error: 0.3333\n",
      "  Iteration: 3/35, Loss: 0.484427, Error: 0.1875\n",
      "  Iteration: 4/35, Loss: 0.544119, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.548444, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.479914, Error: 0.2188\n",
      "  Iteration: 7/35, Loss: 0.602638, Error: 0.3125\n",
      "  Iteration: 8/35, Loss: 0.605988, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.650426, Error: 0.3333\n",
      "  Iteration: 10/35, Loss: 0.596058, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.566796, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.604735, Error: 0.2917\n",
      "  Iteration: 13/35, Loss: 0.582905, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.56355, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.56042, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.581353, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.551986, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.599058, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.582549, Error: 0.2812\n",
      "  Iteration: 20/35, Loss: 0.556829, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.513616, Error: 0.1979\n",
      "  Iteration: 22/35, Loss: 0.543438, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.4999, Error: 0.1979\n",
      "  Iteration: 24/35, Loss: 0.570306, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.604443, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.573582, Error: 0.2812\n",
      "  Iteration: 27/35, Loss: 0.570694, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.498741, Error: 0.1771\n",
      "  Iteration: 29/35, Loss: 0.510749, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.559873, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.635023, Error: 0.3125\n",
      "  Iteration: 32/35, Loss: 0.580231, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.560516, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.5107, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.712497, Error: 0.4500\n",
      "Average Error for this Epoch: 0.2632\n",
      "Epoch: 19/100\n",
      "  Iteration: 1/35, Loss: 0.599151, Error: 0.2917\n",
      "  Iteration: 2/35, Loss: 0.505748, Error: 0.2083\n",
      "  Iteration: 3/35, Loss: 0.61, Error: 0.3333\n",
      "  Iteration: 4/35, Loss: 0.56198, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.566916, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.540997, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.54536, Error: 0.2292\n",
      "  Iteration: 8/35, Loss: 0.619676, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.510153, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.544599, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.530068, Error: 0.2188\n",
      "  Iteration: 12/35, Loss: 0.498353, Error: 0.1979\n",
      "  Iteration: 13/35, Loss: 0.576278, Error: 0.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 14/35, Loss: 0.522998, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.508862, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.578523, Error: 0.2917\n",
      "  Iteration: 17/35, Loss: 0.561974, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.577543, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.575004, Error: 0.2812\n",
      "  Iteration: 20/35, Loss: 0.559404, Error: 0.2812\n",
      "  Iteration: 21/35, Loss: 0.587131, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.545533, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.476711, Error: 0.1562\n",
      "  Iteration: 24/35, Loss: 0.478104, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.694155, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.634303, Error: 0.2917\n",
      "  Iteration: 27/35, Loss: 0.552753, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.564522, Error: 0.2604\n",
      "  Iteration: 29/35, Loss: 0.534936, Error: 0.2396\n",
      "  Iteration: 30/35, Loss: 0.570302, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.520821, Error: 0.1979\n",
      "  Iteration: 32/35, Loss: 0.599989, Error: 0.2917\n",
      "  Iteration: 33/35, Loss: 0.591749, Error: 0.3021\n",
      "  Iteration: 34/35, Loss: 0.596743, Error: 0.2917\n",
      "  Iteration: 35/35, Loss: 0.769233, Error: 0.4500\n",
      "Average Error for this Epoch: 0.2635\n",
      "Epoch: 20/100\n",
      "  Iteration: 1/35, Loss: 0.560998, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.574516, Error: 0.2292\n",
      "  Iteration: 3/35, Loss: 0.568124, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.547171, Error: 0.2292\n",
      "  Iteration: 5/35, Loss: 0.538993, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.546705, Error: 0.2604\n",
      "  Iteration: 7/35, Loss: 0.524318, Error: 0.2188\n",
      "  Iteration: 8/35, Loss: 0.481195, Error: 0.1979\n",
      "  Iteration: 9/35, Loss: 0.612708, Error: 0.2917\n",
      "  Iteration: 10/35, Loss: 0.665215, Error: 0.3229\n",
      "  Iteration: 11/35, Loss: 0.474237, Error: 0.1875\n",
      "  Iteration: 12/35, Loss: 0.510861, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.590186, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.645219, Error: 0.3646\n",
      "  Iteration: 15/35, Loss: 0.540331, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.569264, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.629555, Error: 0.3333\n",
      "  Iteration: 18/35, Loss: 0.565049, Error: 0.2500\n",
      "  Iteration: 19/35, Loss: 0.637474, Error: 0.3542\n",
      "  Iteration: 20/35, Loss: 0.555359, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.571249, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.535808, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.424664, Error: 0.1354\n",
      "  Iteration: 24/35, Loss: 0.643724, Error: 0.2917\n",
      "  Iteration: 25/35, Loss: 0.564697, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.58642, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.415553, Error: 0.1354\n",
      "  Iteration: 28/35, Loss: 0.625513, Error: 0.3125\n",
      "  Iteration: 29/35, Loss: 0.627226, Error: 0.3125\n",
      "  Iteration: 30/35, Loss: 0.594961, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.645763, Error: 0.3750\n",
      "  Iteration: 32/35, Loss: 0.52905, Error: 0.1979\n",
      "  Iteration: 33/35, Loss: 0.570215, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.57186, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.569665, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2601\n",
      "Epoch: 21/100\n",
      "  Iteration: 1/35, Loss: 0.55909, Error: 0.2604\n",
      "  Iteration: 2/35, Loss: 0.497855, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.5189, Error: 0.2396\n",
      "  Iteration: 4/35, Loss: 0.600088, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.5226, Error: 0.2083\n",
      "  Iteration: 6/35, Loss: 0.593328, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.649143, Error: 0.3125\n",
      "  Iteration: 8/35, Loss: 0.47305, Error: 0.1771\n",
      "  Iteration: 9/35, Loss: 0.527947, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.519143, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.561744, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.580986, Error: 0.2708\n",
      "  Iteration: 13/35, Loss: 0.607263, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.587649, Error: 0.3125\n",
      "  Iteration: 15/35, Loss: 0.541418, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.599816, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.595385, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.514046, Error: 0.2396\n",
      "  Iteration: 19/35, Loss: 0.539854, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.561342, Error: 0.2708\n",
      "  Iteration: 21/35, Loss: 0.593236, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.53066, Error: 0.2188\n",
      "  Iteration: 23/35, Loss: 0.524533, Error: 0.2188\n",
      "  Iteration: 24/35, Loss: 0.545486, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.711946, Error: 0.3854\n",
      "  Iteration: 26/35, Loss: 0.532403, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.53026, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.568885, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.548561, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.551357, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.534893, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.545967, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.56856, Error: 0.2917\n",
      "  Iteration: 34/35, Loss: 0.586914, Error: 0.2812\n",
      "  Iteration: 35/35, Loss: 0.497854, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2572\n",
      "found a better model!\n",
      "Epoch: 22/100\n",
      "  Iteration: 1/35, Loss: 0.638158, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.554572, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.48172, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.612607, Error: 0.3021\n",
      "  Iteration: 5/35, Loss: 0.574566, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.550538, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.557647, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.575964, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.549038, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.583096, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.572117, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.490046, Error: 0.1979\n",
      "  Iteration: 13/35, Loss: 0.549442, Error: 0.2500\n",
      "  Iteration: 14/35, Loss: 0.534332, Error: 0.2292\n",
      "  Iteration: 15/35, Loss: 0.548896, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.622013, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.626935, Error: 0.3125\n",
      "  Iteration: 18/35, Loss: 0.51173, Error: 0.2396\n",
      "  Iteration: 19/35, Loss: 0.615931, Error: 0.3438\n",
      "  Iteration: 20/35, Loss: 0.582462, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.52932, Error: 0.2188\n",
      "  Iteration: 22/35, Loss: 0.576404, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.522779, Error: 0.1771\n",
      "  Iteration: 24/35, Loss: 0.589143, Error: 0.3125\n",
      "  Iteration: 25/35, Loss: 0.584877, Error: 0.2604\n",
      "  Iteration: 26/35, Loss: 0.49852, Error: 0.1979\n",
      "  Iteration: 27/35, Loss: 0.558815, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.538683, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.60278, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.658575, Error: 0.3438\n",
      "  Iteration: 31/35, Loss: 0.539115, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.527618, Error: 0.2188\n",
      "  Iteration: 33/35, Loss: 0.535401, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.538489, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.463677, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2590\n",
      "Epoch: 23/100\n",
      "  Iteration: 1/35, Loss: 0.549716, Error: 0.2917\n",
      "  Iteration: 2/35, Loss: 0.543423, Error: 0.2604\n",
      "  Iteration: 3/35, Loss: 0.575273, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.635861, Error: 0.3125\n",
      "  Iteration: 5/35, Loss: 0.502419, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.57773, Error: 0.2812\n",
      "  Iteration: 7/35, Loss: 0.529259, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.553624, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.52511, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.49675, Error: 0.1771\n",
      "  Iteration: 11/35, Loss: 0.557747, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.559949, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.489478, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.58082, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.448848, Error: 0.1771\n",
      "  Iteration: 16/35, Loss: 0.623045, Error: 0.3021\n",
      "  Iteration: 17/35, Loss: 0.551909, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.566631, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.583129, Error: 0.2812\n",
      "  Iteration: 20/35, Loss: 0.536144, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.590907, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.541388, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.608196, Error: 0.2917\n",
      "  Iteration: 24/35, Loss: 0.615523, Error: 0.3542\n",
      "  Iteration: 25/35, Loss: 0.524607, Error: 0.1979\n",
      "  Iteration: 26/35, Loss: 0.54447, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.537348, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.567633, Error: 0.2917\n",
      "  Iteration: 29/35, Loss: 0.52362, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.482208, Error: 0.1979\n",
      "  Iteration: 31/35, Loss: 0.623852, Error: 0.2812\n",
      "  Iteration: 32/35, Loss: 0.545428, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.643305, Error: 0.3333\n",
      "  Iteration: 34/35, Loss: 0.616493, Error: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 35/35, Loss: 0.569982, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2583\n",
      "Epoch: 24/100\n",
      "  Iteration: 1/35, Loss: 0.549988, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.588244, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.580523, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.556789, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.528922, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.533257, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.541495, Error: 0.2500\n",
      "  Iteration: 8/35, Loss: 0.568463, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.490846, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.492756, Error: 0.1771\n",
      "  Iteration: 11/35, Loss: 0.710539, Error: 0.3750\n",
      "  Iteration: 12/35, Loss: 0.638271, Error: 0.3229\n",
      "  Iteration: 13/35, Loss: 0.578159, Error: 0.3021\n",
      "  Iteration: 14/35, Loss: 0.620938, Error: 0.3438\n",
      "  Iteration: 15/35, Loss: 0.621212, Error: 0.3646\n",
      "  Iteration: 16/35, Loss: 0.59135, Error: 0.3125\n",
      "  Iteration: 17/35, Loss: 0.593321, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.56875, Error: 0.2500\n",
      "  Iteration: 19/35, Loss: 0.558275, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.517174, Error: 0.2188\n",
      "  Iteration: 21/35, Loss: 0.511837, Error: 0.2188\n",
      "  Iteration: 22/35, Loss: 0.473244, Error: 0.1979\n",
      "  Iteration: 23/35, Loss: 0.519787, Error: 0.2083\n",
      "  Iteration: 24/35, Loss: 0.396882, Error: 0.1562\n",
      "  Iteration: 25/35, Loss: 0.560481, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.57002, Error: 0.2396\n",
      "  Iteration: 27/35, Loss: 0.535772, Error: 0.2292\n",
      "  Iteration: 28/35, Loss: 0.639803, Error: 0.3125\n",
      "  Iteration: 29/35, Loss: 0.605568, Error: 0.3021\n",
      "  Iteration: 30/35, Loss: 0.61367, Error: 0.3021\n",
      "  Iteration: 31/35, Loss: 0.539823, Error: 0.2188\n",
      "  Iteration: 32/35, Loss: 0.556225, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.53823, Error: 0.1875\n",
      "  Iteration: 34/35, Loss: 0.607362, Error: 0.2604\n",
      "  Iteration: 35/35, Loss: 0.683642, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2636\n",
      "Epoch: 25/100\n",
      "  Iteration: 1/35, Loss: 0.548638, Error: 0.2188\n",
      "  Iteration: 2/35, Loss: 0.539502, Error: 0.2188\n",
      "  Iteration: 3/35, Loss: 0.559563, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.567326, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.549123, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.423299, Error: 0.1562\n",
      "  Iteration: 7/35, Loss: 0.580146, Error: 0.2604\n",
      "  Iteration: 8/35, Loss: 0.770118, Error: 0.3958\n",
      "  Iteration: 9/35, Loss: 0.533571, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.546236, Error: 0.2083\n",
      "  Iteration: 11/35, Loss: 0.524002, Error: 0.2396\n",
      "  Iteration: 12/35, Loss: 0.633916, Error: 0.3125\n",
      "  Iteration: 13/35, Loss: 0.529431, Error: 0.2292\n",
      "  Iteration: 14/35, Loss: 0.513882, Error: 0.2083\n",
      "  Iteration: 15/35, Loss: 0.541086, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.630229, Error: 0.3229\n",
      "  Iteration: 17/35, Loss: 0.56785, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.564224, Error: 0.2500\n",
      "  Iteration: 19/35, Loss: 0.566257, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.58623, Error: 0.2812\n",
      "  Iteration: 21/35, Loss: 0.52676, Error: 0.2188\n",
      "  Iteration: 22/35, Loss: 0.519731, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.686022, Error: 0.3438\n",
      "  Iteration: 24/35, Loss: 0.477734, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.537598, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.546078, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.522416, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.62859, Error: 0.3021\n",
      "  Iteration: 29/35, Loss: 0.592563, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.543272, Error: 0.2292\n",
      "  Iteration: 31/35, Loss: 0.612598, Error: 0.3021\n",
      "  Iteration: 32/35, Loss: 0.499551, Error: 0.1979\n",
      "  Iteration: 33/35, Loss: 0.57369, Error: 0.2812\n",
      "  Iteration: 34/35, Loss: 0.595669, Error: 0.2812\n",
      "  Iteration: 35/35, Loss: 0.55119, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2577\n",
      "Epoch: 26/100\n",
      "  Iteration: 1/35, Loss: 0.533566, Error: 0.2604\n",
      "  Iteration: 2/35, Loss: 0.621, Error: 0.3229\n",
      "  Iteration: 3/35, Loss: 0.594272, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.466665, Error: 0.1875\n",
      "  Iteration: 5/35, Loss: 0.529167, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.515532, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.535855, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.518095, Error: 0.1979\n",
      "  Iteration: 9/35, Loss: 0.54859, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.581827, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.662077, Error: 0.3229\n",
      "  Iteration: 12/35, Loss: 0.576523, Error: 0.2708\n",
      "  Iteration: 13/35, Loss: 0.522875, Error: 0.1771\n",
      "  Iteration: 14/35, Loss: 0.58792, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.541906, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.582353, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.47587, Error: 0.1875\n",
      "  Iteration: 18/35, Loss: 0.56798, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.624921, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.547516, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.511952, Error: 0.2292\n",
      "  Iteration: 22/35, Loss: 0.58373, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.557286, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.577917, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.555014, Error: 0.2604\n",
      "  Iteration: 26/35, Loss: 0.538551, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.53001, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.510187, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.559443, Error: 0.2708\n",
      "  Iteration: 30/35, Loss: 0.58286, Error: 0.2708\n",
      "  Iteration: 31/35, Loss: 0.568422, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.576498, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.543141, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.60105, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.839749, Error: 0.5000\n",
      "Average Error for this Epoch: 0.2628\n",
      "Epoch: 27/100\n",
      "  Iteration: 1/35, Loss: 0.575803, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.557851, Error: 0.2292\n",
      "  Iteration: 3/35, Loss: 0.581564, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.561154, Error: 0.2292\n",
      "  Iteration: 5/35, Loss: 0.581498, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.561546, Error: 0.2292\n",
      "  Iteration: 7/35, Loss: 0.562648, Error: 0.2500\n",
      "  Iteration: 8/35, Loss: 0.493765, Error: 0.1771\n",
      "  Iteration: 9/35, Loss: 0.528512, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.630218, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.633782, Error: 0.3021\n",
      "  Iteration: 12/35, Loss: 0.748676, Error: 0.3750\n",
      "  Iteration: 13/35, Loss: 0.609477, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.569715, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.521948, Error: 0.2188\n",
      "  Iteration: 16/35, Loss: 0.496865, Error: 0.1875\n",
      "  Iteration: 17/35, Loss: 0.58564, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.566021, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.513317, Error: 0.1979\n",
      "  Iteration: 20/35, Loss: 0.565315, Error: 0.2604\n",
      "  Iteration: 21/35, Loss: 0.542649, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.564242, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.551267, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.640804, Error: 0.3229\n",
      "  Iteration: 25/35, Loss: 0.484369, Error: 0.1979\n",
      "  Iteration: 26/35, Loss: 0.666089, Error: 0.3333\n",
      "  Iteration: 27/35, Loss: 0.584799, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.49822, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.5697, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.51054, Error: 0.2083\n",
      "  Iteration: 31/35, Loss: 0.552424, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.508227, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.631302, Error: 0.3125\n",
      "  Iteration: 34/35, Loss: 0.682649, Error: 0.3542\n",
      "  Iteration: 35/35, Loss: 0.457941, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2557\n",
      "found a better model!\n",
      "Epoch: 28/100\n",
      "  Iteration: 1/35, Loss: 0.521075, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.611156, Error: 0.3125\n",
      "  Iteration: 3/35, Loss: 0.541621, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.561897, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.583415, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.508635, Error: 0.1979\n",
      "  Iteration: 7/35, Loss: 0.607209, Error: 0.3542\n",
      "  Iteration: 8/35, Loss: 0.522363, Error: 0.2083\n",
      "  Iteration: 9/35, Loss: 0.60504, Error: 0.3229\n",
      "  Iteration: 10/35, Loss: 0.449795, Error: 0.1667\n",
      "  Iteration: 11/35, Loss: 0.538021, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.464377, Error: 0.1771\n",
      "  Iteration: 13/35, Loss: 0.618788, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.470551, Error: 0.1979\n",
      "  Iteration: 15/35, Loss: 0.6443, Error: 0.3229\n",
      "  Iteration: 16/35, Loss: 0.53755, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.540182, Error: 0.2396\n",
      "  Iteration: 18/35, Loss: 0.619678, Error: 0.3229\n",
      "  Iteration: 19/35, Loss: 0.573492, Error: 0.2812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 20/35, Loss: 0.591853, Error: 0.3229\n",
      "  Iteration: 21/35, Loss: 0.559085, Error: 0.2500\n",
      "  Iteration: 22/35, Loss: 0.59757, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.573509, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.576088, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.58165, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.516302, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.629109, Error: 0.2917\n",
      "  Iteration: 28/35, Loss: 0.525375, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.598528, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.503433, Error: 0.2083\n",
      "  Iteration: 31/35, Loss: 0.505415, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.554203, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.562173, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.666643, Error: 0.3438\n",
      "  Iteration: 35/35, Loss: 0.537122, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2601\n",
      "Epoch: 29/100\n",
      "  Iteration: 1/35, Loss: 0.63162, Error: 0.3438\n",
      "  Iteration: 2/35, Loss: 0.601077, Error: 0.3125\n",
      "  Iteration: 3/35, Loss: 0.595687, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.548911, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.575828, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.573334, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.561571, Error: 0.2188\n",
      "  Iteration: 8/35, Loss: 0.527237, Error: 0.1979\n",
      "  Iteration: 9/35, Loss: 0.551508, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.515733, Error: 0.2188\n",
      "  Iteration: 11/35, Loss: 0.511263, Error: 0.2083\n",
      "  Iteration: 12/35, Loss: 0.597863, Error: 0.2708\n",
      "  Iteration: 13/35, Loss: 0.721574, Error: 0.3646\n",
      "  Iteration: 14/35, Loss: 0.616739, Error: 0.3021\n",
      "  Iteration: 15/35, Loss: 0.539037, Error: 0.2188\n",
      "  Iteration: 16/35, Loss: 0.515181, Error: 0.2292\n",
      "  Iteration: 17/35, Loss: 0.480638, Error: 0.2083\n",
      "  Iteration: 18/35, Loss: 0.498998, Error: 0.2188\n",
      "  Iteration: 19/35, Loss: 0.570606, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.570074, Error: 0.2708\n",
      "  Iteration: 21/35, Loss: 0.613291, Error: 0.3125\n",
      "  Iteration: 22/35, Loss: 0.5833, Error: 0.2917\n",
      "  Iteration: 23/35, Loss: 0.578141, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.505343, Error: 0.2083\n",
      "  Iteration: 25/35, Loss: 0.500679, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.501114, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.536316, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.581677, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.592104, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.577808, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.601587, Error: 0.3021\n",
      "  Iteration: 32/35, Loss: 0.559158, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.561636, Error: 0.2917\n",
      "  Iteration: 34/35, Loss: 0.481661, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.517592, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2574\n",
      "Epoch: 30/100\n",
      "  Iteration: 1/35, Loss: 0.527434, Error: 0.2188\n",
      "  Iteration: 2/35, Loss: 0.574263, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.61095, Error: 0.3021\n",
      "  Iteration: 4/35, Loss: 0.528978, Error: 0.2396\n",
      "  Iteration: 5/35, Loss: 0.585271, Error: 0.2812\n",
      "  Iteration: 6/35, Loss: 0.476987, Error: 0.1875\n",
      "  Iteration: 7/35, Loss: 0.516333, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.458113, Error: 0.1979\n",
      "  Iteration: 9/35, Loss: 0.567194, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.631699, Error: 0.3125\n",
      "  Iteration: 11/35, Loss: 0.605157, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.472546, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.605001, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.576461, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.527084, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.55992, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.652025, Error: 0.3750\n",
      "  Iteration: 18/35, Loss: 0.585804, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.610216, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.573965, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.526223, Error: 0.1875\n",
      "  Iteration: 22/35, Loss: 0.590556, Error: 0.3021\n",
      "  Iteration: 23/35, Loss: 0.54061, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.545523, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.447658, Error: 0.1771\n",
      "  Iteration: 26/35, Loss: 0.547327, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.498853, Error: 0.2083\n",
      "  Iteration: 28/35, Loss: 0.654239, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.55701, Error: 0.2396\n",
      "  Iteration: 30/35, Loss: 0.65028, Error: 0.3125\n",
      "  Iteration: 31/35, Loss: 0.479573, Error: 0.1979\n",
      "  Iteration: 32/35, Loss: 0.590582, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.54547, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.586041, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.488458, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2534\n",
      "found a better model!\n",
      "Epoch: 31/100\n",
      "  Iteration: 1/35, Loss: 0.543806, Error: 0.2604\n",
      "  Iteration: 2/35, Loss: 0.637079, Error: 0.3333\n",
      "  Iteration: 3/35, Loss: 0.606339, Error: 0.3333\n",
      "  Iteration: 4/35, Loss: 0.605021, Error: 0.3125\n",
      "  Iteration: 5/35, Loss: 0.540206, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.574667, Error: 0.2812\n",
      "  Iteration: 7/35, Loss: 0.551294, Error: 0.2500\n",
      "  Iteration: 8/35, Loss: 0.604185, Error: 0.3021\n",
      "  Iteration: 9/35, Loss: 0.51727, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.572894, Error: 0.2812\n",
      "  Iteration: 11/35, Loss: 0.549454, Error: 0.2396\n",
      "  Iteration: 12/35, Loss: 0.436106, Error: 0.1562\n",
      "  Iteration: 13/35, Loss: 0.534284, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.55326, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.59921, Error: 0.3021\n",
      "  Iteration: 16/35, Loss: 0.644006, Error: 0.3333\n",
      "  Iteration: 17/35, Loss: 0.55363, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.631076, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.571449, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.501865, Error: 0.2083\n",
      "  Iteration: 21/35, Loss: 0.555541, Error: 0.2604\n",
      "  Iteration: 22/35, Loss: 0.580708, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.572856, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.522539, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.67012, Error: 0.3542\n",
      "  Iteration: 26/35, Loss: 0.508321, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.511412, Error: 0.2188\n",
      "  Iteration: 28/35, Loss: 0.582029, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.529815, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.559442, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.558343, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.452268, Error: 0.1562\n",
      "  Iteration: 33/35, Loss: 0.51414, Error: 0.2188\n",
      "  Iteration: 34/35, Loss: 0.589078, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.662468, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2589\n",
      "Epoch: 32/100\n",
      "  Iteration: 1/35, Loss: 0.506262, Error: 0.2188\n",
      "  Iteration: 2/35, Loss: 0.557492, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.595402, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.506338, Error: 0.1979\n",
      "  Iteration: 5/35, Loss: 0.629711, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.620808, Error: 0.3438\n",
      "  Iteration: 7/35, Loss: 0.582006, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.547354, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.527185, Error: 0.2083\n",
      "  Iteration: 10/35, Loss: 0.489635, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.547274, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.596178, Error: 0.3021\n",
      "  Iteration: 13/35, Loss: 0.529363, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.546528, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.568634, Error: 0.2604\n",
      "  Iteration: 16/35, Loss: 0.673464, Error: 0.3542\n",
      "  Iteration: 17/35, Loss: 0.553547, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.568936, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.534407, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.532516, Error: 0.2083\n",
      "  Iteration: 21/35, Loss: 0.596988, Error: 0.3125\n",
      "  Iteration: 22/35, Loss: 0.548269, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.548692, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.499997, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.460806, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.478191, Error: 0.1979\n",
      "  Iteration: 27/35, Loss: 0.504467, Error: 0.2188\n",
      "  Iteration: 28/35, Loss: 0.705986, Error: 0.3021\n",
      "  Iteration: 29/35, Loss: 0.677469, Error: 0.3021\n",
      "  Iteration: 30/35, Loss: 0.503315, Error: 0.2188\n",
      "  Iteration: 31/35, Loss: 0.655779, Error: 0.3125\n",
      "  Iteration: 32/35, Loss: 0.581209, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.557508, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.625313, Error: 0.3333\n",
      "  Iteration: 35/35, Loss: 0.554987, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2619\n",
      "Epoch: 33/100\n",
      "  Iteration: 1/35, Loss: 0.550188, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.535476, Error: 0.2188\n",
      "  Iteration: 3/35, Loss: 0.545483, Error: 0.2396\n",
      "  Iteration: 4/35, Loss: 0.659774, Error: 0.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 5/35, Loss: 0.549823, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.593777, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.54216, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.635806, Error: 0.3229\n",
      "  Iteration: 9/35, Loss: 0.573724, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.596158, Error: 0.2812\n",
      "  Iteration: 11/35, Loss: 0.517583, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.623605, Error: 0.3333\n",
      "  Iteration: 13/35, Loss: 0.554886, Error: 0.2708\n",
      "  Iteration: 14/35, Loss: 0.576642, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.555396, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.562022, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.487917, Error: 0.1875\n",
      "  Iteration: 18/35, Loss: 0.557723, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.590591, Error: 0.2812\n",
      "  Iteration: 20/35, Loss: 0.453362, Error: 0.1979\n",
      "  Iteration: 21/35, Loss: 0.535001, Error: 0.2292\n",
      "  Iteration: 22/35, Loss: 0.686754, Error: 0.3542\n",
      "  Iteration: 23/35, Loss: 0.511408, Error: 0.2188\n",
      "  Iteration: 24/35, Loss: 0.538566, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.503323, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.55179, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.571906, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.500771, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.558683, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.554598, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.541071, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.525298, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.581165, Error: 0.2812\n",
      "  Iteration: 34/35, Loss: 0.613704, Error: 0.3125\n",
      "  Iteration: 35/35, Loss: 0.652922, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2624\n",
      "Epoch: 34/100\n",
      "  Iteration: 1/35, Loss: 0.608967, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.545631, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.571783, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.58626, Error: 0.2917\n",
      "  Iteration: 5/35, Loss: 0.595613, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.593103, Error: 0.2917\n",
      "  Iteration: 7/35, Loss: 0.502377, Error: 0.1354\n",
      "  Iteration: 8/35, Loss: 0.591674, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.541095, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.59497, Error: 0.2917\n",
      "  Iteration: 11/35, Loss: 0.511697, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.521565, Error: 0.2396\n",
      "  Iteration: 13/35, Loss: 0.581664, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.552895, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.564951, Error: 0.2604\n",
      "  Iteration: 16/35, Loss: 0.475798, Error: 0.2083\n",
      "  Iteration: 17/35, Loss: 0.54189, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.49546, Error: 0.2292\n",
      "  Iteration: 19/35, Loss: 0.575303, Error: 0.3021\n",
      "  Iteration: 20/35, Loss: 0.58221, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.568395, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.602004, Error: 0.2917\n",
      "  Iteration: 23/35, Loss: 0.517629, Error: 0.1771\n",
      "  Iteration: 24/35, Loss: 0.566036, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.51728, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.549165, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.611057, Error: 0.3021\n",
      "  Iteration: 28/35, Loss: 0.510815, Error: 0.2083\n",
      "  Iteration: 29/35, Loss: 0.439876, Error: 0.1562\n",
      "  Iteration: 30/35, Loss: 0.606004, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.477593, Error: 0.1875\n",
      "  Iteration: 32/35, Loss: 0.593711, Error: 0.2708\n",
      "  Iteration: 33/35, Loss: 0.661338, Error: 0.3542\n",
      "  Iteration: 34/35, Loss: 0.607783, Error: 0.2917\n",
      "  Iteration: 35/35, Loss: 0.474023, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2546\n",
      "Epoch: 35/100\n",
      "  Iteration: 1/35, Loss: 0.55775, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.595376, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.541698, Error: 0.2292\n",
      "  Iteration: 4/35, Loss: 0.560766, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.545139, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.615468, Error: 0.3438\n",
      "  Iteration: 7/35, Loss: 0.591433, Error: 0.2604\n",
      "  Iteration: 8/35, Loss: 0.614224, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.446044, Error: 0.1562\n",
      "  Iteration: 10/35, Loss: 0.506456, Error: 0.2188\n",
      "  Iteration: 11/35, Loss: 0.622457, Error: 0.3125\n",
      "  Iteration: 12/35, Loss: 0.55538, Error: 0.2917\n",
      "  Iteration: 13/35, Loss: 0.578856, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.674962, Error: 0.3646\n",
      "  Iteration: 15/35, Loss: 0.521096, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.431461, Error: 0.1562\n",
      "  Iteration: 17/35, Loss: 0.589332, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.606344, Error: 0.3125\n",
      "  Iteration: 19/35, Loss: 0.530082, Error: 0.2292\n",
      "  Iteration: 20/35, Loss: 0.451405, Error: 0.1458\n",
      "  Iteration: 21/35, Loss: 0.611436, Error: 0.3438\n",
      "  Iteration: 22/35, Loss: 0.538174, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.556021, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.531115, Error: 0.2500\n",
      "  Iteration: 25/35, Loss: 0.496336, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.510296, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.614449, Error: 0.3021\n",
      "  Iteration: 28/35, Loss: 0.595367, Error: 0.3125\n",
      "  Iteration: 29/35, Loss: 0.582963, Error: 0.2812\n",
      "  Iteration: 30/35, Loss: 0.584083, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.494898, Error: 0.1979\n",
      "  Iteration: 32/35, Loss: 0.557753, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.532738, Error: 0.2083\n",
      "  Iteration: 34/35, Loss: 0.567609, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.440272, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2572\n",
      "Epoch: 36/100\n",
      "  Iteration: 1/35, Loss: 0.567729, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.603881, Error: 0.3333\n",
      "  Iteration: 3/35, Loss: 0.601495, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.612821, Error: 0.2917\n",
      "  Iteration: 5/35, Loss: 0.467857, Error: 0.1562\n",
      "  Iteration: 6/35, Loss: 0.57632, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.51785, Error: 0.2188\n",
      "  Iteration: 8/35, Loss: 0.544283, Error: 0.2604\n",
      "  Iteration: 9/35, Loss: 0.53918, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.560791, Error: 0.2500\n",
      "  Iteration: 11/35, Loss: 0.560433, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.484564, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.656683, Error: 0.3438\n",
      "  Iteration: 14/35, Loss: 0.532234, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.526268, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.55193, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.501645, Error: 0.2083\n",
      "  Iteration: 18/35, Loss: 0.654989, Error: 0.3542\n",
      "  Iteration: 19/35, Loss: 0.534576, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.479263, Error: 0.2083\n",
      "  Iteration: 21/35, Loss: 0.487401, Error: 0.1771\n",
      "  Iteration: 22/35, Loss: 0.527007, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.487569, Error: 0.1979\n",
      "  Iteration: 24/35, Loss: 0.493872, Error: 0.2083\n",
      "  Iteration: 25/35, Loss: 0.647504, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.695085, Error: 0.3438\n",
      "  Iteration: 27/35, Loss: 0.542485, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.610244, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.526991, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.611324, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.565748, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.616167, Error: 0.3229\n",
      "  Iteration: 33/35, Loss: 0.568891, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.542438, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.546618, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2580\n",
      "Epoch: 37/100\n",
      "  Iteration: 1/35, Loss: 0.559605, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.576901, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.571995, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.566215, Error: 0.2500\n",
      "  Iteration: 5/35, Loss: 0.549623, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.460627, Error: 0.1771\n",
      "  Iteration: 7/35, Loss: 0.547294, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.505596, Error: 0.2083\n",
      "  Iteration: 9/35, Loss: 0.551314, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.592295, Error: 0.2812\n",
      "  Iteration: 11/35, Loss: 0.633024, Error: 0.3125\n",
      "  Iteration: 12/35, Loss: 0.644831, Error: 0.3125\n",
      "  Iteration: 13/35, Loss: 0.527163, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.530617, Error: 0.2083\n",
      "  Iteration: 15/35, Loss: 0.526946, Error: 0.2188\n",
      "  Iteration: 16/35, Loss: 0.50958, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.530582, Error: 0.2396\n",
      "  Iteration: 18/35, Loss: 0.494698, Error: 0.1875\n",
      "  Iteration: 19/35, Loss: 0.575447, Error: 0.2812\n",
      "  Iteration: 20/35, Loss: 0.524421, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.4799, Error: 0.2083\n",
      "  Iteration: 22/35, Loss: 0.53717, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.501853, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.587167, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.662067, Error: 0.3438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 26/35, Loss: 0.643158, Error: 0.3333\n",
      "  Iteration: 27/35, Loss: 0.526633, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.556179, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.557488, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.617942, Error: 0.3229\n",
      "  Iteration: 31/35, Loss: 0.601749, Error: 0.3125\n",
      "  Iteration: 32/35, Loss: 0.632541, Error: 0.3333\n",
      "  Iteration: 33/35, Loss: 0.587543, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.548304, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.503259, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2569\n",
      "Epoch: 38/100\n",
      "  Iteration: 1/35, Loss: 0.510259, Error: 0.1979\n",
      "  Iteration: 2/35, Loss: 0.595318, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.465599, Error: 0.1875\n",
      "  Iteration: 4/35, Loss: 0.557418, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.559827, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.5551, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.59534, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.524749, Error: 0.2188\n",
      "  Iteration: 9/35, Loss: 0.555665, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.570051, Error: 0.2500\n",
      "  Iteration: 11/35, Loss: 0.586577, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.549546, Error: 0.2396\n",
      "  Iteration: 13/35, Loss: 0.573693, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.550477, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.538644, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.513765, Error: 0.2292\n",
      "  Iteration: 17/35, Loss: 0.579425, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.616508, Error: 0.3333\n",
      "  Iteration: 19/35, Loss: 0.601474, Error: 0.3125\n",
      "  Iteration: 20/35, Loss: 0.618223, Error: 0.3021\n",
      "  Iteration: 21/35, Loss: 0.604713, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.560952, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.601418, Error: 0.2917\n",
      "  Iteration: 24/35, Loss: 0.56439, Error: 0.2500\n",
      "  Iteration: 25/35, Loss: 0.527086, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.475761, Error: 0.1875\n",
      "  Iteration: 27/35, Loss: 0.574704, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.54238, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.489117, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.603269, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.522357, Error: 0.2396\n",
      "  Iteration: 32/35, Loss: 0.487637, Error: 0.1979\n",
      "  Iteration: 33/35, Loss: 0.672035, Error: 0.3438\n",
      "  Iteration: 34/35, Loss: 0.492534, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.546112, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2545\n",
      "Epoch: 39/100\n",
      "  Iteration: 1/35, Loss: 0.52939, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.530107, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.603846, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.603998, Error: 0.3333\n",
      "  Iteration: 5/35, Loss: 0.565703, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.610577, Error: 0.3229\n",
      "  Iteration: 7/35, Loss: 0.553891, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.52595, Error: 0.2917\n",
      "  Iteration: 9/35, Loss: 0.514535, Error: 0.2083\n",
      "  Iteration: 10/35, Loss: 0.517047, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.519362, Error: 0.2396\n",
      "  Iteration: 12/35, Loss: 0.60157, Error: 0.3021\n",
      "  Iteration: 13/35, Loss: 0.525877, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.714161, Error: 0.3333\n",
      "  Iteration: 15/35, Loss: 0.631725, Error: 0.3021\n",
      "  Iteration: 16/35, Loss: 0.493377, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.550334, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.563683, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.544698, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.472089, Error: 0.1875\n",
      "  Iteration: 21/35, Loss: 0.588787, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.553766, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.534211, Error: 0.2708\n",
      "  Iteration: 24/35, Loss: 0.57831, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.570903, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.552996, Error: 0.2396\n",
      "  Iteration: 27/35, Loss: 0.578248, Error: 0.3021\n",
      "  Iteration: 28/35, Loss: 0.653381, Error: 0.3542\n",
      "  Iteration: 29/35, Loss: 0.576127, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.542407, Error: 0.2292\n",
      "  Iteration: 31/35, Loss: 0.485644, Error: 0.1771\n",
      "  Iteration: 32/35, Loss: 0.527208, Error: 0.2188\n",
      "  Iteration: 33/35, Loss: 0.5427, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.471517, Error: 0.1875\n",
      "  Iteration: 35/35, Loss: 0.63356, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2633\n",
      "Epoch: 40/100\n",
      "  Iteration: 1/35, Loss: 0.601559, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.433295, Error: 0.1667\n",
      "  Iteration: 3/35, Loss: 0.616546, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.505299, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.50985, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.527611, Error: 0.2292\n",
      "  Iteration: 7/35, Loss: 0.591869, Error: 0.2917\n",
      "  Iteration: 8/35, Loss: 0.581561, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.590694, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.517536, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.642136, Error: 0.3229\n",
      "  Iteration: 12/35, Loss: 0.563599, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.559535, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.513765, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.543405, Error: 0.2708\n",
      "  Iteration: 16/35, Loss: 0.522297, Error: 0.2083\n",
      "  Iteration: 17/35, Loss: 0.625927, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.511864, Error: 0.2188\n",
      "  Iteration: 19/35, Loss: 0.528199, Error: 0.2188\n",
      "  Iteration: 20/35, Loss: 0.551052, Error: 0.2604\n",
      "  Iteration: 21/35, Loss: 0.5079, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.619817, Error: 0.3021\n",
      "  Iteration: 23/35, Loss: 0.569595, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.539109, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.616892, Error: 0.3333\n",
      "  Iteration: 26/35, Loss: 0.573485, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.486009, Error: 0.1771\n",
      "  Iteration: 28/35, Loss: 0.504557, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.503727, Error: 0.1979\n",
      "  Iteration: 30/35, Loss: 0.536248, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.612686, Error: 0.3333\n",
      "  Iteration: 32/35, Loss: 0.586676, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.543305, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.613729, Error: 0.2917\n",
      "  Iteration: 35/35, Loss: 0.494264, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2563\n",
      "Epoch: 41/100\n",
      "  Iteration: 1/35, Loss: 0.509161, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.502154, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.593358, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.469827, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.561868, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.664461, Error: 0.3438\n",
      "  Iteration: 7/35, Loss: 0.505505, Error: 0.2188\n",
      "  Iteration: 8/35, Loss: 0.593798, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.554396, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.526565, Error: 0.2188\n",
      "  Iteration: 11/35, Loss: 0.528674, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.546261, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.563827, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.551787, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.505058, Error: 0.1979\n",
      "  Iteration: 16/35, Loss: 0.459484, Error: 0.1875\n",
      "  Iteration: 17/35, Loss: 0.612954, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.610651, Error: 0.3125\n",
      "  Iteration: 19/35, Loss: 0.56962, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.611608, Error: 0.3229\n",
      "  Iteration: 21/35, Loss: 0.489265, Error: 0.1875\n",
      "  Iteration: 22/35, Loss: 0.446299, Error: 0.1562\n",
      "  Iteration: 23/35, Loss: 0.464513, Error: 0.1771\n",
      "  Iteration: 24/35, Loss: 0.581468, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.565829, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.639003, Error: 0.3125\n",
      "  Iteration: 27/35, Loss: 0.585098, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.538975, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.539796, Error: 0.2396\n",
      "  Iteration: 30/35, Loss: 0.639634, Error: 0.3646\n",
      "  Iteration: 31/35, Loss: 0.55231, Error: 0.2396\n",
      "  Iteration: 32/35, Loss: 0.585658, Error: 0.2917\n",
      "  Iteration: 33/35, Loss: 0.559754, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.574213, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.610882, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2591\n",
      "Epoch: 42/100\n",
      "  Iteration: 1/35, Loss: 0.533638, Error: 0.2604\n",
      "  Iteration: 2/35, Loss: 0.604821, Error: 0.2708\n",
      "  Iteration: 3/35, Loss: 0.519093, Error: 0.2292\n",
      "  Iteration: 4/35, Loss: 0.529968, Error: 0.2292\n",
      "  Iteration: 5/35, Loss: 0.546945, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.501353, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.613592, Error: 0.3125\n",
      "  Iteration: 8/35, Loss: 0.514708, Error: 0.2188\n",
      "  Iteration: 9/35, Loss: 0.446511, Error: 0.1667\n",
      "  Iteration: 10/35, Loss: 0.533577, Error: 0.2396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 11/35, Loss: 0.666797, Error: 0.3021\n",
      "  Iteration: 12/35, Loss: 0.580229, Error: 0.2917\n",
      "  Iteration: 13/35, Loss: 0.520051, Error: 0.2292\n",
      "  Iteration: 14/35, Loss: 0.53976, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.601153, Error: 0.2917\n",
      "  Iteration: 16/35, Loss: 0.530495, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.59182, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.457286, Error: 0.1562\n",
      "  Iteration: 19/35, Loss: 0.518105, Error: 0.2083\n",
      "  Iteration: 20/35, Loss: 0.558, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.571528, Error: 0.3125\n",
      "  Iteration: 22/35, Loss: 0.530563, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.600704, Error: 0.2917\n",
      "  Iteration: 24/35, Loss: 0.587569, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.607959, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.600107, Error: 0.3229\n",
      "  Iteration: 27/35, Loss: 0.637014, Error: 0.3229\n",
      "  Iteration: 28/35, Loss: 0.557438, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.574236, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.539974, Error: 0.1979\n",
      "  Iteration: 31/35, Loss: 0.538067, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.526853, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.563324, Error: 0.3021\n",
      "  Iteration: 34/35, Loss: 0.536556, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.486673, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2557\n",
      "Epoch: 43/100\n",
      "  Iteration: 1/35, Loss: 0.583084, Error: 0.2917\n",
      "  Iteration: 2/35, Loss: 0.567593, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.649431, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.630767, Error: 0.3438\n",
      "  Iteration: 5/35, Loss: 0.646339, Error: 0.3438\n",
      "  Iteration: 6/35, Loss: 0.518286, Error: 0.2083\n",
      "  Iteration: 7/35, Loss: 0.586752, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.62442, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.528027, Error: 0.2083\n",
      "  Iteration: 10/35, Loss: 0.588847, Error: 0.2500\n",
      "  Iteration: 11/35, Loss: 0.561124, Error: 0.2500\n",
      "  Iteration: 12/35, Loss: 0.557916, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.549806, Error: 0.2500\n",
      "  Iteration: 14/35, Loss: 0.584145, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.50232, Error: 0.1979\n",
      "  Iteration: 16/35, Loss: 0.447452, Error: 0.1562\n",
      "  Iteration: 17/35, Loss: 0.45127, Error: 0.1667\n",
      "  Iteration: 18/35, Loss: 0.492275, Error: 0.2083\n",
      "  Iteration: 19/35, Loss: 0.574219, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.599593, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.566638, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.580356, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.476516, Error: 0.1875\n",
      "  Iteration: 24/35, Loss: 0.561377, Error: 0.2917\n",
      "  Iteration: 25/35, Loss: 0.568435, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.628987, Error: 0.3646\n",
      "  Iteration: 27/35, Loss: 0.582228, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.541111, Error: 0.2917\n",
      "  Iteration: 29/35, Loss: 0.564752, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.576126, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.582745, Error: 0.2812\n",
      "  Iteration: 32/35, Loss: 0.49936, Error: 0.2188\n",
      "  Iteration: 33/35, Loss: 0.430626, Error: 0.1875\n",
      "  Iteration: 34/35, Loss: 0.573139, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.469921, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2539\n",
      "Epoch: 44/100\n",
      "  Iteration: 1/35, Loss: 0.562015, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.490756, Error: 0.2188\n",
      "  Iteration: 3/35, Loss: 0.501858, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.501521, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.47639, Error: 0.2083\n",
      "  Iteration: 6/35, Loss: 0.632397, Error: 0.3333\n",
      "  Iteration: 7/35, Loss: 0.631574, Error: 0.3542\n",
      "  Iteration: 8/35, Loss: 0.638009, Error: 0.3438\n",
      "  Iteration: 9/35, Loss: 0.545775, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.60392, Error: 0.2917\n",
      "  Iteration: 11/35, Loss: 0.58598, Error: 0.2812\n",
      "  Iteration: 12/35, Loss: 0.5543, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.568931, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.526201, Error: 0.2188\n",
      "  Iteration: 15/35, Loss: 0.508793, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.617002, Error: 0.3333\n",
      "  Iteration: 17/35, Loss: 0.613476, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.611709, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.580418, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.515392, Error: 0.2188\n",
      "  Iteration: 21/35, Loss: 0.584653, Error: 0.3021\n",
      "  Iteration: 22/35, Loss: 0.555464, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.560168, Error: 0.2708\n",
      "  Iteration: 24/35, Loss: 0.59103, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.545096, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.587085, Error: 0.3021\n",
      "  Iteration: 27/35, Loss: 0.5094, Error: 0.2292\n",
      "  Iteration: 28/35, Loss: 0.562546, Error: 0.2604\n",
      "  Iteration: 29/35, Loss: 0.575803, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.539486, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.521078, Error: 0.2396\n",
      "  Iteration: 32/35, Loss: 0.564798, Error: 0.2708\n",
      "  Iteration: 33/35, Loss: 0.533278, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.500419, Error: 0.1979\n",
      "  Iteration: 35/35, Loss: 0.688304, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2660\n",
      "Epoch: 45/100\n",
      "  Iteration: 1/35, Loss: 0.534945, Error: 0.2188\n",
      "  Iteration: 2/35, Loss: 0.624648, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.517601, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.517811, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.567728, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.545445, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.515804, Error: 0.1875\n",
      "  Iteration: 8/35, Loss: 0.583103, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.601125, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.526543, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.588352, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.563845, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.554342, Error: 0.2708\n",
      "  Iteration: 14/35, Loss: 0.522028, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.53449, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.576035, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.55732, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.578126, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.547508, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.512487, Error: 0.2604\n",
      "  Iteration: 21/35, Loss: 0.53172, Error: 0.2604\n",
      "  Iteration: 22/35, Loss: 0.566738, Error: 0.2917\n",
      "  Iteration: 23/35, Loss: 0.552528, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.526661, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.546804, Error: 0.2188\n",
      "  Iteration: 26/35, Loss: 0.531167, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.569392, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.594652, Error: 0.2917\n",
      "  Iteration: 29/35, Loss: 0.501601, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.545154, Error: 0.2708\n",
      "  Iteration: 31/35, Loss: 0.546007, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.606847, Error: 0.3125\n",
      "  Iteration: 33/35, Loss: 0.56247, Error: 0.2812\n",
      "  Iteration: 34/35, Loss: 0.567048, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.54278, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2557\n",
      "Epoch: 46/100\n",
      "  Iteration: 1/35, Loss: 0.544776, Error: 0.2604\n",
      "  Iteration: 2/35, Loss: 0.55224, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.559677, Error: 0.2708\n",
      "  Iteration: 4/35, Loss: 0.477549, Error: 0.1979\n",
      "  Iteration: 5/35, Loss: 0.569116, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.516789, Error: 0.2292\n",
      "  Iteration: 7/35, Loss: 0.493898, Error: 0.2083\n",
      "  Iteration: 8/35, Loss: 0.605513, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.594393, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.49509, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.583376, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.528111, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.586889, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.622728, Error: 0.3021\n",
      "  Iteration: 15/35, Loss: 0.531312, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.535037, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.611698, Error: 0.3229\n",
      "  Iteration: 18/35, Loss: 0.583241, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.553687, Error: 0.2292\n",
      "  Iteration: 20/35, Loss: 0.550264, Error: 0.2604\n",
      "  Iteration: 21/35, Loss: 0.616329, Error: 0.3333\n",
      "  Iteration: 22/35, Loss: 0.534902, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.550388, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.518059, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.522908, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.561385, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.605775, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.540163, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.513256, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.620604, Error: 0.3125\n",
      "  Iteration: 31/35, Loss: 0.550104, Error: 0.2917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 32/35, Loss: 0.526964, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.673562, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.578097, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.506894, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2601\n",
      "Epoch: 47/100\n",
      "  Iteration: 1/35, Loss: 0.543446, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.592499, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.557923, Error: 0.2708\n",
      "  Iteration: 4/35, Loss: 0.579767, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.563177, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.506941, Error: 0.2083\n",
      "  Iteration: 7/35, Loss: 0.495975, Error: 0.1979\n",
      "  Iteration: 8/35, Loss: 0.516813, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.756399, Error: 0.3438\n",
      "  Iteration: 10/35, Loss: 0.567432, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.603177, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.607632, Error: 0.2708\n",
      "  Iteration: 13/35, Loss: 0.53893, Error: 0.2708\n",
      "  Iteration: 14/35, Loss: 0.612767, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.603894, Error: 0.3125\n",
      "  Iteration: 16/35, Loss: 0.580827, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.592405, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.602701, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.529242, Error: 0.2396\n",
      "  Iteration: 20/35, Loss: 0.660883, Error: 0.3542\n",
      "  Iteration: 21/35, Loss: 0.57737, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.584975, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.515158, Error: 0.1979\n",
      "  Iteration: 24/35, Loss: 0.545066, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.570967, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.631553, Error: 0.3021\n",
      "  Iteration: 27/35, Loss: 0.636106, Error: 0.3125\n",
      "  Iteration: 28/35, Loss: 0.552117, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.4993, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.56817, Error: 0.2708\n",
      "  Iteration: 31/35, Loss: 0.494833, Error: 0.2083\n",
      "  Iteration: 32/35, Loss: 0.473653, Error: 0.1979\n",
      "  Iteration: 33/35, Loss: 0.496353, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.490157, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.572531, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2592\n",
      "Epoch: 48/100\n",
      "  Iteration: 1/35, Loss: 0.659555, Error: 0.2917\n",
      "  Iteration: 2/35, Loss: 0.580366, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.618643, Error: 0.2708\n",
      "  Iteration: 4/35, Loss: 0.547664, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.537069, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.592492, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.574547, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.513114, Error: 0.1979\n",
      "  Iteration: 9/35, Loss: 0.597065, Error: 0.2917\n",
      "  Iteration: 10/35, Loss: 0.582223, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.605944, Error: 0.2812\n",
      "  Iteration: 12/35, Loss: 0.582339, Error: 0.3229\n",
      "  Iteration: 13/35, Loss: 0.550419, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.616501, Error: 0.3333\n",
      "  Iteration: 15/35, Loss: 0.524992, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.600189, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.625408, Error: 0.3229\n",
      "  Iteration: 18/35, Loss: 0.512583, Error: 0.2188\n",
      "  Iteration: 19/35, Loss: 0.539417, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.535759, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.536421, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.498573, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.497842, Error: 0.2083\n",
      "  Iteration: 24/35, Loss: 0.468541, Error: 0.2083\n",
      "  Iteration: 25/35, Loss: 0.521442, Error: 0.2188\n",
      "  Iteration: 26/35, Loss: 0.597436, Error: 0.2812\n",
      "  Iteration: 27/35, Loss: 0.535994, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.5556, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.560549, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.639993, Error: 0.3646\n",
      "  Iteration: 31/35, Loss: 0.552348, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.585803, Error: 0.2708\n",
      "  Iteration: 33/35, Loss: 0.55448, Error: 0.2188\n",
      "  Iteration: 34/35, Loss: 0.556052, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.563738, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2584\n",
      "Epoch: 49/100\n",
      "  Iteration: 1/35, Loss: 0.552333, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.627767, Error: 0.3125\n",
      "  Iteration: 3/35, Loss: 0.465743, Error: 0.1875\n",
      "  Iteration: 4/35, Loss: 0.490913, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.586913, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.605831, Error: 0.2812\n",
      "  Iteration: 7/35, Loss: 0.48889, Error: 0.1875\n",
      "  Iteration: 8/35, Loss: 0.572841, Error: 0.2917\n",
      "  Iteration: 9/35, Loss: 0.559162, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.488725, Error: 0.1771\n",
      "  Iteration: 11/35, Loss: 0.574553, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.504514, Error: 0.1875\n",
      "  Iteration: 13/35, Loss: 0.623972, Error: 0.3333\n",
      "  Iteration: 14/35, Loss: 0.640169, Error: 0.3333\n",
      "  Iteration: 15/35, Loss: 0.635472, Error: 0.3438\n",
      "  Iteration: 16/35, Loss: 0.471942, Error: 0.1771\n",
      "  Iteration: 17/35, Loss: 0.51567, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.689572, Error: 0.4062\n",
      "  Iteration: 19/35, Loss: 0.546912, Error: 0.2188\n",
      "  Iteration: 20/35, Loss: 0.54169, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.613744, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.529331, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.614905, Error: 0.3021\n",
      "  Iteration: 24/35, Loss: 0.591308, Error: 0.3125\n",
      "  Iteration: 25/35, Loss: 0.566513, Error: 0.2917\n",
      "  Iteration: 26/35, Loss: 0.548985, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.565772, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.543053, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.562971, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.467785, Error: 0.1875\n",
      "  Iteration: 31/35, Loss: 0.525271, Error: 0.2188\n",
      "  Iteration: 32/35, Loss: 0.502796, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.570667, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.635821, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.445529, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2575\n",
      "Epoch: 50/100\n",
      "  Iteration: 1/35, Loss: 0.578456, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.540823, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.531258, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.587849, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.570539, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.55011, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.547034, Error: 0.2917\n",
      "  Iteration: 8/35, Loss: 0.676978, Error: 0.3750\n",
      "  Iteration: 9/35, Loss: 0.600477, Error: 0.3229\n",
      "  Iteration: 10/35, Loss: 0.562749, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.605282, Error: 0.3125\n",
      "  Iteration: 12/35, Loss: 0.549261, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.537397, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.55855, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.499558, Error: 0.2188\n",
      "  Iteration: 16/35, Loss: 0.540158, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.513942, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.622671, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.575951, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.496256, Error: 0.2188\n",
      "  Iteration: 21/35, Loss: 0.483867, Error: 0.1771\n",
      "  Iteration: 22/35, Loss: 0.506295, Error: 0.2188\n",
      "  Iteration: 23/35, Loss: 0.640481, Error: 0.3229\n",
      "  Iteration: 24/35, Loss: 0.541747, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.502304, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.541904, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.561913, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.528675, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.502947, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.606072, Error: 0.3125\n",
      "  Iteration: 31/35, Loss: 0.594381, Error: 0.3021\n",
      "  Iteration: 32/35, Loss: 0.578619, Error: 0.2917\n",
      "  Iteration: 33/35, Loss: 0.558719, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.493821, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.678504, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2607\n",
      "Epoch: 51/100\n",
      "  Iteration: 1/35, Loss: 0.586314, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.615159, Error: 0.3021\n",
      "  Iteration: 3/35, Loss: 0.551632, Error: 0.2396\n",
      "  Iteration: 4/35, Loss: 0.627327, Error: 0.3542\n",
      "  Iteration: 5/35, Loss: 0.565192, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.539072, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.574377, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.595908, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.59932, Error: 0.3125\n",
      "  Iteration: 10/35, Loss: 0.559764, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.490129, Error: 0.2083\n",
      "  Iteration: 12/35, Loss: 0.566582, Error: 0.2917\n",
      "  Iteration: 13/35, Loss: 0.472309, Error: 0.1771\n",
      "  Iteration: 14/35, Loss: 0.593221, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.509423, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.557056, Error: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 17/35, Loss: 0.486466, Error: 0.2083\n",
      "  Iteration: 18/35, Loss: 0.565432, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.592439, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.492855, Error: 0.2083\n",
      "  Iteration: 21/35, Loss: 0.511718, Error: 0.2188\n",
      "  Iteration: 22/35, Loss: 0.563374, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.517604, Error: 0.2188\n",
      "  Iteration: 24/35, Loss: 0.615959, Error: 0.3229\n",
      "  Iteration: 25/35, Loss: 0.562799, Error: 0.2604\n",
      "  Iteration: 26/35, Loss: 0.518509, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.521492, Error: 0.2188\n",
      "  Iteration: 28/35, Loss: 0.516756, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.528549, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.716653, Error: 0.3750\n",
      "  Iteration: 31/35, Loss: 0.494466, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.582262, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.539077, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.518976, Error: 0.2083\n",
      "  Iteration: 35/35, Loss: 0.450858, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2543\n",
      "Epoch: 52/100\n",
      "  Iteration: 1/35, Loss: 0.518973, Error: 0.1979\n",
      "  Iteration: 2/35, Loss: 0.52915, Error: 0.2292\n",
      "  Iteration: 3/35, Loss: 0.536404, Error: 0.2708\n",
      "  Iteration: 4/35, Loss: 0.570519, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.630946, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.46935, Error: 0.2083\n",
      "  Iteration: 7/35, Loss: 0.516053, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.555697, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.607042, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.543201, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.47036, Error: 0.1979\n",
      "  Iteration: 12/35, Loss: 0.497487, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.584602, Error: 0.3021\n",
      "  Iteration: 14/35, Loss: 0.632438, Error: 0.3125\n",
      "  Iteration: 15/35, Loss: 0.51772, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.585128, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.597747, Error: 0.3229\n",
      "  Iteration: 18/35, Loss: 0.56052, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.611278, Error: 0.3438\n",
      "  Iteration: 20/35, Loss: 0.558721, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.571091, Error: 0.2708\n",
      "  Iteration: 22/35, Loss: 0.542067, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.572305, Error: 0.2708\n",
      "  Iteration: 24/35, Loss: 0.551258, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.534701, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.510061, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.621533, Error: 0.3021\n",
      "  Iteration: 28/35, Loss: 0.505989, Error: 0.1979\n",
      "  Iteration: 29/35, Loss: 0.530022, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.646905, Error: 0.3125\n",
      "  Iteration: 31/35, Loss: 0.53203, Error: 0.2396\n",
      "  Iteration: 32/35, Loss: 0.586344, Error: 0.2917\n",
      "  Iteration: 33/35, Loss: 0.517475, Error: 0.2083\n",
      "  Iteration: 34/35, Loss: 0.501361, Error: 0.1979\n",
      "  Iteration: 35/35, Loss: 0.609853, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2568\n",
      "Epoch: 53/100\n",
      "  Iteration: 1/35, Loss: 0.602119, Error: 0.3229\n",
      "  Iteration: 2/35, Loss: 0.578071, Error: 0.2604\n",
      "  Iteration: 3/35, Loss: 0.598002, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.507676, Error: 0.1875\n",
      "  Iteration: 5/35, Loss: 0.537769, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.592827, Error: 0.2917\n",
      "  Iteration: 7/35, Loss: 0.587045, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.535081, Error: 0.2292\n",
      "  Iteration: 9/35, Loss: 0.587309, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.574721, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.568147, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.558692, Error: 0.2708\n",
      "  Iteration: 13/35, Loss: 0.529009, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.576568, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.531775, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.630373, Error: 0.3333\n",
      "  Iteration: 17/35, Loss: 0.613448, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.545309, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.592439, Error: 0.3229\n",
      "  Iteration: 20/35, Loss: 0.557138, Error: 0.2604\n",
      "  Iteration: 21/35, Loss: 0.581337, Error: 0.2708\n",
      "  Iteration: 22/35, Loss: 0.548472, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.496588, Error: 0.2083\n",
      "  Iteration: 24/35, Loss: 0.522941, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.524747, Error: 0.2188\n",
      "  Iteration: 26/35, Loss: 0.55204, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.540193, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.522289, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.513197, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.564987, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.524952, Error: 0.2708\n",
      "  Iteration: 32/35, Loss: 0.48309, Error: 0.2188\n",
      "  Iteration: 33/35, Loss: 0.567102, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.520739, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.466103, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2543\n",
      "Epoch: 54/100\n",
      "  Iteration: 1/35, Loss: 0.610191, Error: 0.3229\n",
      "  Iteration: 2/35, Loss: 0.595365, Error: 0.3229\n",
      "  Iteration: 3/35, Loss: 0.580431, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.513026, Error: 0.2292\n",
      "  Iteration: 5/35, Loss: 0.592796, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.539874, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.512515, Error: 0.2292\n",
      "  Iteration: 8/35, Loss: 0.50975, Error: 0.2292\n",
      "  Iteration: 9/35, Loss: 0.52762, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.498505, Error: 0.1875\n",
      "  Iteration: 11/35, Loss: 0.640542, Error: 0.3333\n",
      "  Iteration: 12/35, Loss: 0.534532, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.5469, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.448581, Error: 0.1771\n",
      "  Iteration: 15/35, Loss: 0.57233, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.538652, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.622149, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.594753, Error: 0.3021\n",
      "  Iteration: 19/35, Loss: 0.478842, Error: 0.2188\n",
      "  Iteration: 20/35, Loss: 0.589177, Error: 0.2812\n",
      "  Iteration: 21/35, Loss: 0.551082, Error: 0.2500\n",
      "  Iteration: 22/35, Loss: 0.546165, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.553835, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.579457, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.565684, Error: 0.3021\n",
      "  Iteration: 26/35, Loss: 0.65753, Error: 0.3333\n",
      "  Iteration: 27/35, Loss: 0.480783, Error: 0.1875\n",
      "  Iteration: 28/35, Loss: 0.524122, Error: 0.2083\n",
      "  Iteration: 29/35, Loss: 0.53246, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.577202, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.455973, Error: 0.1667\n",
      "  Iteration: 32/35, Loss: 0.490001, Error: 0.2083\n",
      "  Iteration: 33/35, Loss: 0.547497, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.65021, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.611317, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2539\n",
      "Epoch: 55/100\n",
      "  Iteration: 1/35, Loss: 0.521745, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.507034, Error: 0.2083\n",
      "  Iteration: 3/35, Loss: 0.557665, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.542781, Error: 0.2500\n",
      "  Iteration: 5/35, Loss: 0.544971, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.672056, Error: 0.3646\n",
      "  Iteration: 7/35, Loss: 0.561292, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.568537, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.568028, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.610201, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.548859, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.526036, Error: 0.1979\n",
      "  Iteration: 13/35, Loss: 0.608601, Error: 0.3125\n",
      "  Iteration: 14/35, Loss: 0.519525, Error: 0.2292\n",
      "  Iteration: 15/35, Loss: 0.519279, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.551569, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.533683, Error: 0.2500\n",
      "  Iteration: 18/35, Loss: 0.569589, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.501381, Error: 0.2188\n",
      "  Iteration: 20/35, Loss: 0.529993, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.588398, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.554675, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.451111, Error: 0.1771\n",
      "  Iteration: 24/35, Loss: 0.624727, Error: 0.3333\n",
      "  Iteration: 25/35, Loss: 0.65545, Error: 0.3542\n",
      "  Iteration: 26/35, Loss: 0.498172, Error: 0.2396\n",
      "  Iteration: 27/35, Loss: 0.493327, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.542695, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.533277, Error: 0.2396\n",
      "  Iteration: 30/35, Loss: 0.633223, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.485703, Error: 0.2083\n",
      "  Iteration: 32/35, Loss: 0.574348, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.570342, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.494532, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.484057, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2528\n",
      "found a better model!\n",
      "Epoch: 56/100\n",
      "  Iteration: 1/35, Loss: 0.529622, Error: 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 2/35, Loss: 0.525608, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.579814, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.574117, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.483673, Error: 0.2083\n",
      "  Iteration: 6/35, Loss: 0.689714, Error: 0.3125\n",
      "  Iteration: 7/35, Loss: 0.524121, Error: 0.2188\n",
      "  Iteration: 8/35, Loss: 0.511975, Error: 0.2188\n",
      "  Iteration: 9/35, Loss: 0.557202, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.530231, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.539812, Error: 0.2500\n",
      "  Iteration: 12/35, Loss: 0.527198, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.588114, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.593118, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.577545, Error: 0.2604\n",
      "  Iteration: 16/35, Loss: 0.665035, Error: 0.3646\n",
      "  Iteration: 17/35, Loss: 0.498636, Error: 0.2188\n",
      "  Iteration: 18/35, Loss: 0.59386, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.570355, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.5634, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.587247, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.587126, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.566603, Error: 0.2917\n",
      "  Iteration: 24/35, Loss: 0.543139, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.506778, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.495593, Error: 0.2083\n",
      "  Iteration: 27/35, Loss: 0.541307, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.548115, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.523822, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.523504, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.512564, Error: 0.2396\n",
      "  Iteration: 32/35, Loss: 0.550615, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.50739, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.522249, Error: 0.2083\n",
      "  Iteration: 35/35, Loss: 0.780715, Error: 0.5000\n",
      "Average Error for this Epoch: 0.2610\n",
      "Epoch: 57/100\n",
      "  Iteration: 1/35, Loss: 0.4651, Error: 0.1667\n",
      "  Iteration: 2/35, Loss: 0.58854, Error: 0.2708\n",
      "  Iteration: 3/35, Loss: 0.578129, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.542662, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.537033, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.563002, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.475906, Error: 0.1979\n",
      "  Iteration: 8/35, Loss: 0.539734, Error: 0.2292\n",
      "  Iteration: 9/35, Loss: 0.460829, Error: 0.1979\n",
      "  Iteration: 10/35, Loss: 0.570036, Error: 0.2917\n",
      "  Iteration: 11/35, Loss: 0.627985, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.521361, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.526047, Error: 0.2292\n",
      "  Iteration: 14/35, Loss: 0.550584, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.470969, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.610743, Error: 0.3125\n",
      "  Iteration: 17/35, Loss: 0.579867, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.477465, Error: 0.1875\n",
      "  Iteration: 19/35, Loss: 0.568263, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.60412, Error: 0.3438\n",
      "  Iteration: 21/35, Loss: 0.598269, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.550084, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.610012, Error: 0.3229\n",
      "  Iteration: 24/35, Loss: 0.594207, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.541611, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.592805, Error: 0.3333\n",
      "  Iteration: 27/35, Loss: 0.560896, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.594045, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.534304, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.572383, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.542154, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.520855, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.66554, Error: 0.3333\n",
      "  Iteration: 34/35, Loss: 0.590603, Error: 0.2812\n",
      "  Iteration: 35/35, Loss: 0.855106, Error: 0.4500\n",
      "Average Error for this Epoch: 0.2685\n",
      "Epoch: 58/100\n",
      "  Iteration: 1/35, Loss: 0.559119, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.488317, Error: 0.1875\n",
      "  Iteration: 3/35, Loss: 0.553693, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.561794, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.557603, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.543283, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.585195, Error: 0.3021\n",
      "  Iteration: 8/35, Loss: 0.607813, Error: 0.3229\n",
      "  Iteration: 9/35, Loss: 0.523929, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.484799, Error: 0.1875\n",
      "  Iteration: 11/35, Loss: 0.569878, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.561312, Error: 0.2396\n",
      "  Iteration: 13/35, Loss: 0.523411, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.551806, Error: 0.2604\n",
      "  Iteration: 15/35, Loss: 0.611521, Error: 0.3021\n",
      "  Iteration: 16/35, Loss: 0.573348, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.567249, Error: 0.2500\n",
      "  Iteration: 18/35, Loss: 0.588621, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.580511, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.571035, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.578062, Error: 0.2708\n",
      "  Iteration: 22/35, Loss: 0.546025, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.571896, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.572247, Error: 0.2917\n",
      "  Iteration: 25/35, Loss: 0.522975, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.576976, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.546918, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.53414, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.519121, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.546746, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.493011, Error: 0.1979\n",
      "  Iteration: 32/35, Loss: 0.576984, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.634955, Error: 0.3125\n",
      "  Iteration: 34/35, Loss: 0.557121, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.751404, Error: 0.4000\n",
      "Average Error for this Epoch: 0.2605\n",
      "Epoch: 59/100\n",
      "  Iteration: 1/35, Loss: 0.528001, Error: 0.2083\n",
      "  Iteration: 2/35, Loss: 0.525582, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.562184, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.561931, Error: 0.2292\n",
      "  Iteration: 5/35, Loss: 0.574608, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.555642, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.557289, Error: 0.2292\n",
      "  Iteration: 8/35, Loss: 0.596263, Error: 0.2917\n",
      "  Iteration: 9/35, Loss: 0.502065, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.527155, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.528846, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.520153, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.557319, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.550063, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.636593, Error: 0.3333\n",
      "  Iteration: 16/35, Loss: 0.607226, Error: 0.3021\n",
      "  Iteration: 17/35, Loss: 0.54504, Error: 0.2188\n",
      "  Iteration: 18/35, Loss: 0.661977, Error: 0.3646\n",
      "  Iteration: 19/35, Loss: 0.485622, Error: 0.1667\n",
      "  Iteration: 20/35, Loss: 0.510217, Error: 0.1979\n",
      "  Iteration: 21/35, Loss: 0.629716, Error: 0.3229\n",
      "  Iteration: 22/35, Loss: 0.495571, Error: 0.1875\n",
      "  Iteration: 23/35, Loss: 0.521653, Error: 0.2292\n",
      "  Iteration: 24/35, Loss: 0.576472, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.502904, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.499083, Error: 0.1979\n",
      "  Iteration: 27/35, Loss: 0.559655, Error: 0.2292\n",
      "  Iteration: 28/35, Loss: 0.552764, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.660309, Error: 0.3333\n",
      "  Iteration: 30/35, Loss: 0.508743, Error: 0.2188\n",
      "  Iteration: 31/35, Loss: 0.587547, Error: 0.2917\n",
      "  Iteration: 32/35, Loss: 0.632362, Error: 0.3229\n",
      "  Iteration: 33/35, Loss: 0.575164, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.569437, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.750613, Error: 0.4500\n",
      "Average Error for this Epoch: 0.2590\n",
      "Epoch: 60/100\n",
      "  Iteration: 1/35, Loss: 0.575725, Error: 0.2917\n",
      "  Iteration: 2/35, Loss: 0.627362, Error: 0.3229\n",
      "  Iteration: 3/35, Loss: 0.555667, Error: 0.2292\n",
      "  Iteration: 4/35, Loss: 0.562763, Error: 0.1979\n",
      "  Iteration: 5/35, Loss: 0.554509, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.531085, Error: 0.1979\n",
      "  Iteration: 7/35, Loss: 0.578866, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.610972, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.558427, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.510697, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.632092, Error: 0.3333\n",
      "  Iteration: 12/35, Loss: 0.55514, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.605533, Error: 0.3229\n",
      "  Iteration: 14/35, Loss: 0.602837, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.55629, Error: 0.2708\n",
      "  Iteration: 16/35, Loss: 0.531893, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.463171, Error: 0.1875\n",
      "  Iteration: 18/35, Loss: 0.587499, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.47866, Error: 0.1979\n",
      "  Iteration: 20/35, Loss: 0.52138, Error: 0.2188\n",
      "  Iteration: 21/35, Loss: 0.490645, Error: 0.1979\n",
      "  Iteration: 22/35, Loss: 0.572591, Error: 0.2604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 23/35, Loss: 0.577587, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.568727, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.669554, Error: 0.3646\n",
      "  Iteration: 26/35, Loss: 0.537163, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.520682, Error: 0.2292\n",
      "  Iteration: 28/35, Loss: 0.555063, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.493498, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.544029, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.548641, Error: 0.2188\n",
      "  Iteration: 32/35, Loss: 0.529068, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.594188, Error: 0.2917\n",
      "  Iteration: 34/35, Loss: 0.528746, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.550859, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2560\n",
      "Epoch: 61/100\n",
      "  Iteration: 1/35, Loss: 0.563378, Error: 0.2917\n",
      "  Iteration: 2/35, Loss: 0.462591, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.54313, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.531984, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.543579, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.57998, Error: 0.2812\n",
      "  Iteration: 7/35, Loss: 0.578943, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.475715, Error: 0.2188\n",
      "  Iteration: 9/35, Loss: 0.521049, Error: 0.2188\n",
      "  Iteration: 10/35, Loss: 0.501359, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.612964, Error: 0.3021\n",
      "  Iteration: 12/35, Loss: 0.482565, Error: 0.1979\n",
      "  Iteration: 13/35, Loss: 0.503991, Error: 0.1875\n",
      "  Iteration: 14/35, Loss: 0.504456, Error: 0.2188\n",
      "  Iteration: 15/35, Loss: 0.539466, Error: 0.2708\n",
      "  Iteration: 16/35, Loss: 0.66873, Error: 0.3229\n",
      "  Iteration: 17/35, Loss: 0.505351, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.531677, Error: 0.2188\n",
      "  Iteration: 19/35, Loss: 0.541824, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.585909, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.61386, Error: 0.3021\n",
      "  Iteration: 22/35, Loss: 0.543845, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.544733, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.575151, Error: 0.2812\n",
      "  Iteration: 25/35, Loss: 0.586428, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.536569, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.529306, Error: 0.2083\n",
      "  Iteration: 28/35, Loss: 0.577594, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.609639, Error: 0.3438\n",
      "  Iteration: 30/35, Loss: 0.597881, Error: 0.3021\n",
      "  Iteration: 31/35, Loss: 0.601511, Error: 0.3125\n",
      "  Iteration: 32/35, Loss: 0.502743, Error: 0.1771\n",
      "  Iteration: 33/35, Loss: 0.58481, Error: 0.3229\n",
      "  Iteration: 34/35, Loss: 0.552341, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.675582, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2586\n",
      "Epoch: 62/100\n",
      "  Iteration: 1/35, Loss: 0.520763, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.471441, Error: 0.1771\n",
      "  Iteration: 3/35, Loss: 0.607922, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.521817, Error: 0.2292\n",
      "  Iteration: 5/35, Loss: 0.559659, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.553151, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.545291, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.54102, Error: 0.2188\n",
      "  Iteration: 9/35, Loss: 0.523574, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.573399, Error: 0.2812\n",
      "  Iteration: 11/35, Loss: 0.626028, Error: 0.3021\n",
      "  Iteration: 12/35, Loss: 0.548769, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.530464, Error: 0.2500\n",
      "  Iteration: 14/35, Loss: 0.460912, Error: 0.1771\n",
      "  Iteration: 15/35, Loss: 0.529604, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.575012, Error: 0.2917\n",
      "  Iteration: 17/35, Loss: 0.617458, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.63036, Error: 0.3125\n",
      "  Iteration: 19/35, Loss: 0.526215, Error: 0.2292\n",
      "  Iteration: 20/35, Loss: 0.519048, Error: 0.2083\n",
      "  Iteration: 21/35, Loss: 0.548435, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.548978, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.573218, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.512043, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.510654, Error: 0.2188\n",
      "  Iteration: 26/35, Loss: 0.50509, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.513514, Error: 0.2292\n",
      "  Iteration: 28/35, Loss: 0.613506, Error: 0.2917\n",
      "  Iteration: 29/35, Loss: 0.583771, Error: 0.2812\n",
      "  Iteration: 30/35, Loss: 0.597862, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.654805, Error: 0.3438\n",
      "  Iteration: 32/35, Loss: 0.55123, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.578875, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.50122, Error: 0.1979\n",
      "  Iteration: 35/35, Loss: 0.542839, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2527\n",
      "found a better model!\n",
      "Epoch: 63/100\n",
      "  Iteration: 1/35, Loss: 0.520553, Error: 0.2083\n",
      "  Iteration: 2/35, Loss: 0.513337, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.622297, Error: 0.3229\n",
      "  Iteration: 4/35, Loss: 0.588881, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.510241, Error: 0.1979\n",
      "  Iteration: 6/35, Loss: 0.528081, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.508093, Error: 0.2188\n",
      "  Iteration: 8/35, Loss: 0.549333, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.563549, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.528724, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.638131, Error: 0.3333\n",
      "  Iteration: 12/35, Loss: 0.538183, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.466517, Error: 0.1875\n",
      "  Iteration: 14/35, Loss: 0.52204, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.510536, Error: 0.2188\n",
      "  Iteration: 16/35, Loss: 0.526094, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.659874, Error: 0.3229\n",
      "  Iteration: 18/35, Loss: 0.508492, Error: 0.2083\n",
      "  Iteration: 19/35, Loss: 0.428042, Error: 0.1458\n",
      "  Iteration: 20/35, Loss: 0.600536, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.651045, Error: 0.3438\n",
      "  Iteration: 22/35, Loss: 0.550724, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.555041, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.469886, Error: 0.1979\n",
      "  Iteration: 25/35, Loss: 0.601833, Error: 0.2917\n",
      "  Iteration: 26/35, Loss: 0.612655, Error: 0.3229\n",
      "  Iteration: 27/35, Loss: 0.549687, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.589967, Error: 0.3021\n",
      "  Iteration: 29/35, Loss: 0.57501, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.586994, Error: 0.3229\n",
      "  Iteration: 31/35, Loss: 0.510712, Error: 0.2083\n",
      "  Iteration: 32/35, Loss: 0.651087, Error: 0.3750\n",
      "  Iteration: 33/35, Loss: 0.591292, Error: 0.2812\n",
      "  Iteration: 34/35, Loss: 0.562641, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.421136, Error: 0.1000\n",
      "Average Error for this Epoch: 0.2537\n",
      "Epoch: 64/100\n",
      "  Iteration: 1/35, Loss: 0.542036, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.552194, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.556165, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.535836, Error: 0.2500\n",
      "  Iteration: 5/35, Loss: 0.424656, Error: 0.1667\n",
      "  Iteration: 6/35, Loss: 0.60643, Error: 0.3438\n",
      "  Iteration: 7/35, Loss: 0.562121, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.412258, Error: 0.1354\n",
      "  Iteration: 9/35, Loss: 0.573891, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.575397, Error: 0.2500\n",
      "  Iteration: 11/35, Loss: 0.526864, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.499322, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.631836, Error: 0.3333\n",
      "  Iteration: 14/35, Loss: 0.610903, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.539264, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.542773, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.481493, Error: 0.2083\n",
      "  Iteration: 18/35, Loss: 0.575016, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.500542, Error: 0.2083\n",
      "  Iteration: 20/35, Loss: 0.671076, Error: 0.3542\n",
      "  Iteration: 21/35, Loss: 0.48976, Error: 0.2083\n",
      "  Iteration: 22/35, Loss: 0.606693, Error: 0.3125\n",
      "  Iteration: 23/35, Loss: 0.565595, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.608216, Error: 0.3021\n",
      "  Iteration: 25/35, Loss: 0.573523, Error: 0.2917\n",
      "  Iteration: 26/35, Loss: 0.510217, Error: 0.2083\n",
      "  Iteration: 27/35, Loss: 0.624369, Error: 0.3229\n",
      "  Iteration: 28/35, Loss: 0.567635, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.565926, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.505599, Error: 0.1875\n",
      "  Iteration: 31/35, Loss: 0.523175, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.602513, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.575223, Error: 0.2917\n",
      "  Iteration: 34/35, Loss: 0.48774, Error: 0.2083\n",
      "  Iteration: 35/35, Loss: 0.61905, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2588\n",
      "Epoch: 65/100\n",
      "  Iteration: 1/35, Loss: 0.542655, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.456787, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.546179, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.61011, Error: 0.3229\n",
      "  Iteration: 5/35, Loss: 0.522672, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.529626, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.56753, Error: 0.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 8/35, Loss: 0.595083, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.548947, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.494819, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.595079, Error: 0.2812\n",
      "  Iteration: 12/35, Loss: 0.604477, Error: 0.3125\n",
      "  Iteration: 13/35, Loss: 0.502862, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.549482, Error: 0.2604\n",
      "  Iteration: 15/35, Loss: 0.519479, Error: 0.1979\n",
      "  Iteration: 16/35, Loss: 0.553357, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.510129, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.502644, Error: 0.2396\n",
      "  Iteration: 19/35, Loss: 0.585564, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.543138, Error: 0.2604\n",
      "  Iteration: 21/35, Loss: 0.521488, Error: 0.2292\n",
      "  Iteration: 22/35, Loss: 0.492719, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.505126, Error: 0.2188\n",
      "  Iteration: 24/35, Loss: 0.569655, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.529357, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.681955, Error: 0.3750\n",
      "  Iteration: 27/35, Loss: 0.56362, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.501963, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.548676, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.646498, Error: 0.3229\n",
      "  Iteration: 31/35, Loss: 0.531114, Error: 0.2188\n",
      "  Iteration: 32/35, Loss: 0.619881, Error: 0.3125\n",
      "  Iteration: 33/35, Loss: 0.514825, Error: 0.2083\n",
      "  Iteration: 34/35, Loss: 0.619389, Error: 0.3229\n",
      "  Iteration: 35/35, Loss: 0.43141, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2537\n",
      "Epoch: 66/100\n",
      "  Iteration: 1/35, Loss: 0.59293, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.662615, Error: 0.3646\n",
      "  Iteration: 3/35, Loss: 0.51911, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.51257, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.610321, Error: 0.3333\n",
      "  Iteration: 6/35, Loss: 0.5993, Error: 0.3229\n",
      "  Iteration: 7/35, Loss: 0.559038, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.583338, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.425252, Error: 0.1250\n",
      "  Iteration: 10/35, Loss: 0.58846, Error: 0.2917\n",
      "  Iteration: 11/35, Loss: 0.635055, Error: 0.3333\n",
      "  Iteration: 12/35, Loss: 0.484189, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.520249, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.576107, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.506159, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.607566, Error: 0.3125\n",
      "  Iteration: 17/35, Loss: 0.510847, Error: 0.2500\n",
      "  Iteration: 18/35, Loss: 0.526868, Error: 0.2396\n",
      "  Iteration: 19/35, Loss: 0.518567, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.5255, Error: 0.2083\n",
      "  Iteration: 21/35, Loss: 0.622655, Error: 0.2917\n",
      "  Iteration: 22/35, Loss: 0.51776, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.49617, Error: 0.1771\n",
      "  Iteration: 24/35, Loss: 0.641953, Error: 0.3646\n",
      "  Iteration: 25/35, Loss: 0.515059, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.543354, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.555043, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.517737, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.581686, Error: 0.2708\n",
      "  Iteration: 30/35, Loss: 0.577681, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.525729, Error: 0.2188\n",
      "  Iteration: 32/35, Loss: 0.552118, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.478197, Error: 0.1875\n",
      "  Iteration: 34/35, Loss: 0.512682, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.753258, Error: 0.4000\n",
      "Average Error for this Epoch: 0.2570\n",
      "Epoch: 67/100\n",
      "  Iteration: 1/35, Loss: 0.547522, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.606434, Error: 0.3021\n",
      "  Iteration: 3/35, Loss: 0.613559, Error: 0.3229\n",
      "  Iteration: 4/35, Loss: 0.609157, Error: 0.3125\n",
      "  Iteration: 5/35, Loss: 0.608896, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.586746, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.604858, Error: 0.3021\n",
      "  Iteration: 8/35, Loss: 0.611254, Error: 0.3542\n",
      "  Iteration: 9/35, Loss: 0.544431, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.540559, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.577357, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.56494, Error: 0.2812\n",
      "  Iteration: 13/35, Loss: 0.574387, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.572963, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.601831, Error: 0.3021\n",
      "  Iteration: 16/35, Loss: 0.580615, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.540212, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.460969, Error: 0.1667\n",
      "  Iteration: 19/35, Loss: 0.508633, Error: 0.2188\n",
      "  Iteration: 20/35, Loss: 0.524564, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.480899, Error: 0.1979\n",
      "  Iteration: 22/35, Loss: 0.555608, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.455021, Error: 0.1667\n",
      "  Iteration: 24/35, Loss: 0.458697, Error: 0.1875\n",
      "  Iteration: 25/35, Loss: 0.632434, Error: 0.2917\n",
      "  Iteration: 26/35, Loss: 0.6064, Error: 0.3021\n",
      "  Iteration: 27/35, Loss: 0.603487, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.526615, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.492658, Error: 0.1979\n",
      "  Iteration: 30/35, Loss: 0.555253, Error: 0.2292\n",
      "  Iteration: 31/35, Loss: 0.450964, Error: 0.1458\n",
      "  Iteration: 32/35, Loss: 0.460341, Error: 0.1771\n",
      "  Iteration: 33/35, Loss: 0.571807, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.522834, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.54142, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2542\n",
      "Epoch: 68/100\n",
      "  Iteration: 1/35, Loss: 0.601058, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.489331, Error: 0.2188\n",
      "  Iteration: 3/35, Loss: 0.54303, Error: 0.2396\n",
      "  Iteration: 4/35, Loss: 0.486355, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.507822, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.577034, Error: 0.2917\n",
      "  Iteration: 7/35, Loss: 0.551099, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.633906, Error: 0.3333\n",
      "  Iteration: 9/35, Loss: 0.465324, Error: 0.1979\n",
      "  Iteration: 10/35, Loss: 0.592084, Error: 0.3229\n",
      "  Iteration: 11/35, Loss: 0.54906, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.561735, Error: 0.2604\n",
      "  Iteration: 13/35, Loss: 0.601193, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.537635, Error: 0.2292\n",
      "  Iteration: 15/35, Loss: 0.507919, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.485691, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.584163, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.472389, Error: 0.1875\n",
      "  Iteration: 19/35, Loss: 0.59266, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.555062, Error: 0.2812\n",
      "  Iteration: 21/35, Loss: 0.47565, Error: 0.1875\n",
      "  Iteration: 22/35, Loss: 0.574721, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.603616, Error: 0.2917\n",
      "  Iteration: 24/35, Loss: 0.588411, Error: 0.3021\n",
      "  Iteration: 25/35, Loss: 0.616637, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.533317, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.551835, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.524452, Error: 0.2604\n",
      "  Iteration: 29/35, Loss: 0.535344, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.584784, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.494459, Error: 0.1979\n",
      "  Iteration: 32/35, Loss: 0.517925, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.595172, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.600686, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.632298, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2591\n",
      "Epoch: 69/100\n",
      "  Iteration: 1/35, Loss: 0.548289, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.458234, Error: 0.1562\n",
      "  Iteration: 3/35, Loss: 0.600579, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.52808, Error: 0.2396\n",
      "  Iteration: 5/35, Loss: 0.550481, Error: 0.2812\n",
      "  Iteration: 6/35, Loss: 0.509702, Error: 0.2188\n",
      "  Iteration: 7/35, Loss: 0.550462, Error: 0.2604\n",
      "  Iteration: 8/35, Loss: 0.52403, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.579021, Error: 0.2812\n",
      "  Iteration: 10/35, Loss: 0.47715, Error: 0.2083\n",
      "  Iteration: 11/35, Loss: 0.550423, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.535511, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.567329, Error: 0.3021\n",
      "  Iteration: 14/35, Loss: 0.607934, Error: 0.3125\n",
      "  Iteration: 15/35, Loss: 0.516093, Error: 0.2708\n",
      "  Iteration: 16/35, Loss: 0.588483, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.526928, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.575543, Error: 0.3125\n",
      "  Iteration: 19/35, Loss: 0.585759, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.650364, Error: 0.3438\n",
      "  Iteration: 21/35, Loss: 0.566898, Error: 0.2500\n",
      "  Iteration: 22/35, Loss: 0.616931, Error: 0.3021\n",
      "  Iteration: 23/35, Loss: 0.593991, Error: 0.2708\n",
      "  Iteration: 24/35, Loss: 0.55763, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.575853, Error: 0.2604\n",
      "  Iteration: 26/35, Loss: 0.561658, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.56618, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.467163, Error: 0.1979\n",
      "  Iteration: 29/35, Loss: 0.501701, Error: 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 30/35, Loss: 0.576348, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.595683, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.539106, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.553698, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.512794, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.595424, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2610\n",
      "Epoch: 70/100\n",
      "  Iteration: 1/35, Loss: 0.564728, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.61655, Error: 0.3021\n",
      "  Iteration: 3/35, Loss: 0.613005, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.564089, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.57367, Error: 0.2812\n",
      "  Iteration: 6/35, Loss: 0.534608, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.559818, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.583146, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.541077, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.475032, Error: 0.2083\n",
      "  Iteration: 11/35, Loss: 0.525478, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.575819, Error: 0.2604\n",
      "  Iteration: 13/35, Loss: 0.507409, Error: 0.2292\n",
      "  Iteration: 14/35, Loss: 0.550728, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.558856, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.543249, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.439602, Error: 0.1562\n",
      "  Iteration: 18/35, Loss: 0.529823, Error: 0.2396\n",
      "  Iteration: 19/35, Loss: 0.618423, Error: 0.3438\n",
      "  Iteration: 20/35, Loss: 0.566185, Error: 0.2812\n",
      "  Iteration: 21/35, Loss: 0.582416, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.57166, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.513349, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.554267, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.536338, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.603927, Error: 0.3229\n",
      "  Iteration: 27/35, Loss: 0.576451, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.492225, Error: 0.2083\n",
      "  Iteration: 29/35, Loss: 0.57209, Error: 0.2708\n",
      "  Iteration: 30/35, Loss: 0.658835, Error: 0.3333\n",
      "  Iteration: 31/35, Loss: 0.485798, Error: 0.1979\n",
      "  Iteration: 32/35, Loss: 0.536869, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.519335, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.553857, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.425631, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2572\n",
      "Epoch: 71/100\n",
      "  Iteration: 1/35, Loss: 0.536778, Error: 0.2188\n",
      "  Iteration: 2/35, Loss: 0.504974, Error: 0.2083\n",
      "  Iteration: 3/35, Loss: 0.465587, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.599984, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.562949, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.452856, Error: 0.1458\n",
      "  Iteration: 7/35, Loss: 0.645489, Error: 0.3125\n",
      "  Iteration: 8/35, Loss: 0.616589, Error: 0.3229\n",
      "  Iteration: 9/35, Loss: 0.598427, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.552107, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.501963, Error: 0.1875\n",
      "  Iteration: 12/35, Loss: 0.536622, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.510028, Error: 0.1979\n",
      "  Iteration: 14/35, Loss: 0.594486, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.546462, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.491719, Error: 0.2188\n",
      "  Iteration: 17/35, Loss: 0.660293, Error: 0.3125\n",
      "  Iteration: 18/35, Loss: 0.510676, Error: 0.2083\n",
      "  Iteration: 19/35, Loss: 0.661326, Error: 0.3646\n",
      "  Iteration: 20/35, Loss: 0.489584, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.616799, Error: 0.3229\n",
      "  Iteration: 22/35, Loss: 0.562564, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.618435, Error: 0.3646\n",
      "  Iteration: 24/35, Loss: 0.557254, Error: 0.2500\n",
      "  Iteration: 25/35, Loss: 0.554082, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.570393, Error: 0.3021\n",
      "  Iteration: 27/35, Loss: 0.527051, Error: 0.2083\n",
      "  Iteration: 28/35, Loss: 0.626101, Error: 0.3542\n",
      "  Iteration: 29/35, Loss: 0.523374, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.492198, Error: 0.2083\n",
      "  Iteration: 31/35, Loss: 0.548966, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.612094, Error: 0.2708\n",
      "  Iteration: 33/35, Loss: 0.58566, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.46001, Error: 0.1771\n",
      "  Iteration: 35/35, Loss: 0.332269, Error: 0.1000\n",
      "Average Error for this Epoch: 0.2520\n",
      "found a better model!\n",
      "Epoch: 72/100\n",
      "  Iteration: 1/35, Loss: 0.681233, Error: 0.3229\n",
      "  Iteration: 2/35, Loss: 0.52098, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.578849, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.659223, Error: 0.3333\n",
      "  Iteration: 5/35, Loss: 0.633787, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.526755, Error: 0.2188\n",
      "  Iteration: 7/35, Loss: 0.594285, Error: 0.3229\n",
      "  Iteration: 8/35, Loss: 0.596919, Error: 0.2917\n",
      "  Iteration: 9/35, Loss: 0.596645, Error: 0.3438\n",
      "  Iteration: 10/35, Loss: 0.539947, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.613375, Error: 0.3333\n",
      "  Iteration: 12/35, Loss: 0.562978, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.534903, Error: 0.1875\n",
      "  Iteration: 14/35, Loss: 0.546914, Error: 0.2500\n",
      "  Iteration: 15/35, Loss: 0.556029, Error: 0.2604\n",
      "  Iteration: 16/35, Loss: 0.519157, Error: 0.2292\n",
      "  Iteration: 17/35, Loss: 0.597168, Error: 0.3125\n",
      "  Iteration: 18/35, Loss: 0.632495, Error: 0.2917\n",
      "  Iteration: 19/35, Loss: 0.516411, Error: 0.2188\n",
      "  Iteration: 20/35, Loss: 0.56521, Error: 0.2812\n",
      "  Iteration: 21/35, Loss: 0.542322, Error: 0.2500\n",
      "  Iteration: 22/35, Loss: 0.405351, Error: 0.1354\n",
      "  Iteration: 23/35, Loss: 0.426814, Error: 0.1562\n",
      "  Iteration: 24/35, Loss: 0.596992, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.475491, Error: 0.1875\n",
      "  Iteration: 26/35, Loss: 0.604357, Error: 0.2917\n",
      "  Iteration: 27/35, Loss: 0.563515, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.458375, Error: 0.1875\n",
      "  Iteration: 29/35, Loss: 0.601255, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.540202, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.61901, Error: 0.3021\n",
      "  Iteration: 32/35, Loss: 0.522607, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.542546, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.468942, Error: 0.1771\n",
      "  Iteration: 35/35, Loss: 0.375278, Error: 0.1000\n",
      "Average Error for this Epoch: 0.2526\n",
      "Epoch: 73/100\n",
      "  Iteration: 1/35, Loss: 0.552398, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.605592, Error: 0.3125\n",
      "  Iteration: 3/35, Loss: 0.600832, Error: 0.3125\n",
      "  Iteration: 4/35, Loss: 0.502298, Error: 0.2500\n",
      "  Iteration: 5/35, Loss: 0.480833, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.442961, Error: 0.1875\n",
      "  Iteration: 7/35, Loss: 0.603253, Error: 0.2500\n",
      "  Iteration: 8/35, Loss: 0.653477, Error: 0.3542\n",
      "  Iteration: 9/35, Loss: 0.568709, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.627573, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.531901, Error: 0.2500\n",
      "  Iteration: 12/35, Loss: 0.59635, Error: 0.2917\n",
      "  Iteration: 13/35, Loss: 0.578039, Error: 0.2708\n",
      "  Iteration: 14/35, Loss: 0.550657, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.566931, Error: 0.3021\n",
      "  Iteration: 16/35, Loss: 0.590863, Error: 0.3542\n",
      "  Iteration: 17/35, Loss: 0.559204, Error: 0.2292\n",
      "  Iteration: 18/35, Loss: 0.59963, Error: 0.3021\n",
      "  Iteration: 19/35, Loss: 0.553217, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.636832, Error: 0.3542\n",
      "  Iteration: 21/35, Loss: 0.593051, Error: 0.2708\n",
      "  Iteration: 22/35, Loss: 0.578468, Error: 0.2188\n",
      "  Iteration: 23/35, Loss: 0.555924, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.550351, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.607432, Error: 0.3021\n",
      "  Iteration: 26/35, Loss: 0.532829, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.481165, Error: 0.1979\n",
      "  Iteration: 28/35, Loss: 0.570315, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.532468, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.454763, Error: 0.1771\n",
      "  Iteration: 31/35, Loss: 0.490271, Error: 0.1875\n",
      "  Iteration: 32/35, Loss: 0.664736, Error: 0.3333\n",
      "  Iteration: 33/35, Loss: 0.480745, Error: 0.2188\n",
      "  Iteration: 34/35, Loss: 0.640499, Error: 0.3229\n",
      "  Iteration: 35/35, Loss: 0.500878, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2670\n",
      "Epoch: 74/100\n",
      "  Iteration: 1/35, Loss: 0.519989, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.535013, Error: 0.1771\n",
      "  Iteration: 3/35, Loss: 0.642835, Error: 0.3229\n",
      "  Iteration: 4/35, Loss: 0.690237, Error: 0.3542\n",
      "  Iteration: 5/35, Loss: 0.5426, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.566961, Error: 0.2604\n",
      "  Iteration: 7/35, Loss: 0.555763, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.690893, Error: 0.3646\n",
      "  Iteration: 9/35, Loss: 0.523927, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.500618, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.502168, Error: 0.1979\n",
      "  Iteration: 12/35, Loss: 0.530057, Error: 0.2396\n",
      "  Iteration: 13/35, Loss: 0.576483, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.579537, Error: 0.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 15/35, Loss: 0.537926, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.52413, Error: 0.2188\n",
      "  Iteration: 17/35, Loss: 0.571131, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.52893, Error: 0.2292\n",
      "  Iteration: 19/35, Loss: 0.506781, Error: 0.1875\n",
      "  Iteration: 20/35, Loss: 0.543466, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.622417, Error: 0.3125\n",
      "  Iteration: 22/35, Loss: 0.505954, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.642403, Error: 0.3125\n",
      "  Iteration: 24/35, Loss: 0.526554, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.55467, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.585886, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.603147, Error: 0.3125\n",
      "  Iteration: 28/35, Loss: 0.573193, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.596889, Error: 0.3021\n",
      "  Iteration: 30/35, Loss: 0.562445, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.623894, Error: 0.3021\n",
      "  Iteration: 32/35, Loss: 0.544015, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.56855, Error: 0.2917\n",
      "  Iteration: 34/35, Loss: 0.583062, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.629193, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2601\n",
      "Epoch: 75/100\n",
      "  Iteration: 1/35, Loss: 0.557484, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.601726, Error: 0.3021\n",
      "  Iteration: 3/35, Loss: 0.505423, Error: 0.2083\n",
      "  Iteration: 4/35, Loss: 0.514704, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.564059, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.538339, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.631904, Error: 0.3229\n",
      "  Iteration: 8/35, Loss: 0.459791, Error: 0.1667\n",
      "  Iteration: 9/35, Loss: 0.569493, Error: 0.2708\n",
      "  Iteration: 10/35, Loss: 0.629426, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.557133, Error: 0.2708\n",
      "  Iteration: 12/35, Loss: 0.62026, Error: 0.3125\n",
      "  Iteration: 13/35, Loss: 0.529499, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.55486, Error: 0.2292\n",
      "  Iteration: 15/35, Loss: 0.601549, Error: 0.3021\n",
      "  Iteration: 16/35, Loss: 0.591401, Error: 0.2708\n",
      "  Iteration: 17/35, Loss: 0.603573, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.500149, Error: 0.1875\n",
      "  Iteration: 19/35, Loss: 0.562799, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.61323, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.447184, Error: 0.1771\n",
      "  Iteration: 22/35, Loss: 0.491052, Error: 0.1979\n",
      "  Iteration: 23/35, Loss: 0.506675, Error: 0.2188\n",
      "  Iteration: 24/35, Loss: 0.610861, Error: 0.3125\n",
      "  Iteration: 25/35, Loss: 0.564243, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.53521, Error: 0.2396\n",
      "  Iteration: 27/35, Loss: 0.556798, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.49855, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.566487, Error: 0.2917\n",
      "  Iteration: 30/35, Loss: 0.592423, Error: 0.3021\n",
      "  Iteration: 31/35, Loss: 0.577567, Error: 0.2812\n",
      "  Iteration: 32/35, Loss: 0.524116, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.571122, Error: 0.2604\n",
      "  Iteration: 34/35, Loss: 0.500624, Error: 0.1979\n",
      "  Iteration: 35/35, Loss: 0.440094, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2525\n",
      "Epoch: 76/100\n",
      "  Iteration: 1/35, Loss: 0.620672, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.598816, Error: 0.3021\n",
      "  Iteration: 3/35, Loss: 0.652538, Error: 0.3438\n",
      "  Iteration: 4/35, Loss: 0.584517, Error: 0.3125\n",
      "  Iteration: 5/35, Loss: 0.583018, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.612146, Error: 0.3125\n",
      "  Iteration: 7/35, Loss: 0.523791, Error: 0.2083\n",
      "  Iteration: 8/35, Loss: 0.561331, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.536112, Error: 0.1979\n",
      "  Iteration: 10/35, Loss: 0.632446, Error: 0.3125\n",
      "  Iteration: 11/35, Loss: 0.509768, Error: 0.1875\n",
      "  Iteration: 12/35, Loss: 0.557755, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.476235, Error: 0.1667\n",
      "  Iteration: 14/35, Loss: 0.578058, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.537114, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.518081, Error: 0.2188\n",
      "  Iteration: 17/35, Loss: 0.609846, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.50034, Error: 0.2083\n",
      "  Iteration: 19/35, Loss: 0.58185, Error: 0.2812\n",
      "  Iteration: 20/35, Loss: 0.588072, Error: 0.2708\n",
      "  Iteration: 21/35, Loss: 0.526545, Error: 0.2292\n",
      "  Iteration: 22/35, Loss: 0.521246, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.546228, Error: 0.2708\n",
      "  Iteration: 24/35, Loss: 0.513657, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.576949, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.503714, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.568609, Error: 0.2604\n",
      "  Iteration: 28/35, Loss: 0.527077, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.517952, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.524797, Error: 0.2396\n",
      "  Iteration: 31/35, Loss: 0.56637, Error: 0.2396\n",
      "  Iteration: 32/35, Loss: 0.547371, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.539208, Error: 0.2292\n",
      "  Iteration: 34/35, Loss: 0.523137, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.690456, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2546\n",
      "Epoch: 77/100\n",
      "  Iteration: 1/35, Loss: 0.561904, Error: 0.2604\n",
      "  Iteration: 2/35, Loss: 0.526597, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.583597, Error: 0.2604\n",
      "  Iteration: 4/35, Loss: 0.557915, Error: 0.2812\n",
      "  Iteration: 5/35, Loss: 0.44679, Error: 0.1354\n",
      "  Iteration: 6/35, Loss: 0.5221, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.555027, Error: 0.2500\n",
      "  Iteration: 8/35, Loss: 0.544128, Error: 0.2292\n",
      "  Iteration: 9/35, Loss: 0.490631, Error: 0.2083\n",
      "  Iteration: 10/35, Loss: 0.540495, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.690983, Error: 0.3646\n",
      "  Iteration: 12/35, Loss: 0.570021, Error: 0.2812\n",
      "  Iteration: 13/35, Loss: 0.583372, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.629899, Error: 0.3229\n",
      "  Iteration: 15/35, Loss: 0.542809, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.539252, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.560778, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.555768, Error: 0.2396\n",
      "  Iteration: 19/35, Loss: 0.600123, Error: 0.3021\n",
      "  Iteration: 20/35, Loss: 0.485083, Error: 0.1562\n",
      "  Iteration: 21/35, Loss: 0.624172, Error: 0.3229\n",
      "  Iteration: 22/35, Loss: 0.517345, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.507221, Error: 0.1979\n",
      "  Iteration: 24/35, Loss: 0.573469, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.533378, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.589074, Error: 0.3021\n",
      "  Iteration: 27/35, Loss: 0.527938, Error: 0.2188\n",
      "  Iteration: 28/35, Loss: 0.582527, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.577098, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.579995, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.561677, Error: 0.2812\n",
      "  Iteration: 32/35, Loss: 0.551962, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.477352, Error: 0.1875\n",
      "  Iteration: 34/35, Loss: 0.583918, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.457413, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2518\n",
      "found a better model!\n",
      "Epoch: 78/100\n",
      "  Iteration: 1/35, Loss: 0.576558, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.5492, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.46827, Error: 0.1979\n",
      "  Iteration: 4/35, Loss: 0.534837, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.490422, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.557459, Error: 0.2812\n",
      "  Iteration: 7/35, Loss: 0.550563, Error: 0.2604\n",
      "  Iteration: 8/35, Loss: 0.570717, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.531179, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.529061, Error: 0.2396\n",
      "  Iteration: 11/35, Loss: 0.611332, Error: 0.3333\n",
      "  Iteration: 12/35, Loss: 0.532858, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.550866, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.525352, Error: 0.2604\n",
      "  Iteration: 15/35, Loss: 0.504872, Error: 0.1875\n",
      "  Iteration: 16/35, Loss: 0.597755, Error: 0.3021\n",
      "  Iteration: 17/35, Loss: 0.552104, Error: 0.2396\n",
      "  Iteration: 18/35, Loss: 0.542161, Error: 0.2500\n",
      "  Iteration: 19/35, Loss: 0.55593, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.499303, Error: 0.2083\n",
      "  Iteration: 21/35, Loss: 0.616447, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.523652, Error: 0.2188\n",
      "  Iteration: 23/35, Loss: 0.553086, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.509422, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.70444, Error: 0.3646\n",
      "  Iteration: 26/35, Loss: 0.496714, Error: 0.2083\n",
      "  Iteration: 27/35, Loss: 0.590504, Error: 0.3021\n",
      "  Iteration: 28/35, Loss: 0.57614, Error: 0.2604\n",
      "  Iteration: 29/35, Loss: 0.589677, Error: 0.3021\n",
      "  Iteration: 30/35, Loss: 0.467465, Error: 0.1771\n",
      "  Iteration: 31/35, Loss: 0.591353, Error: 0.2708\n",
      "  Iteration: 32/35, Loss: 0.54353, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.619969, Error: 0.3021\n",
      "  Iteration: 34/35, Loss: 0.542913, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.627037, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2556\n",
      "Epoch: 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 1/35, Loss: 0.575976, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.54834, Error: 0.2604\n",
      "  Iteration: 3/35, Loss: 0.527549, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.465994, Error: 0.1667\n",
      "  Iteration: 5/35, Loss: 0.630097, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.547012, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.432052, Error: 0.1562\n",
      "  Iteration: 8/35, Loss: 0.558682, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.6699, Error: 0.3438\n",
      "  Iteration: 10/35, Loss: 0.683535, Error: 0.3854\n",
      "  Iteration: 11/35, Loss: 0.493155, Error: 0.2083\n",
      "  Iteration: 12/35, Loss: 0.479245, Error: 0.2083\n",
      "  Iteration: 13/35, Loss: 0.576263, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.603468, Error: 0.3021\n",
      "  Iteration: 15/35, Loss: 0.56717, Error: 0.2708\n",
      "  Iteration: 16/35, Loss: 0.529273, Error: 0.2188\n",
      "  Iteration: 17/35, Loss: 0.5006, Error: 0.2396\n",
      "  Iteration: 18/35, Loss: 0.644471, Error: 0.3333\n",
      "  Iteration: 19/35, Loss: 0.587395, Error: 0.2917\n",
      "  Iteration: 20/35, Loss: 0.601652, Error: 0.3021\n",
      "  Iteration: 21/35, Loss: 0.475078, Error: 0.1667\n",
      "  Iteration: 22/35, Loss: 0.540729, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.499441, Error: 0.2083\n",
      "  Iteration: 24/35, Loss: 0.601285, Error: 0.2917\n",
      "  Iteration: 25/35, Loss: 0.530422, Error: 0.2188\n",
      "  Iteration: 26/35, Loss: 0.563844, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.455847, Error: 0.1771\n",
      "  Iteration: 28/35, Loss: 0.592124, Error: 0.2708\n",
      "  Iteration: 29/35, Loss: 0.527544, Error: 0.2708\n",
      "  Iteration: 30/35, Loss: 0.547321, Error: 0.2500\n",
      "  Iteration: 31/35, Loss: 0.601947, Error: 0.3125\n",
      "  Iteration: 32/35, Loss: 0.513187, Error: 0.2292\n",
      "  Iteration: 33/35, Loss: 0.572874, Error: 0.2708\n",
      "  Iteration: 34/35, Loss: 0.540767, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.470393, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2522\n",
      "Epoch: 80/100\n",
      "  Iteration: 1/35, Loss: 0.564684, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.531523, Error: 0.2188\n",
      "  Iteration: 3/35, Loss: 0.68253, Error: 0.3542\n",
      "  Iteration: 4/35, Loss: 0.602434, Error: 0.3021\n",
      "  Iteration: 5/35, Loss: 0.584977, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.619276, Error: 0.3438\n",
      "  Iteration: 7/35, Loss: 0.572812, Error: 0.2917\n",
      "  Iteration: 8/35, Loss: 0.540072, Error: 0.2188\n",
      "  Iteration: 9/35, Loss: 0.609151, Error: 0.2917\n",
      "  Iteration: 10/35, Loss: 0.594072, Error: 0.2917\n",
      "  Iteration: 11/35, Loss: 0.555394, Error: 0.2812\n",
      "  Iteration: 12/35, Loss: 0.595835, Error: 0.3021\n",
      "  Iteration: 13/35, Loss: 0.514619, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.50318, Error: 0.1979\n",
      "  Iteration: 15/35, Loss: 0.547477, Error: 0.2188\n",
      "  Iteration: 16/35, Loss: 0.509608, Error: 0.2083\n",
      "  Iteration: 17/35, Loss: 0.531647, Error: 0.2396\n",
      "  Iteration: 18/35, Loss: 0.656643, Error: 0.3021\n",
      "  Iteration: 19/35, Loss: 0.633814, Error: 0.3125\n",
      "  Iteration: 20/35, Loss: 0.504723, Error: 0.1979\n",
      "  Iteration: 21/35, Loss: 0.498075, Error: 0.1979\n",
      "  Iteration: 22/35, Loss: 0.48891, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.535093, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.502424, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.527403, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.494425, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.524027, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.519908, Error: 0.1979\n",
      "  Iteration: 29/35, Loss: 0.535659, Error: 0.2396\n",
      "  Iteration: 30/35, Loss: 0.518108, Error: 0.2292\n",
      "  Iteration: 31/35, Loss: 0.563387, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.544466, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.467998, Error: 0.2083\n",
      "  Iteration: 34/35, Loss: 0.600257, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.453747, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2524\n",
      "Epoch: 81/100\n",
      "  Iteration: 1/35, Loss: 0.533173, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.513083, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.493281, Error: 0.2292\n",
      "  Iteration: 4/35, Loss: 0.450878, Error: 0.1458\n",
      "  Iteration: 5/35, Loss: 0.495297, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.637147, Error: 0.3125\n",
      "  Iteration: 7/35, Loss: 0.625911, Error: 0.3021\n",
      "  Iteration: 8/35, Loss: 0.637544, Error: 0.3333\n",
      "  Iteration: 9/35, Loss: 0.56581, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.69985, Error: 0.3958\n",
      "  Iteration: 11/35, Loss: 0.508426, Error: 0.1875\n",
      "  Iteration: 12/35, Loss: 0.634632, Error: 0.3438\n",
      "  Iteration: 13/35, Loss: 0.548063, Error: 0.2500\n",
      "  Iteration: 14/35, Loss: 0.50504, Error: 0.1875\n",
      "  Iteration: 15/35, Loss: 0.506487, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.552747, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.542308, Error: 0.2188\n",
      "  Iteration: 18/35, Loss: 0.622384, Error: 0.3438\n",
      "  Iteration: 19/35, Loss: 0.629667, Error: 0.3229\n",
      "  Iteration: 20/35, Loss: 0.592948, Error: 0.3125\n",
      "  Iteration: 21/35, Loss: 0.537849, Error: 0.2188\n",
      "  Iteration: 22/35, Loss: 0.468648, Error: 0.1875\n",
      "  Iteration: 23/35, Loss: 0.485559, Error: 0.1875\n",
      "  Iteration: 24/35, Loss: 0.537587, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.584541, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.513592, Error: 0.2292\n",
      "  Iteration: 27/35, Loss: 0.473759, Error: 0.1979\n",
      "  Iteration: 28/35, Loss: 0.492721, Error: 0.2083\n",
      "  Iteration: 29/35, Loss: 0.607555, Error: 0.3125\n",
      "  Iteration: 30/35, Loss: 0.545039, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.540647, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.503144, Error: 0.2188\n",
      "  Iteration: 33/35, Loss: 0.495238, Error: 0.2083\n",
      "  Iteration: 34/35, Loss: 0.69236, Error: 0.3646\n",
      "  Iteration: 35/35, Loss: 0.673903, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2570\n",
      "Epoch: 82/100\n",
      "  Iteration: 1/35, Loss: 0.523484, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.563468, Error: 0.2708\n",
      "  Iteration: 3/35, Loss: 0.557303, Error: 0.2708\n",
      "  Iteration: 4/35, Loss: 0.566668, Error: 0.2396\n",
      "  Iteration: 5/35, Loss: 0.473159, Error: 0.1562\n",
      "  Iteration: 6/35, Loss: 0.559407, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.571633, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.471545, Error: 0.1667\n",
      "  Iteration: 9/35, Loss: 0.542193, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.650294, Error: 0.3333\n",
      "  Iteration: 11/35, Loss: 0.587319, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.587805, Error: 0.2812\n",
      "  Iteration: 13/35, Loss: 0.550992, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.568191, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.584676, Error: 0.2812\n",
      "  Iteration: 16/35, Loss: 0.544875, Error: 0.2604\n",
      "  Iteration: 17/35, Loss: 0.578469, Error: 0.2708\n",
      "  Iteration: 18/35, Loss: 0.535236, Error: 0.2188\n",
      "  Iteration: 19/35, Loss: 0.558394, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.584532, Error: 0.3021\n",
      "  Iteration: 21/35, Loss: 0.504127, Error: 0.1979\n",
      "  Iteration: 22/35, Loss: 0.554965, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.54402, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.5214, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.499563, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.713346, Error: 0.3750\n",
      "  Iteration: 27/35, Loss: 0.590582, Error: 0.3125\n",
      "  Iteration: 28/35, Loss: 0.498793, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.555301, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.5884, Error: 0.2604\n",
      "  Iteration: 31/35, Loss: 0.502546, Error: 0.2083\n",
      "  Iteration: 32/35, Loss: 0.504683, Error: 0.2083\n",
      "  Iteration: 33/35, Loss: 0.524608, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.575697, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.417214, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2495\n",
      "found a better model!\n",
      "Epoch: 83/100\n",
      "  Iteration: 1/35, Loss: 0.584057, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.597362, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.474642, Error: 0.1875\n",
      "  Iteration: 4/35, Loss: 0.496117, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.561143, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.523711, Error: 0.2083\n",
      "  Iteration: 7/35, Loss: 0.551877, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.592772, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.52162, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.521779, Error: 0.2500\n",
      "  Iteration: 11/35, Loss: 0.502719, Error: 0.2083\n",
      "  Iteration: 12/35, Loss: 0.596552, Error: 0.2812\n",
      "  Iteration: 13/35, Loss: 0.575073, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.587592, Error: 0.3021\n",
      "  Iteration: 15/35, Loss: 0.529164, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.53019, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.601438, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.614134, Error: 0.3229\n",
      "  Iteration: 19/35, Loss: 0.536008, Error: 0.2292\n",
      "  Iteration: 20/35, Loss: 0.578322, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.481694, Error: 0.1979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 22/35, Loss: 0.552116, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.525691, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.554006, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.555724, Error: 0.2396\n",
      "  Iteration: 26/35, Loss: 0.569176, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.605856, Error: 0.2917\n",
      "  Iteration: 28/35, Loss: 0.589171, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.496614, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.48586, Error: 0.2188\n",
      "  Iteration: 31/35, Loss: 0.560255, Error: 0.2812\n",
      "  Iteration: 32/35, Loss: 0.549369, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.507305, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.526375, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.653598, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2568\n",
      "Epoch: 84/100\n",
      "  Iteration: 1/35, Loss: 0.49962, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.536899, Error: 0.2604\n",
      "  Iteration: 3/35, Loss: 0.580403, Error: 0.2917\n",
      "  Iteration: 4/35, Loss: 0.553517, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.599136, Error: 0.3125\n",
      "  Iteration: 6/35, Loss: 0.551326, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.538464, Error: 0.2500\n",
      "  Iteration: 8/35, Loss: 0.538261, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.576052, Error: 0.2917\n",
      "  Iteration: 10/35, Loss: 0.514921, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.483433, Error: 0.2188\n",
      "  Iteration: 12/35, Loss: 0.530011, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.663075, Error: 0.3438\n",
      "  Iteration: 14/35, Loss: 0.496235, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.6533, Error: 0.3438\n",
      "  Iteration: 16/35, Loss: 0.557255, Error: 0.2292\n",
      "  Iteration: 17/35, Loss: 0.670244, Error: 0.3229\n",
      "  Iteration: 18/35, Loss: 0.508471, Error: 0.2083\n",
      "  Iteration: 19/35, Loss: 0.576391, Error: 0.3021\n",
      "  Iteration: 20/35, Loss: 0.56794, Error: 0.2708\n",
      "  Iteration: 21/35, Loss: 0.558845, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.534055, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.529846, Error: 0.2083\n",
      "  Iteration: 24/35, Loss: 0.53165, Error: 0.2083\n",
      "  Iteration: 25/35, Loss: 0.560087, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.538648, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.493577, Error: 0.1979\n",
      "  Iteration: 28/35, Loss: 0.60605, Error: 0.3021\n",
      "  Iteration: 29/35, Loss: 0.559861, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.567311, Error: 0.2708\n",
      "  Iteration: 31/35, Loss: 0.586502, Error: 0.2812\n",
      "  Iteration: 32/35, Loss: 0.527649, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.507408, Error: 0.2396\n",
      "  Iteration: 34/35, Loss: 0.514449, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.638753, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2589\n",
      "Epoch: 85/100\n",
      "  Iteration: 1/35, Loss: 0.668145, Error: 0.3542\n",
      "  Iteration: 2/35, Loss: 0.542746, Error: 0.2708\n",
      "  Iteration: 3/35, Loss: 0.589991, Error: 0.2708\n",
      "  Iteration: 4/35, Loss: 0.552378, Error: 0.2396\n",
      "  Iteration: 5/35, Loss: 0.476961, Error: 0.1875\n",
      "  Iteration: 6/35, Loss: 0.573348, Error: 0.3021\n",
      "  Iteration: 7/35, Loss: 0.580043, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.513524, Error: 0.2083\n",
      "  Iteration: 9/35, Loss: 0.600103, Error: 0.3125\n",
      "  Iteration: 10/35, Loss: 0.567222, Error: 0.2812\n",
      "  Iteration: 11/35, Loss: 0.492281, Error: 0.1979\n",
      "  Iteration: 12/35, Loss: 0.55347, Error: 0.2396\n",
      "  Iteration: 13/35, Loss: 0.530725, Error: 0.2500\n",
      "  Iteration: 14/35, Loss: 0.616353, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.525934, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.476663, Error: 0.1875\n",
      "  Iteration: 17/35, Loss: 0.607663, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.565311, Error: 0.2604\n",
      "  Iteration: 19/35, Loss: 0.564981, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.463168, Error: 0.1979\n",
      "  Iteration: 21/35, Loss: 0.564319, Error: 0.2708\n",
      "  Iteration: 22/35, Loss: 0.444323, Error: 0.1667\n",
      "  Iteration: 23/35, Loss: 0.607028, Error: 0.3125\n",
      "  Iteration: 24/35, Loss: 0.555473, Error: 0.2708\n",
      "  Iteration: 25/35, Loss: 0.475917, Error: 0.1875\n",
      "  Iteration: 26/35, Loss: 0.554114, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.560411, Error: 0.2917\n",
      "  Iteration: 28/35, Loss: 0.503838, Error: 0.2188\n",
      "  Iteration: 29/35, Loss: 0.44822, Error: 0.1667\n",
      "  Iteration: 30/35, Loss: 0.596686, Error: 0.3021\n",
      "  Iteration: 31/35, Loss: 0.602398, Error: 0.3021\n",
      "  Iteration: 32/35, Loss: 0.570013, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.616419, Error: 0.2812\n",
      "  Iteration: 34/35, Loss: 0.622256, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.425479, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2537\n",
      "Epoch: 86/100\n",
      "  Iteration: 1/35, Loss: 0.514887, Error: 0.2292\n",
      "  Iteration: 2/35, Loss: 0.60976, Error: 0.3333\n",
      "  Iteration: 3/35, Loss: 0.5145, Error: 0.2396\n",
      "  Iteration: 4/35, Loss: 0.494982, Error: 0.2083\n",
      "  Iteration: 5/35, Loss: 0.495362, Error: 0.2083\n",
      "  Iteration: 6/35, Loss: 0.554302, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.556145, Error: 0.2604\n",
      "  Iteration: 8/35, Loss: 0.545296, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.593772, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.629915, Error: 0.3125\n",
      "  Iteration: 11/35, Loss: 0.578587, Error: 0.2500\n",
      "  Iteration: 12/35, Loss: 0.488101, Error: 0.1979\n",
      "  Iteration: 13/35, Loss: 0.474174, Error: 0.1875\n",
      "  Iteration: 14/35, Loss: 0.501707, Error: 0.1875\n",
      "  Iteration: 15/35, Loss: 0.5139, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.486713, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.558769, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.586523, Error: 0.2708\n",
      "  Iteration: 19/35, Loss: 0.588706, Error: 0.2812\n",
      "  Iteration: 20/35, Loss: 0.516783, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.564778, Error: 0.2604\n",
      "  Iteration: 22/35, Loss: 0.530921, Error: 0.2500\n",
      "  Iteration: 23/35, Loss: 0.490569, Error: 0.1979\n",
      "  Iteration: 24/35, Loss: 0.484986, Error: 0.2083\n",
      "  Iteration: 25/35, Loss: 0.603649, Error: 0.3021\n",
      "  Iteration: 26/35, Loss: 0.599356, Error: 0.3125\n",
      "  Iteration: 27/35, Loss: 0.601256, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.674635, Error: 0.3958\n",
      "  Iteration: 29/35, Loss: 0.588343, Error: 0.3021\n",
      "  Iteration: 30/35, Loss: 0.56183, Error: 0.2292\n",
      "  Iteration: 31/35, Loss: 0.528443, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.58872, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.582348, Error: 0.3021\n",
      "  Iteration: 34/35, Loss: 0.547356, Error: 0.2708\n",
      "  Iteration: 35/35, Loss: 0.457804, Error: 0.1500\n",
      "Average Error for this Epoch: 0.2537\n",
      "Epoch: 87/100\n",
      "  Iteration: 1/35, Loss: 0.561732, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.535068, Error: 0.2708\n",
      "  Iteration: 3/35, Loss: 0.534961, Error: 0.2500\n",
      "  Iteration: 4/35, Loss: 0.642571, Error: 0.3542\n",
      "  Iteration: 5/35, Loss: 0.526686, Error: 0.2396\n",
      "  Iteration: 6/35, Loss: 0.482822, Error: 0.1875\n",
      "  Iteration: 7/35, Loss: 0.520474, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.590914, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.538165, Error: 0.2396\n",
      "  Iteration: 10/35, Loss: 0.46337, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.53986, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.53863, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.588646, Error: 0.2917\n",
      "  Iteration: 14/35, Loss: 0.589597, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.535715, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.532743, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.525939, Error: 0.2188\n",
      "  Iteration: 18/35, Loss: 0.632107, Error: 0.3229\n",
      "  Iteration: 19/35, Loss: 0.586576, Error: 0.3125\n",
      "  Iteration: 20/35, Loss: 0.554242, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.545347, Error: 0.2604\n",
      "  Iteration: 22/35, Loss: 0.503231, Error: 0.1875\n",
      "  Iteration: 23/35, Loss: 0.45986, Error: 0.1354\n",
      "  Iteration: 24/35, Loss: 0.529302, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.539349, Error: 0.2292\n",
      "  Iteration: 26/35, Loss: 0.513526, Error: 0.2188\n",
      "  Iteration: 27/35, Loss: 0.593544, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.551737, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.697959, Error: 0.3229\n",
      "  Iteration: 30/35, Loss: 0.486405, Error: 0.2083\n",
      "  Iteration: 31/35, Loss: 0.618947, Error: 0.3125\n",
      "  Iteration: 32/35, Loss: 0.543793, Error: 0.2604\n",
      "  Iteration: 33/35, Loss: 0.566982, Error: 0.2812\n",
      "  Iteration: 34/35, Loss: 0.625803, Error: 0.3438\n",
      "  Iteration: 35/35, Loss: 0.669971, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2576\n",
      "Epoch: 88/100\n",
      "  Iteration: 1/35, Loss: 0.589688, Error: 0.2917\n",
      "  Iteration: 2/35, Loss: 0.541719, Error: 0.2604\n",
      "  Iteration: 3/35, Loss: 0.543179, Error: 0.2188\n",
      "  Iteration: 4/35, Loss: 0.538431, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.56584, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.586103, Error: 0.2917\n",
      "  Iteration: 7/35, Loss: 0.568868, Error: 0.2708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 8/35, Loss: 0.577484, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.525359, Error: 0.2500\n",
      "  Iteration: 10/35, Loss: 0.46772, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.632392, Error: 0.3125\n",
      "  Iteration: 12/35, Loss: 0.476107, Error: 0.1875\n",
      "  Iteration: 13/35, Loss: 0.570623, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.602291, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.605749, Error: 0.3125\n",
      "  Iteration: 16/35, Loss: 0.619365, Error: 0.3125\n",
      "  Iteration: 17/35, Loss: 0.60077, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.530304, Error: 0.2292\n",
      "  Iteration: 19/35, Loss: 0.541255, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.536806, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.536584, Error: 0.2604\n",
      "  Iteration: 22/35, Loss: 0.479358, Error: 0.1979\n",
      "  Iteration: 23/35, Loss: 0.540205, Error: 0.2812\n",
      "  Iteration: 24/35, Loss: 0.449919, Error: 0.1771\n",
      "  Iteration: 25/35, Loss: 0.57954, Error: 0.2812\n",
      "  Iteration: 26/35, Loss: 0.620411, Error: 0.3021\n",
      "  Iteration: 27/35, Loss: 0.612981, Error: 0.3021\n",
      "  Iteration: 28/35, Loss: 0.607386, Error: 0.2917\n",
      "  Iteration: 29/35, Loss: 0.560058, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.614576, Error: 0.3021\n",
      "  Iteration: 31/35, Loss: 0.573445, Error: 0.3021\n",
      "  Iteration: 32/35, Loss: 0.471773, Error: 0.1771\n",
      "  Iteration: 33/35, Loss: 0.461954, Error: 0.1562\n",
      "  Iteration: 34/35, Loss: 0.595543, Error: 0.3021\n",
      "  Iteration: 35/35, Loss: 0.538638, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2590\n",
      "Epoch: 89/100\n",
      "  Iteration: 1/35, Loss: 0.537239, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.504443, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.510543, Error: 0.2292\n",
      "  Iteration: 4/35, Loss: 0.668766, Error: 0.3438\n",
      "  Iteration: 5/35, Loss: 0.682058, Error: 0.3333\n",
      "  Iteration: 6/35, Loss: 0.598144, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.568037, Error: 0.2708\n",
      "  Iteration: 8/35, Loss: 0.572442, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.601549, Error: 0.3021\n",
      "  Iteration: 10/35, Loss: 0.567823, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.544967, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.587385, Error: 0.3021\n",
      "  Iteration: 13/35, Loss: 0.581286, Error: 0.2604\n",
      "  Iteration: 14/35, Loss: 0.538379, Error: 0.2188\n",
      "  Iteration: 15/35, Loss: 0.588406, Error: 0.3021\n",
      "  Iteration: 16/35, Loss: 0.520103, Error: 0.2083\n",
      "  Iteration: 17/35, Loss: 0.572543, Error: 0.3021\n",
      "  Iteration: 18/35, Loss: 0.635605, Error: 0.3542\n",
      "  Iteration: 19/35, Loss: 0.559266, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.413627, Error: 0.1146\n",
      "  Iteration: 21/35, Loss: 0.508012, Error: 0.1979\n",
      "  Iteration: 22/35, Loss: 0.549813, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.539359, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.507734, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.481531, Error: 0.2083\n",
      "  Iteration: 26/35, Loss: 0.448461, Error: 0.1875\n",
      "  Iteration: 27/35, Loss: 0.536289, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.44687, Error: 0.1875\n",
      "  Iteration: 29/35, Loss: 0.591347, Error: 0.2812\n",
      "  Iteration: 30/35, Loss: 0.519852, Error: 0.2396\n",
      "  Iteration: 31/35, Loss: 0.599279, Error: 0.2812\n",
      "  Iteration: 32/35, Loss: 0.617603, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.473404, Error: 0.1771\n",
      "  Iteration: 34/35, Loss: 0.572322, Error: 0.2604\n",
      "  Iteration: 35/35, Loss: 0.549215, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2524\n",
      "Epoch: 90/100\n",
      "  Iteration: 1/35, Loss: 0.601856, Error: 0.3333\n",
      "  Iteration: 2/35, Loss: 0.579942, Error: 0.2292\n",
      "  Iteration: 3/35, Loss: 0.471831, Error: 0.1875\n",
      "  Iteration: 4/35, Loss: 0.51798, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.552415, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.471017, Error: 0.1875\n",
      "  Iteration: 7/35, Loss: 0.55295, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.617682, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.669466, Error: 0.3438\n",
      "  Iteration: 10/35, Loss: 0.57596, Error: 0.2812\n",
      "  Iteration: 11/35, Loss: 0.587085, Error: 0.3229\n",
      "  Iteration: 12/35, Loss: 0.599732, Error: 0.3021\n",
      "  Iteration: 13/35, Loss: 0.503916, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.581639, Error: 0.2708\n",
      "  Iteration: 15/35, Loss: 0.545384, Error: 0.2396\n",
      "  Iteration: 16/35, Loss: 0.4774, Error: 0.1875\n",
      "  Iteration: 17/35, Loss: 0.459534, Error: 0.1562\n",
      "  Iteration: 18/35, Loss: 0.607252, Error: 0.3229\n",
      "  Iteration: 19/35, Loss: 0.683358, Error: 0.3438\n",
      "  Iteration: 20/35, Loss: 0.532227, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.586452, Error: 0.2812\n",
      "  Iteration: 22/35, Loss: 0.533785, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.541669, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.510092, Error: 0.2083\n",
      "  Iteration: 25/35, Loss: 0.6257, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.550101, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.593209, Error: 0.3229\n",
      "  Iteration: 28/35, Loss: 0.583907, Error: 0.2917\n",
      "  Iteration: 29/35, Loss: 0.498436, Error: 0.2396\n",
      "  Iteration: 30/35, Loss: 0.602602, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.532117, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.555814, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.588191, Error: 0.2917\n",
      "  Iteration: 34/35, Loss: 0.533982, Error: 0.2083\n",
      "  Iteration: 35/35, Loss: 0.533167, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2610\n",
      "Epoch: 91/100\n",
      "  Iteration: 1/35, Loss: 0.659913, Error: 0.3646\n",
      "  Iteration: 2/35, Loss: 0.573568, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.448154, Error: 0.1875\n",
      "  Iteration: 4/35, Loss: 0.55346, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.605409, Error: 0.3229\n",
      "  Iteration: 6/35, Loss: 0.533316, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.580406, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.521633, Error: 0.2396\n",
      "  Iteration: 9/35, Loss: 0.469162, Error: 0.1875\n",
      "  Iteration: 10/35, Loss: 0.543376, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.526707, Error: 0.2292\n",
      "  Iteration: 12/35, Loss: 0.588896, Error: 0.2812\n",
      "  Iteration: 13/35, Loss: 0.523497, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.627893, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.506362, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.489892, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.537706, Error: 0.2396\n",
      "  Iteration: 18/35, Loss: 0.665318, Error: 0.3438\n",
      "  Iteration: 19/35, Loss: 0.472605, Error: 0.1979\n",
      "  Iteration: 20/35, Loss: 0.566386, Error: 0.2917\n",
      "  Iteration: 21/35, Loss: 0.493329, Error: 0.2083\n",
      "  Iteration: 22/35, Loss: 0.54083, Error: 0.2292\n",
      "  Iteration: 23/35, Loss: 0.531103, Error: 0.2500\n",
      "  Iteration: 24/35, Loss: 0.456641, Error: 0.1875\n",
      "  Iteration: 25/35, Loss: 0.598179, Error: 0.3021\n",
      "  Iteration: 26/35, Loss: 0.57456, Error: 0.2917\n",
      "  Iteration: 27/35, Loss: 0.554381, Error: 0.2500\n",
      "  Iteration: 28/35, Loss: 0.528027, Error: 0.2396\n",
      "  Iteration: 29/35, Loss: 0.582295, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.516757, Error: 0.2396\n",
      "  Iteration: 31/35, Loss: 0.547967, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.610064, Error: 0.3229\n",
      "  Iteration: 33/35, Loss: 0.546252, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.520963, Error: 0.2500\n",
      "  Iteration: 35/35, Loss: 0.723634, Error: 0.4000\n",
      "Average Error for this Epoch: 0.2588\n",
      "Epoch: 92/100\n",
      "  Iteration: 1/35, Loss: 0.507582, Error: 0.2396\n",
      "  Iteration: 2/35, Loss: 0.548213, Error: 0.2500\n",
      "  Iteration: 3/35, Loss: 0.635309, Error: 0.3333\n",
      "  Iteration: 4/35, Loss: 0.53247, Error: 0.2396\n",
      "  Iteration: 5/35, Loss: 0.559128, Error: 0.2917\n",
      "  Iteration: 6/35, Loss: 0.531826, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.529038, Error: 0.2500\n",
      "  Iteration: 8/35, Loss: 0.492873, Error: 0.1979\n",
      "  Iteration: 9/35, Loss: 0.522672, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.467853, Error: 0.2188\n",
      "  Iteration: 11/35, Loss: 0.510741, Error: 0.2083\n",
      "  Iteration: 12/35, Loss: 0.574233, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.682257, Error: 0.3438\n",
      "  Iteration: 14/35, Loss: 0.506023, Error: 0.2292\n",
      "  Iteration: 15/35, Loss: 0.59752, Error: 0.2917\n",
      "  Iteration: 16/35, Loss: 0.554172, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.617742, Error: 0.3125\n",
      "  Iteration: 18/35, Loss: 0.52719, Error: 0.1979\n",
      "  Iteration: 19/35, Loss: 0.525823, Error: 0.2604\n",
      "  Iteration: 20/35, Loss: 0.55696, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.56006, Error: 0.2500\n",
      "  Iteration: 22/35, Loss: 0.615007, Error: 0.3229\n",
      "  Iteration: 23/35, Loss: 0.473124, Error: 0.2083\n",
      "  Iteration: 24/35, Loss: 0.543078, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.56466, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.441451, Error: 0.1562\n",
      "  Iteration: 27/35, Loss: 0.523318, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.560884, Error: 0.2604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 29/35, Loss: 0.611679, Error: 0.2812\n",
      "  Iteration: 30/35, Loss: 0.567452, Error: 0.2396\n",
      "  Iteration: 31/35, Loss: 0.51507, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.661921, Error: 0.3021\n",
      "  Iteration: 33/35, Loss: 0.601528, Error: 0.3021\n",
      "  Iteration: 34/35, Loss: 0.52386, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.554598, Error: 0.3000\n",
      "Average Error for this Epoch: 0.2550\n",
      "Epoch: 93/100\n",
      "  Iteration: 1/35, Loss: 0.466689, Error: 0.2083\n",
      "  Iteration: 2/35, Loss: 0.62881, Error: 0.3438\n",
      "  Iteration: 3/35, Loss: 0.437333, Error: 0.1354\n",
      "  Iteration: 4/35, Loss: 0.628348, Error: 0.3333\n",
      "  Iteration: 5/35, Loss: 0.540038, Error: 0.2292\n",
      "  Iteration: 6/35, Loss: 0.619223, Error: 0.3229\n",
      "  Iteration: 7/35, Loss: 0.510154, Error: 0.1771\n",
      "  Iteration: 8/35, Loss: 0.585659, Error: 0.3125\n",
      "  Iteration: 9/35, Loss: 0.586612, Error: 0.3125\n",
      "  Iteration: 10/35, Loss: 0.611715, Error: 0.3021\n",
      "  Iteration: 11/35, Loss: 0.539593, Error: 0.2396\n",
      "  Iteration: 12/35, Loss: 0.507533, Error: 0.2292\n",
      "  Iteration: 13/35, Loss: 0.56254, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.564621, Error: 0.2812\n",
      "  Iteration: 15/35, Loss: 0.504826, Error: 0.2083\n",
      "  Iteration: 16/35, Loss: 0.568062, Error: 0.2396\n",
      "  Iteration: 17/35, Loss: 0.529601, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.663952, Error: 0.3333\n",
      "  Iteration: 19/35, Loss: 0.522145, Error: 0.2500\n",
      "  Iteration: 20/35, Loss: 0.544076, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.532571, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.563107, Error: 0.2917\n",
      "  Iteration: 23/35, Loss: 0.559176, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.622173, Error: 0.3333\n",
      "  Iteration: 25/35, Loss: 0.547531, Error: 0.2604\n",
      "  Iteration: 26/35, Loss: 0.568766, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.496101, Error: 0.1667\n",
      "  Iteration: 28/35, Loss: 0.483271, Error: 0.1979\n",
      "  Iteration: 29/35, Loss: 0.505073, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.485822, Error: 0.2188\n",
      "  Iteration: 31/35, Loss: 0.525774, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.56082, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.569987, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.541481, Error: 0.2396\n",
      "  Iteration: 35/35, Loss: 0.549726, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2533\n",
      "Epoch: 94/100\n",
      "  Iteration: 1/35, Loss: 0.55829, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.543325, Error: 0.2708\n",
      "  Iteration: 3/35, Loss: 0.47421, Error: 0.1875\n",
      "  Iteration: 4/35, Loss: 0.598762, Error: 0.2917\n",
      "  Iteration: 5/35, Loss: 0.541422, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.602433, Error: 0.3021\n",
      "  Iteration: 7/35, Loss: 0.553042, Error: 0.2604\n",
      "  Iteration: 8/35, Loss: 0.522712, Error: 0.2604\n",
      "  Iteration: 9/35, Loss: 0.571087, Error: 0.2917\n",
      "  Iteration: 10/35, Loss: 0.539142, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.560229, Error: 0.2396\n",
      "  Iteration: 12/35, Loss: 0.541927, Error: 0.2604\n",
      "  Iteration: 13/35, Loss: 0.6124, Error: 0.3125\n",
      "  Iteration: 14/35, Loss: 0.497794, Error: 0.2083\n",
      "  Iteration: 15/35, Loss: 0.495933, Error: 0.1875\n",
      "  Iteration: 16/35, Loss: 0.567055, Error: 0.2500\n",
      "  Iteration: 17/35, Loss: 0.533641, Error: 0.2396\n",
      "  Iteration: 18/35, Loss: 0.520217, Error: 0.2500\n",
      "  Iteration: 19/35, Loss: 0.501133, Error: 0.1979\n",
      "  Iteration: 20/35, Loss: 0.54006, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.666019, Error: 0.3542\n",
      "  Iteration: 22/35, Loss: 0.547743, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.55282, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.578985, Error: 0.2604\n",
      "  Iteration: 25/35, Loss: 0.603647, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.5559, Error: 0.2708\n",
      "  Iteration: 27/35, Loss: 0.538341, Error: 0.2396\n",
      "  Iteration: 28/35, Loss: 0.477423, Error: 0.1667\n",
      "  Iteration: 29/35, Loss: 0.535583, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.578931, Error: 0.2917\n",
      "  Iteration: 31/35, Loss: 0.576981, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.492015, Error: 0.2188\n",
      "  Iteration: 33/35, Loss: 0.588958, Error: 0.2812\n",
      "  Iteration: 34/35, Loss: 0.570267, Error: 0.2812\n",
      "  Iteration: 35/35, Loss: 0.612057, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2536\n",
      "Epoch: 95/100\n",
      "  Iteration: 1/35, Loss: 0.567888, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.507809, Error: 0.1979\n",
      "  Iteration: 3/35, Loss: 0.498203, Error: 0.2083\n",
      "  Iteration: 4/35, Loss: 0.591106, Error: 0.3021\n",
      "  Iteration: 5/35, Loss: 0.520195, Error: 0.2500\n",
      "  Iteration: 6/35, Loss: 0.559572, Error: 0.2500\n",
      "  Iteration: 7/35, Loss: 0.600931, Error: 0.2812\n",
      "  Iteration: 8/35, Loss: 0.549301, Error: 0.2500\n",
      "  Iteration: 9/35, Loss: 0.518555, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.509951, Error: 0.2292\n",
      "  Iteration: 11/35, Loss: 0.550466, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.497369, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.611672, Error: 0.2812\n",
      "  Iteration: 14/35, Loss: 0.541907, Error: 0.2083\n",
      "  Iteration: 15/35, Loss: 0.63362, Error: 0.3125\n",
      "  Iteration: 16/35, Loss: 0.589718, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.551032, Error: 0.2812\n",
      "  Iteration: 18/35, Loss: 0.57706, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.527455, Error: 0.2708\n",
      "  Iteration: 20/35, Loss: 0.538434, Error: 0.2396\n",
      "  Iteration: 21/35, Loss: 0.519787, Error: 0.2083\n",
      "  Iteration: 22/35, Loss: 0.51584, Error: 0.2396\n",
      "  Iteration: 23/35, Loss: 0.551928, Error: 0.2917\n",
      "  Iteration: 24/35, Loss: 0.528284, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.583699, Error: 0.2500\n",
      "  Iteration: 26/35, Loss: 0.572488, Error: 0.2604\n",
      "  Iteration: 27/35, Loss: 0.492164, Error: 0.2292\n",
      "  Iteration: 28/35, Loss: 0.551864, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.628162, Error: 0.3125\n",
      "  Iteration: 30/35, Loss: 0.514413, Error: 0.1979\n",
      "  Iteration: 31/35, Loss: 0.474922, Error: 0.1667\n",
      "  Iteration: 32/35, Loss: 0.533945, Error: 0.2396\n",
      "  Iteration: 33/35, Loss: 0.609386, Error: 0.3125\n",
      "  Iteration: 34/35, Loss: 0.554162, Error: 0.2604\n",
      "  Iteration: 35/35, Loss: 0.601771, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2518\n",
      "Epoch: 96/100\n",
      "  Iteration: 1/35, Loss: 0.605037, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.52993, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.48962, Error: 0.1667\n",
      "  Iteration: 4/35, Loss: 0.50495, Error: 0.1875\n",
      "  Iteration: 5/35, Loss: 0.521629, Error: 0.2188\n",
      "  Iteration: 6/35, Loss: 0.55738, Error: 0.2708\n",
      "  Iteration: 7/35, Loss: 0.589182, Error: 0.3021\n",
      "  Iteration: 8/35, Loss: 0.61805, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.514064, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.590326, Error: 0.2812\n",
      "  Iteration: 11/35, Loss: 0.553064, Error: 0.2604\n",
      "  Iteration: 12/35, Loss: 0.461953, Error: 0.1875\n",
      "  Iteration: 13/35, Loss: 0.533972, Error: 0.2188\n",
      "  Iteration: 14/35, Loss: 0.538942, Error: 0.2396\n",
      "  Iteration: 15/35, Loss: 0.594732, Error: 0.2812\n",
      "  Iteration: 16/35, Loss: 0.499021, Error: 0.2188\n",
      "  Iteration: 17/35, Loss: 0.663436, Error: 0.3438\n",
      "  Iteration: 18/35, Loss: 0.428167, Error: 0.1458\n",
      "  Iteration: 19/35, Loss: 0.568792, Error: 0.3021\n",
      "  Iteration: 20/35, Loss: 0.533145, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.51403, Error: 0.2188\n",
      "  Iteration: 22/35, Loss: 0.577519, Error: 0.2708\n",
      "  Iteration: 23/35, Loss: 0.549128, Error: 0.2396\n",
      "  Iteration: 24/35, Loss: 0.58192, Error: 0.2917\n",
      "  Iteration: 25/35, Loss: 0.549354, Error: 0.2604\n",
      "  Iteration: 26/35, Loss: 0.524832, Error: 0.2083\n",
      "  Iteration: 27/35, Loss: 0.613018, Error: 0.3125\n",
      "  Iteration: 28/35, Loss: 0.500209, Error: 0.2083\n",
      "  Iteration: 29/35, Loss: 0.511865, Error: 0.2500\n",
      "  Iteration: 30/35, Loss: 0.469173, Error: 0.1979\n",
      "  Iteration: 31/35, Loss: 0.526338, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.560148, Error: 0.2708\n",
      "  Iteration: 33/35, Loss: 0.627043, Error: 0.3125\n",
      "  Iteration: 34/35, Loss: 0.594776, Error: 0.2812\n",
      "  Iteration: 35/35, Loss: 0.638723, Error: 0.3500\n",
      "Average Error for this Epoch: 0.2523\n",
      "Epoch: 97/100\n",
      "  Iteration: 1/35, Loss: 0.592754, Error: 0.2708\n",
      "  Iteration: 2/35, Loss: 0.526325, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.530339, Error: 0.2083\n",
      "  Iteration: 4/35, Loss: 0.639407, Error: 0.2708\n",
      "  Iteration: 5/35, Loss: 0.534771, Error: 0.1979\n",
      "  Iteration: 6/35, Loss: 0.550411, Error: 0.2604\n",
      "  Iteration: 7/35, Loss: 0.583208, Error: 0.3125\n",
      "  Iteration: 8/35, Loss: 0.583925, Error: 0.2708\n",
      "  Iteration: 9/35, Loss: 0.562803, Error: 0.2917\n",
      "  Iteration: 10/35, Loss: 0.581396, Error: 0.2708\n",
      "  Iteration: 11/35, Loss: 0.621827, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.56884, Error: 0.2500\n",
      "  Iteration: 13/35, Loss: 0.64054, Error: 0.3333\n",
      "  Iteration: 14/35, Loss: 0.497393, Error: 0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 15/35, Loss: 0.558479, Error: 0.2708\n",
      "  Iteration: 16/35, Loss: 0.578847, Error: 0.3021\n",
      "  Iteration: 17/35, Loss: 0.518769, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.432948, Error: 0.1771\n",
      "  Iteration: 19/35, Loss: 0.590886, Error: 0.3021\n",
      "  Iteration: 20/35, Loss: 0.561518, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.529062, Error: 0.2292\n",
      "  Iteration: 22/35, Loss: 0.469722, Error: 0.2083\n",
      "  Iteration: 23/35, Loss: 0.521907, Error: 0.2083\n",
      "  Iteration: 24/35, Loss: 0.521443, Error: 0.2292\n",
      "  Iteration: 25/35, Loss: 0.564041, Error: 0.2708\n",
      "  Iteration: 26/35, Loss: 0.493139, Error: 0.1979\n",
      "  Iteration: 27/35, Loss: 0.587545, Error: 0.3021\n",
      "  Iteration: 28/35, Loss: 0.528405, Error: 0.2500\n",
      "  Iteration: 29/35, Loss: 0.557435, Error: 0.2604\n",
      "  Iteration: 30/35, Loss: 0.564487, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.502091, Error: 0.2292\n",
      "  Iteration: 32/35, Loss: 0.557912, Error: 0.2500\n",
      "  Iteration: 33/35, Loss: 0.645299, Error: 0.3229\n",
      "  Iteration: 34/35, Loss: 0.514909, Error: 0.2188\n",
      "  Iteration: 35/35, Loss: 0.487772, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2542\n",
      "Epoch: 98/100\n",
      "  Iteration: 1/35, Loss: 0.54204, Error: 0.2500\n",
      "  Iteration: 2/35, Loss: 0.573431, Error: 0.2812\n",
      "  Iteration: 3/35, Loss: 0.558017, Error: 0.2812\n",
      "  Iteration: 4/35, Loss: 0.545702, Error: 0.2292\n",
      "  Iteration: 5/35, Loss: 0.544701, Error: 0.2604\n",
      "  Iteration: 6/35, Loss: 0.56616, Error: 0.2917\n",
      "  Iteration: 7/35, Loss: 0.598979, Error: 0.2917\n",
      "  Iteration: 8/35, Loss: 0.593212, Error: 0.2917\n",
      "  Iteration: 9/35, Loss: 0.560983, Error: 0.2604\n",
      "  Iteration: 10/35, Loss: 0.476363, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.569781, Error: 0.2500\n",
      "  Iteration: 12/35, Loss: 0.501725, Error: 0.2188\n",
      "  Iteration: 13/35, Loss: 0.5823, Error: 0.2396\n",
      "  Iteration: 14/35, Loss: 0.480635, Error: 0.1771\n",
      "  Iteration: 15/35, Loss: 0.504497, Error: 0.2292\n",
      "  Iteration: 16/35, Loss: 0.542266, Error: 0.2812\n",
      "  Iteration: 17/35, Loss: 0.453296, Error: 0.1979\n",
      "  Iteration: 18/35, Loss: 0.624929, Error: 0.3125\n",
      "  Iteration: 19/35, Loss: 0.454909, Error: 0.1667\n",
      "  Iteration: 20/35, Loss: 0.499276, Error: 0.2292\n",
      "  Iteration: 21/35, Loss: 0.663085, Error: 0.3438\n",
      "  Iteration: 22/35, Loss: 0.574629, Error: 0.2604\n",
      "  Iteration: 23/35, Loss: 0.53639, Error: 0.2292\n",
      "  Iteration: 24/35, Loss: 0.634295, Error: 0.3125\n",
      "  Iteration: 25/35, Loss: 0.595118, Error: 0.2917\n",
      "  Iteration: 26/35, Loss: 0.565903, Error: 0.2500\n",
      "  Iteration: 27/35, Loss: 0.537341, Error: 0.2188\n",
      "  Iteration: 28/35, Loss: 0.541192, Error: 0.2292\n",
      "  Iteration: 29/35, Loss: 0.52354, Error: 0.2188\n",
      "  Iteration: 30/35, Loss: 0.543991, Error: 0.2292\n",
      "  Iteration: 31/35, Loss: 0.555327, Error: 0.2604\n",
      "  Iteration: 32/35, Loss: 0.619355, Error: 0.3333\n",
      "  Iteration: 33/35, Loss: 0.480638, Error: 0.1771\n",
      "  Iteration: 34/35, Loss: 0.501289, Error: 0.2292\n",
      "  Iteration: 35/35, Loss: 0.512895, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2492\n",
      "found a better model!\n",
      "Epoch: 99/100\n",
      "  Iteration: 1/35, Loss: 0.604423, Error: 0.2812\n",
      "  Iteration: 2/35, Loss: 0.630609, Error: 0.2917\n",
      "  Iteration: 3/35, Loss: 0.627367, Error: 0.3021\n",
      "  Iteration: 4/35, Loss: 0.511336, Error: 0.2188\n",
      "  Iteration: 5/35, Loss: 0.479079, Error: 0.2083\n",
      "  Iteration: 6/35, Loss: 0.498803, Error: 0.2396\n",
      "  Iteration: 7/35, Loss: 0.638552, Error: 0.3438\n",
      "  Iteration: 8/35, Loss: 0.525509, Error: 0.2812\n",
      "  Iteration: 9/35, Loss: 0.531096, Error: 0.2083\n",
      "  Iteration: 10/35, Loss: 0.523218, Error: 0.2604\n",
      "  Iteration: 11/35, Loss: 0.487347, Error: 0.2188\n",
      "  Iteration: 12/35, Loss: 0.559622, Error: 0.2812\n",
      "  Iteration: 13/35, Loss: 0.548694, Error: 0.2708\n",
      "  Iteration: 14/35, Loss: 0.591835, Error: 0.3229\n",
      "  Iteration: 15/35, Loss: 0.632261, Error: 0.3125\n",
      "  Iteration: 16/35, Loss: 0.506032, Error: 0.2188\n",
      "  Iteration: 17/35, Loss: 0.587132, Error: 0.2917\n",
      "  Iteration: 18/35, Loss: 0.595644, Error: 0.2812\n",
      "  Iteration: 19/35, Loss: 0.460626, Error: 0.1771\n",
      "  Iteration: 20/35, Loss: 0.641643, Error: 0.3438\n",
      "  Iteration: 21/35, Loss: 0.509472, Error: 0.1771\n",
      "  Iteration: 22/35, Loss: 0.592028, Error: 0.2812\n",
      "  Iteration: 23/35, Loss: 0.55686, Error: 0.2604\n",
      "  Iteration: 24/35, Loss: 0.509839, Error: 0.2396\n",
      "  Iteration: 25/35, Loss: 0.574674, Error: 0.2917\n",
      "  Iteration: 26/35, Loss: 0.486415, Error: 0.2083\n",
      "  Iteration: 27/35, Loss: 0.555999, Error: 0.2812\n",
      "  Iteration: 28/35, Loss: 0.637875, Error: 0.3438\n",
      "  Iteration: 29/35, Loss: 0.513102, Error: 0.2083\n",
      "  Iteration: 30/35, Loss: 0.580361, Error: 0.2812\n",
      "  Iteration: 31/35, Loss: 0.565089, Error: 0.2500\n",
      "  Iteration: 32/35, Loss: 0.567374, Error: 0.2812\n",
      "  Iteration: 33/35, Loss: 0.448971, Error: 0.1250\n",
      "  Iteration: 34/35, Loss: 0.470879, Error: 0.1771\n",
      "  Iteration: 35/35, Loss: 0.580665, Error: 0.2500\n",
      "Average Error for this Epoch: 0.2574\n",
      "Epoch: 100/100\n",
      "  Iteration: 1/35, Loss: 0.611594, Error: 0.3021\n",
      "  Iteration: 2/35, Loss: 0.558954, Error: 0.2396\n",
      "  Iteration: 3/35, Loss: 0.613104, Error: 0.2708\n",
      "  Iteration: 4/35, Loss: 0.530059, Error: 0.2604\n",
      "  Iteration: 5/35, Loss: 0.590177, Error: 0.2708\n",
      "  Iteration: 6/35, Loss: 0.552236, Error: 0.2604\n",
      "  Iteration: 7/35, Loss: 0.546538, Error: 0.2396\n",
      "  Iteration: 8/35, Loss: 0.472101, Error: 0.1667\n",
      "  Iteration: 9/35, Loss: 0.527973, Error: 0.2292\n",
      "  Iteration: 10/35, Loss: 0.443338, Error: 0.1979\n",
      "  Iteration: 11/35, Loss: 0.565597, Error: 0.2917\n",
      "  Iteration: 12/35, Loss: 0.60878, Error: 0.3021\n",
      "  Iteration: 13/35, Loss: 0.516077, Error: 0.2292\n",
      "  Iteration: 14/35, Loss: 0.587539, Error: 0.2917\n",
      "  Iteration: 15/35, Loss: 0.536229, Error: 0.2500\n",
      "  Iteration: 16/35, Loss: 0.484449, Error: 0.1979\n",
      "  Iteration: 17/35, Loss: 0.57703, Error: 0.2604\n",
      "  Iteration: 18/35, Loss: 0.487465, Error: 0.2188\n",
      "  Iteration: 19/35, Loss: 0.549706, Error: 0.2292\n",
      "  Iteration: 20/35, Loss: 0.528695, Error: 0.2500\n",
      "  Iteration: 21/35, Loss: 0.566674, Error: 0.2396\n",
      "  Iteration: 22/35, Loss: 0.421032, Error: 0.1250\n",
      "  Iteration: 23/35, Loss: 0.670196, Error: 0.3125\n",
      "  Iteration: 24/35, Loss: 0.495495, Error: 0.2188\n",
      "  Iteration: 25/35, Loss: 0.611415, Error: 0.3125\n",
      "  Iteration: 26/35, Loss: 0.628458, Error: 0.3438\n",
      "  Iteration: 27/35, Loss: 0.55677, Error: 0.2708\n",
      "  Iteration: 28/35, Loss: 0.572772, Error: 0.2812\n",
      "  Iteration: 29/35, Loss: 0.524778, Error: 0.2292\n",
      "  Iteration: 30/35, Loss: 0.547769, Error: 0.2708\n",
      "  Iteration: 31/35, Loss: 0.602707, Error: 0.2917\n",
      "  Iteration: 32/35, Loss: 0.470289, Error: 0.1667\n",
      "  Iteration: 33/35, Loss: 0.526255, Error: 0.2500\n",
      "  Iteration: 34/35, Loss: 0.599941, Error: 0.3125\n",
      "  Iteration: 35/35, Loss: 0.502489, Error: 0.2000\n",
      "Average Error for this Epoch: 0.2510\n"
     ]
    }
   ],
   "source": [
    "model.train()     # training mode\n",
    "if not use_previous_best_model:\n",
    "    avg_error = 0\n",
    "    best_avg_error = 1\n",
    "\n",
    "avg_error_vec = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: %d/%d\" % (epoch+1, num_epochs))\n",
    "\n",
    "    for i, (samples, labels) in enumerate(train_loader):\n",
    "        samples = Variable(samples)\n",
    "        labels = Variable(labels)\n",
    "        output = model(samples)                # forward pass\n",
    "        output = torch.flatten(output)         # resize predicted labels\n",
    "        labels = labels.type(torch.DoubleTensor)\n",
    "        \n",
    "        loss = criterion(output, labels)  # calculate loss\n",
    "        optimizer.zero_grad()     # clear gradient\n",
    "        loss.backward()           # calculate gradients\n",
    "        optimizer.step()          # update weights\n",
    "        \n",
    "        # calculate and print error\n",
    "        out = output\n",
    "\n",
    "        for j in range(0, out.size()[0]):\n",
    "            if out[j] < 0.5:\n",
    "                out[j] = 0\n",
    "            else:\n",
    "                out[j] = 1\n",
    "        error = 1 - torch.sum(output == labels).item() / labels.size()[0]\n",
    "        avg_error += error\n",
    "\n",
    "        print(\"  Iteration: %d/%d, Loss: %g, Error: %0.4f\" % \n",
    "              (i+1, np.ceil(X_train.size()[0] / batch_size).astype(int), loss.item(), error))\n",
    "    \n",
    "    avg_error = avg_error / np.ceil(X_train.size()[0] / batch_size)\n",
    "    avg_error_vec.append(avg_error)\n",
    "    print(\"Average Error for this Epoch: %0.4f\" % avg_error)\n",
    "\n",
    "    if avg_error < best_avg_error:\n",
    "        print(\"found a better model!\")\n",
    "        best_avg_error = avg_error\n",
    "        best_model = copy.deepcopy(model)\n",
    "        use_previous_best_model = True\n",
    "    \n",
    "    avg_error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(start=1, stop=num_epochs, num=num_epochs), avg_error_vec)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Average Training Error\")\n",
    "plt.title(\"Average Training Error for Epochs=1:100\")\n",
    "plt.grid(True)\n",
    "# plt.savefig(\"Neural Net Training Error.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Error: 0.1711\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "\n",
    "for i, (samples, labels) in enumerate(test_loader):\n",
    "    samples = Variable(samples)\n",
    "    labels = Variable(labels)\n",
    "    predictions = best_model(samples)\n",
    "    predictions = torch.flatten(predictions)\n",
    "    labels = labels.type(torch.DoubleTensor)\n",
    "\n",
    "    for j in range(0, predictions.size()[0]):\n",
    "        if predictions[j] < 0.5:\n",
    "            predictions[j] = 0\n",
    "        else:\n",
    "            predictions[j] = 1\n",
    "    \n",
    "    error = 1 - torch.sum(predictions == labels).item() / labels.size()[0]\n",
    "    \n",
    "    print(\"Testing set Error: %0.4f\" % error)\n",
    "    \n",
    "model_path = dest_path + \"torch_model_4_4_19_lr=\" + str(learning_rate) + \"_hourly_dict.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Evaluate previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Error: 0.1590\n"
     ]
    }
   ],
   "source": [
    "model = CLANet(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(dest_path + \"torch_model_4_4_19_lr=0.001_hourly_dict.pt\"))\n",
    "model.double()     # cast model parameters to double\n",
    "model.eval()\n",
    "\n",
    "for i, (samples, labels) in enumerate(test_loader):\n",
    "    samples = Variable(samples)\n",
    "    labels = Variable(labels)\n",
    "    conf = model(samples)\n",
    "    conf = torch.flatten(conf)\n",
    "    labels = labels.type(torch.DoubleTensor)\n",
    "    \n",
    "    for j in range(conf.size()[0]):\n",
    "        if conf[j] < 0.5:\n",
    "            conf[j] = 0\n",
    "        else:\n",
    "            conf[j] = 1\n",
    "                \n",
    "    error = 1 - torch.sum(conf == labels).item() / labels.size()[0]\n",
    "    \n",
    "    print(\"Testing set Error: %0.4f\" % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLANet(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(dest_path + \"torch_model_4_4_19_lr=0.001_hourly_dict.pt\"))\n",
    "model.double()     # cast model parameters to double\n",
    "model.eval()\n",
    "\n",
    "for i, (samples, labels) in enumerate(test_loader):\n",
    "    samples = Variable(samples)\n",
    "    labels = Variable(labels)\n",
    "    conf = model(samples)    # confidence that a certain instance is predicted correctly\n",
    "    conf = torch.flatten(conf)\n",
    "    labels = labels.type(torch.DoubleTensor)\n",
    "    \n",
    "# convert to numpy arrays\n",
    "conf = conf.detach().numpy()\n",
    "labels = labels.numpy()\n",
    "\n",
    "# sort arrays according to the predicted confidence (high confidence to low confidence)\n",
    "sort_idx = np.argsort(-conf, kind='mergesort')\n",
    "conf = conf[sort_idx]\n",
    "labels = labels[sort_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_pos = 0\n",
    "num_neg = 0\n",
    "\n",
    "for label in labels:\n",
    "    if label < 0.5:\n",
    "        num_neg += 1\n",
    "    else:\n",
    "        num_pos += 1\n",
    "        \n",
    "tp = 0\n",
    "fp = 0\n",
    "last_tp = 0\n",
    "fpr = []\n",
    "tpr = []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if (i > 1) and (conf[i] != conf[i-1]) and (labels[i] == 0) and (tp > last_tp):\n",
    "        fpr.append(fp / num_neg)\n",
    "        tpr.append(tp / num_pos)\n",
    "        last_tp = tp\n",
    "    if labels[i] == 1:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "        \n",
    "fpr.append(fp / num_neg)\n",
    "tpr.append(tp / num_pos)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Postive Rate (FPR)', fontsize=20)\n",
    "plt.ylabel('True Positive Rate (TPR)', fontsize=20)\n",
    "plt.axis([0, 1, 0.6, 1.001])\n",
    "plt.title('ROC Curve', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (samples, labels) in enumerate(test_loader):\n",
    "    samples = Variable(samples)\n",
    "    labels = Variable(labels)\n",
    "    pred = model(samples)\n",
    "    pred = torch.flatten(pred)\n",
    "    labels = labels.type(torch.DoubleTensor)\n",
    "\n",
    "# convert to numpy arrays\n",
    "pred = pred.detach().numpy()\n",
    "labels = labels.numpy()\n",
    "\n",
    "# sort arrays according to the predicted confidence (high confidence to low confidence)\n",
    "sort_idx = np.argsort(-pred, kind='mergesort')\n",
    "pred = pred[sort_idx]\n",
    "labels = labels[sort_idx]\n",
    "\n",
    "num_pred_pos = 0\n",
    "num_actual_pos = 0\n",
    "num_tp = 0\n",
    "precision = []\n",
    "recall = []\n",
    "\n",
    "for confidence in conf:\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] >= confidence:\n",
    "            num_pred_pos += 1\n",
    "            \n",
    "            if labels[i] == 1:\n",
    "                num_tp += 1\n",
    "        \n",
    "        if labels[i] == 1:\n",
    "            num_actual_pos += 1\n",
    "\n",
    "    precision.append(num_tp / num_pred_pos)\n",
    "    recall.append(num_tp / num_actual_pos)\n",
    "    \n",
    "    num_pred_pos = 0\n",
    "    num_actual_pos = 0\n",
    "    num_tp = 0\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall', fontsize=20)\n",
    "plt.ylabel('Precision', fontsize=20)\n",
    "plt.axis([0, 1.001, 0.4, 1])\n",
    "plt.title('PR Curve', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test best model on other data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data path\n",
    "data_path = \"/Users/Alliot/Documents/CLA-Project/Data/hourly-data-sets/\"\n",
    "data_set = \"hourly_data_2014\"\n",
    "\n",
    "# load data sets\n",
    "X = np.load(data_path + data_set + \".npy\")\n",
    "y = np.load(data_path + data_set + \"_labels.npy\")\n",
    "\n",
    "# manipulate data set. labels are converted to 0, +1 for binary classification; samples are removed uniformly \n",
    "# from the data set so that the disproportionately large number of negative samples (no algae) does \n",
    "# not bias the model.\n",
    "\n",
    "num_alg = 0  # count the number of algae instances\n",
    "num_no_alg = 0  # count the number of no algae instances\n",
    "\n",
    "# Convert labels to binary: -1 for no algae and 1 for algae\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == 0:\n",
    "        num_no_alg += 1\n",
    "    if y[i] == 1 or y[i] == 2:\n",
    "        y[i] = 1\n",
    "        num_alg += 1\n",
    "\n",
    "# oversample the data set by randomly adding occurences of algae until the difference between the number of algae\n",
    "# samples and no algae samples equals sample_bias (defined below)\n",
    "idx = 0\n",
    "sample_bias = 0\n",
    "length_y = len(y)\n",
    "while num_alg != (num_no_alg + sample_bias):\n",
    "    # circle through the data sets until the difference of num_no_alg and num_alg equals\n",
    "    # the value specified by sample_bias\n",
    "    if idx == (length_y - 1):\n",
    "        idx = 0\n",
    "\n",
    "    if y[idx] == 1:\n",
    "        if np.random.rand() >= 0.5:  # add this sample with some probability\n",
    "            y = np.append(y, y[idx])\n",
    "            X = np.append(X, np.reshape(X[idx, :], newshape=(1, num_features)), axis=0)\n",
    "            num_alg += 1\n",
    "        else:\n",
    "            idx += 1\n",
    "    else:\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '28.95s'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-57bdc54988ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mscale\u001b[0;34m(X, axis, with_mean, with_std, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m     X = check_array(X, accept_sparse='csc', copy=copy, ensure_2d=False,\n\u001b[1;32m    144\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'the scale function'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                     dtype=FLOAT_DTYPES, force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '28.95s'"
     ]
    }
   ],
   "source": [
    "# standardize data: remove the mean and variance in each sample\n",
    "num_splits = 2   # do not change\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=num_splits, test_size=test_size)\n",
    "\n",
    "idx, _ = sss.split(X, y);\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "X_train = preprocessing.scale(X_train, axis=1, with_mean=True, with_std=True)\n",
    "X_test = preprocessing.scale(X_test, axis=1, with_mean=True, with_std=True)\n",
    "\n",
    "# convert numpy arrays to pytorch tensors\n",
    "train_set_size = X_train.shape\n",
    "test_set_size = X_test.shape\n",
    "X_train, X_test = torch.from_numpy(X_train), torch.from_numpy(X_test)\n",
    "y_train, y_test = torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "\n",
    "# convert pytorch tensors to pytorch TensorDataset\n",
    "train_set = utils.TensorDataset(X_train, y_train)\n",
    "test_set = utils.TensorDataset(X_test, y_test)\n",
    "\n",
    "# create DataLoaders\n",
    "train_loader = utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = utils.DataLoader(test_set, batch_size=test_set_size[0], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (samples, labels) in enumerate(test_loader):\n",
    "    samples = Variable(samples)\n",
    "    labels = Variable(labels)\n",
    "    conf = model(samples)\n",
    "    conf = torch.flatten(conf)\n",
    "    labels = labels.type(torch.DoubleTensor)\n",
    "    \n",
    "    for j in range(conf.size()[0]):\n",
    "        if conf[j] < 0.5:\n",
    "            conf[j] = 0\n",
    "        else:\n",
    "            conf[j] = 1\n",
    "                \n",
    "    error = 1 - torch.sum(conf == labels).item() / labels.size()[0]\n",
    "    \n",
    "    print(\"Testing set Error: %0.4f\" % error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer parameter adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups:\n",
    "    p[\"lr\"] = 0.003\n",
    "    p[\"momentum\"] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups:\n",
    "    p[\"lr\"] = 0.001\n",
    "    p[\"momentum\"] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups:\n",
    "    p[\"lr\"] = 0.00001\n",
    "    p[\"momentum\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups:\n",
    "    p[\"lr\"] = 0.0000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in optimizer.param_groups:\n",
    "    p[\"lr\"] = 0.0003\n",
    "    p[\"momentum\"] = 0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
