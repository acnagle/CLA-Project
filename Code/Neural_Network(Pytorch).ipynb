{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for CLA Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "import errno\n",
    "import os\n",
    "import sys\n",
    "import Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "sample_bias = 0     # adjust the difference in the number of the two types of samples (no algae vs algae)\n",
    "test_size = 0.2\n",
    "batch_size = 1000    # batch size for the DataLoaders\n",
    "\n",
    "# NN model\n",
    "num_features = 17\n",
    "input_size = num_features     # size of input layer\n",
    "multiplier = 12               # multiplied by num_features to determine the size of each hidden layer\n",
    "learning_rate = 0.001         # learning rate of optimizer\n",
    "num_epochs = 3                # number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)  # prints a full matrix rather than an abbreviated matrix\n",
    "\n",
    "# define data and destination paths\n",
    "dest_path = \"/Users/Alliot/Documents/CLA-Project/Data/all-data-no-na/neural-network/\"\n",
    "data_path = \"/Users/Alliot/Documents/CLA-Project/Data/data-sets/\"\n",
    "data_set = \"data_2017_summer\"\n",
    "\n",
    "# if dest_path does not exist, create it\n",
    "if not os.path.exists(dest_path):\n",
    "    try:\n",
    "        os.makedirs(dest_path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "# load data sets\n",
    "X = np.load(data_path + data_set + \".npy\")\n",
    "y = np.load(data_path + data_set + \"_labels.npy\")\n",
    "\n",
    "# manipulate data set. labels are converted to -1, +1 for binary classification; samples are removed uniformly \n",
    "# from the data set so that the disproportionately large number of negative samples (no algae) does \n",
    "# not bias the model.\n",
    "\n",
    "num_alg = 0  # count the number of algae instances\n",
    "num_no_alg = 0  # count the number of no algae instances\n",
    "\n",
    "# Convert labels to binary: -1 for no algae and 1 for algae\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == 0:\n",
    "        y[i] = -1\n",
    "        num_no_alg += 1\n",
    "    if y[i] == 1 or y[i] == 2:\n",
    "        y[i] = 1\n",
    "        num_alg += 1\n",
    "\n",
    "# shrink the data set by randomly removing occurences of no algae until the number of no algae samples equals the\n",
    "# number of algae samples minus the sample_bias\n",
    "idx = 0  # index for the data set\n",
    "while num_no_alg != (num_alg - sample_bias):\n",
    "    # circle through the data set until the difference of num_no_alg and num_alg equals\n",
    "    # the value specified by sample_bias\n",
    "    if idx == (len(y) - 1):\n",
    "        idx = 0\n",
    "        \n",
    "    if y[idx] == -1:\n",
    "        if np.random.rand() >= 0.5:  # remove this sample with some probability\n",
    "            y = np.delete(y, obj=idx)\n",
    "            X = np.delete(X, obj=idx, axis=Constants.ROWS)\n",
    "            num_no_alg -= 1\n",
    "        else:\n",
    "            idx += 1\n",
    "    else:\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data: remove the mean and variance in each sample\n",
    "\n",
    "# TEST DATA DELETE THIS\n",
    "num_test_samples = 47000\n",
    "X = 100*np.random.rand(num_test_samples, 17)\n",
    "y = np.random.randint(2, size=num_test_samples);\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == 0:\n",
    "        y[i] = -1\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "num_splits = 2   # do not change\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=num_splits, test_size=test_size)\n",
    "\n",
    "idx, _ = sss.split(X, y);\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "X_train = preprocessing.scale(X_train, axis=1, with_mean=True, with_std=True)\n",
    "X_test = preprocessing.scale(X_test, axis=1, with_mean=True, with_std=True)\n",
    "\n",
    "# convert numpy arrays to pytorch tensors\n",
    "X_train, X_test = torch.from_numpy(X_train), torch.from_numpy(X_test)\n",
    "y_train, y_test = torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "\n",
    "# convert pytorch tensors to pytorch TensorDataset\n",
    "train_set = utils.TensorDataset(X_train, y_train)\n",
    "test_set = utils.TensorDataset(X_test, y_test)\n",
    "\n",
    "# create DataLoaders\n",
    "train_loader = utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = utils.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLANet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CLANet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu4 = nn.ReLU()\n",
    "#         self.fc5 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu5 = nn.ReLU()\n",
    "#         self.fc6 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu6 = nn.ReLU()\n",
    "#         self.fc7 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu7 = nn.ReLU()\n",
    "#         self.fc8 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu8 = nn.ReLU()\n",
    "#         self.fc9 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu9 = nn.ReLU()\n",
    "#         self.fc10 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu10 = nn.ReLU()\n",
    "#         self.fc11 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu11 = nn.ReLU()\n",
    "#         self.fc12 = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "#         out = self.relu2(out)\n",
    "#         out = self.fc3(out)\n",
    "#         out = self.relu3(out)\n",
    "#         out = self.fc4(out)\n",
    "#         out = self.relu4(out)\n",
    "#         out = self.fc5(out)\n",
    "#         out = self.relu5(out)\n",
    "#         out = self.fc6(out)\n",
    "#         out = self.relu6(out)\n",
    "#         out = self.fc7(out)\n",
    "#         out = self.relu7(out)\n",
    "#         out = self.fc8(out)\n",
    "#         out = self.relu8(out)\n",
    "#         out = self.fc9(out)\n",
    "#         out = self.relu9(out)\n",
    "#         out = self.fc10(out)\n",
    "#         out = self.relu10(out)\n",
    "#         out = self.fc11(out)\n",
    "#         out = self.relu11(out)\n",
    "#         out = self.fc12(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLANet(num_features, multiplier * num_features, 1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, nesterov=True, momentum=0.9, dampening=0)\n",
    "model.double();     # cast model parameters to double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3\n",
      "  Iteration: 1/38, Error: 0.5050, Loss: 0.946262\n",
      "  Iteration: 2/38, Error: 0.4880, Loss: 0.905262\n",
      "  Iteration: 3/38, Error: 0.4900, Loss: 0.874262\n",
      "  Iteration: 4/38, Error: 0.4870, Loss: 0.916262\n",
      "  Iteration: 5/38, Error: 0.4790, Loss: 0.915262\n",
      "  Iteration: 6/38, Error: 0.4970, Loss: 0.916262\n",
      "  Iteration: 7/38, Error: 0.4920, Loss: 0.908262\n",
      "  Iteration: 8/38, Error: 0.4960, Loss: 0.933262\n",
      "  Iteration: 9/38, Error: 0.4930, Loss: 0.910262\n",
      "  Iteration: 10/38, Error: 0.4980, Loss: 0.909262\n",
      "  Iteration: 11/38, Error: 0.5030, Loss: 0.927262\n",
      "  Iteration: 12/38, Error: 0.4800, Loss: 0.887262\n",
      "  Iteration: 13/38, Error: 0.5090, Loss: 0.916262\n",
      "  Iteration: 14/38, Error: 0.5150, Loss: 0.919262\n",
      "  Iteration: 15/38, Error: 0.5210, Loss: 0.962262\n",
      "  Iteration: 16/38, Error: 0.5220, Loss: 0.953262\n",
      "  Iteration: 17/38, Error: 0.5090, Loss: 0.939262\n",
      "  Iteration: 18/38, Error: 0.4880, Loss: 0.900262\n",
      "  Iteration: 19/38, Error: 0.4980, Loss: 0.912262\n",
      "  Iteration: 20/38, Error: 0.4930, Loss: 0.907262\n",
      "  Iteration: 21/38, Error: 0.4840, Loss: 0.899262\n",
      "  Iteration: 22/38, Error: 0.4710, Loss: 0.880262\n",
      "  Iteration: 23/38, Error: 0.4810, Loss: 0.885262\n",
      "  Iteration: 24/38, Error: 0.5010, Loss: 0.914262\n",
      "  Iteration: 25/38, Error: 0.4700, Loss: 0.867262\n",
      "  Iteration: 26/38, Error: 0.4930, Loss: 0.918262\n",
      "  Iteration: 27/38, Error: 0.4750, Loss: 0.892262\n",
      "  Iteration: 28/38, Error: 0.4820, Loss: 0.883262\n",
      "  Iteration: 29/38, Error: 0.5100, Loss: 0.951262\n",
      "  Iteration: 30/38, Error: 0.4860, Loss: 0.900262\n",
      "  Iteration: 31/38, Error: 0.5160, Loss: 0.954262\n",
      "  Iteration: 32/38, Error: 0.5030, Loss: 0.951262\n",
      "  Iteration: 33/38, Error: 0.5200, Loss: 0.950262\n",
      "  Iteration: 34/38, Error: 0.5160, Loss: 0.971262\n",
      "  Iteration: 35/38, Error: 0.4790, Loss: 0.907262\n",
      "  Iteration: 36/38, Error: 0.4870, Loss: 0.906262\n",
      "  Iteration: 37/38, Error: 0.4790, Loss: 0.869262\n",
      "  Iteration: 38/38, Error: 0.4983, Loss: 0.903262\n",
      "Epoch: 2/3\n",
      "  Iteration: 1/38, Error: 0.4860, Loss: 0.911262\n",
      "  Iteration: 2/38, Error: 0.5090, Loss: 0.923262\n",
      "  Iteration: 3/38, Error: 0.4870, Loss: 0.919262\n",
      "  Iteration: 4/38, Error: 0.4810, Loss: 0.904262\n",
      "  Iteration: 5/38, Error: 0.5100, Loss: 0.965262\n",
      "  Iteration: 6/38, Error: 0.5000, Loss: 0.931262\n",
      "  Iteration: 7/38, Error: 0.5130, Loss: 0.945262\n",
      "  Iteration: 8/38, Error: 0.5050, Loss: 0.924262\n",
      "  Iteration: 9/38, Error: 0.5150, Loss: 0.968262\n",
      "  Iteration: 10/38, Error: 0.5140, Loss: 0.962262\n",
      "  Iteration: 11/38, Error: 0.4970, Loss: 0.903262\n",
      "  Iteration: 12/38, Error: 0.4540, Loss: 0.810262\n",
      "  Iteration: 13/38, Error: 0.5020, Loss: 0.912262\n",
      "  Iteration: 14/38, Error: 0.4890, Loss: 0.869262\n",
      "  Iteration: 15/38, Error: 0.5200, Loss: 0.993262\n",
      "  Iteration: 16/38, Error: 0.5000, Loss: 0.929262\n",
      "  Iteration: 17/38, Error: 0.4830, Loss: 0.853262\n",
      "  Iteration: 18/38, Error: 0.4850, Loss: 0.902262\n",
      "  Iteration: 19/38, Error: 0.4800, Loss: 0.859262\n",
      "  Iteration: 20/38, Error: 0.4990, Loss: 0.944262\n",
      "  Iteration: 21/38, Error: 0.5000, Loss: 0.931262\n",
      "  Iteration: 22/38, Error: 0.4900, Loss: 0.888262\n",
      "  Iteration: 23/38, Error: 0.4910, Loss: 0.900262\n",
      "  Iteration: 24/38, Error: 0.5050, Loss: 0.946262\n",
      "  Iteration: 25/38, Error: 0.4960, Loss: 0.921262\n",
      "  Iteration: 26/38, Error: 0.5070, Loss: 0.954262\n",
      "  Iteration: 27/38, Error: 0.4800, Loss: 0.898262\n",
      "  Iteration: 28/38, Error: 0.4810, Loss: 0.918262\n",
      "  Iteration: 29/38, Error: 0.4900, Loss: 0.882262\n",
      "  Iteration: 30/38, Error: 0.4870, Loss: 0.902262\n",
      "  Iteration: 31/38, Error: 0.5120, Loss: 0.957262\n",
      "  Iteration: 32/38, Error: 0.5090, Loss: 0.947262\n",
      "  Iteration: 33/38, Error: 0.4960, Loss: 0.925262\n",
      "  Iteration: 34/38, Error: 0.5070, Loss: 0.943262\n",
      "  Iteration: 35/38, Error: 0.4780, Loss: 0.875262\n",
      "  Iteration: 36/38, Error: 0.4960, Loss: 0.907262\n",
      "  Iteration: 37/38, Error: 0.4660, Loss: 0.851262\n",
      "  Iteration: 38/38, Error: 0.4917, Loss: 0.869928\n",
      "Epoch: 3/3\n",
      "  Iteration: 1/38, Error: 0.4910, Loss: 0.891262\n",
      "  Iteration: 2/38, Error: 0.5090, Loss: 0.913262\n",
      "  Iteration: 3/38, Error: 0.5010, Loss: 0.903262\n",
      "  Iteration: 4/38, Error: 0.4830, Loss: 0.888262\n",
      "  Iteration: 5/38, Error: 0.5240, Loss: 0.972262\n",
      "  Iteration: 6/38, Error: 0.4990, Loss: 0.923262\n",
      "  Iteration: 7/38, Error: 0.4870, Loss: 0.896262\n",
      "  Iteration: 8/38, Error: 0.4750, Loss: 0.880262\n",
      "  Iteration: 9/38, Error: 0.5220, Loss: 0.998262\n",
      "  Iteration: 10/38, Error: 0.5160, Loss: 0.964262\n",
      "  Iteration: 11/38, Error: 0.4830, Loss: 0.893262\n",
      "  Iteration: 12/38, Error: 0.4930, Loss: 0.875262\n",
      "  Iteration: 13/38, Error: 0.5060, Loss: 0.956262\n",
      "  Iteration: 14/38, Error: 0.4990, Loss: 0.926262\n",
      "  Iteration: 15/38, Error: 0.4880, Loss: 0.904262\n",
      "  Iteration: 16/38, Error: 0.4690, Loss: 0.862262\n",
      "  Iteration: 17/38, Error: 0.4910, Loss: 0.934262\n",
      "  Iteration: 18/38, Error: 0.4890, Loss: 0.925262\n",
      "  Iteration: 19/38, Error: 0.4750, Loss: 0.851262\n",
      "  Iteration: 20/38, Error: 0.5030, Loss: 0.930262\n",
      "  Iteration: 21/38, Error: 0.4980, Loss: 0.958262\n",
      "  Iteration: 22/38, Error: 0.4990, Loss: 0.925262\n",
      "  Iteration: 23/38, Error: 0.4830, Loss: 0.898262\n",
      "  Iteration: 24/38, Error: 0.4940, Loss: 0.885262\n",
      "  Iteration: 25/38, Error: 0.4850, Loss: 0.894262\n",
      "  Iteration: 26/38, Error: 0.4670, Loss: 0.829262\n",
      "  Iteration: 27/38, Error: 0.5060, Loss: 0.949262\n",
      "  Iteration: 28/38, Error: 0.4860, Loss: 0.887262\n",
      "  Iteration: 29/38, Error: 0.5000, Loss: 0.912262\n",
      "  Iteration: 30/38, Error: 0.4880, Loss: 0.893262\n",
      "  Iteration: 31/38, Error: 0.4890, Loss: 0.871262\n",
      "  Iteration: 32/38, Error: 0.5160, Loss: 0.968262\n",
      "  Iteration: 33/38, Error: 0.4960, Loss: 0.941262\n",
      "  Iteration: 34/38, Error: 0.5230, Loss: 0.975262\n",
      "  Iteration: 35/38, Error: 0.4870, Loss: 0.908262\n",
      "  Iteration: 36/38, Error: 0.4800, Loss: 0.863262\n",
      "  Iteration: 37/38, Error: 0.5280, Loss: 1.00226\n",
      "  Iteration: 38/38, Error: 0.4783, Loss: 0.918262\n"
     ]
    }
   ],
   "source": [
    "model.train()     # training mode\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: %d/%d\" %(epoch+1, num_epochs))\n",
    "    \n",
    "    for i, (samples, labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()     # clear gradient\n",
    "        \n",
    "        output = torch.sign(model(samples))    # forward pass\n",
    "        output = torch.flatten(output)         # resize predicted labels\n",
    "        labels = labels.type(torch.DoubleTensor)\n",
    "        \n",
    "        loss = criterion(output, labels)  # calculate loss\n",
    "        loss.backward()           # calculate gradients\n",
    "        optimizer.step()          # update weights\n",
    "        \n",
    "        # calculate and print error\n",
    "        error = 1 - torch.sum(output == labels).item() / labels.size()[0]\n",
    "        print(\"  Iteration: %d/%d, Error: %0.4f, Loss: %g\" % \n",
    "              (i+1, np.ceil(X_train.size()[0] / batch_size).astype(int), error, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
