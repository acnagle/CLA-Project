{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for CLA Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as utils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import errno\n",
    "import os\n",
    "import sys\n",
    "import Constants\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "sample_bias = 0     # adjust the difference in the number of the two types of samples (no algae vs algae)\n",
    "test_size = 0.2\n",
    "batch_size = 100    # batch size for the DataLoaders. previously was 100\n",
    "\n",
    "# NN model\n",
    "num_features = 17\n",
    "input_size = num_features     # size of input layer\n",
    "multiplier = 100         # multiplied by num_features to determine the size of each hidden layer. previously was 100\n",
    "hidden_size = multiplier * input_size\n",
    "output_size = 1\n",
    "learning_rate = 0.01         # learning rate of optimizer. previously was 0.01\n",
    "num_epochs = 100                # number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)  # prints a full matrix rather than an abbreviated matrix\n",
    "\n",
    "# define data and destination paths\n",
    "dest_path = \"/Users/Alliot/Documents/CLA-Project/Data/all-data-no-na/neural-network/\"\n",
    "data_path = \"/Users/Alliot/Documents/CLA-Project/Data/data-sets/\"\n",
    "data_set = \"data_2017_summer\"\n",
    "\n",
    "# if dest_path does not exist, create it\n",
    "if not os.path.exists(dest_path):\n",
    "    try:\n",
    "        os.makedirs(dest_path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "# load data sets\n",
    "X = np.load(data_path + data_set + \".npy\")\n",
    "y = np.load(data_path + data_set + \"_labels.npy\")\n",
    "\n",
    "# manipulate data set. labels are converted to -1, +1 for binary classification; samples are removed uniformly \n",
    "# from the data set so that the disproportionately large number of negative samples (no algae) does \n",
    "# not bias the model.\n",
    "\n",
    "num_alg = 0  # count the number of algae instances\n",
    "num_no_alg = 0  # count the number of no algae instances\n",
    "\n",
    "# Convert labels to binary: -1 for no algae and 1 for algae\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == 0:\n",
    "        num_no_alg += 1\n",
    "    if y[i] == 1 or y[i] == 2:\n",
    "        y[i] = 1\n",
    "        num_alg += 1\n",
    "\n",
    "# oversample the data set by randomly adding occurences of algae until the difference between the number of algae\n",
    "# samples and no algae samples equals sample_bias (defined below)\n",
    "idx = 0\n",
    "sample_bias = 0\n",
    "length_y = len(y)\n",
    "while num_alg != (num_no_alg + sample_bias):\n",
    "    # circle through the data sets until the difference of num_no_alg and num_alg equals\n",
    "    # the value specified by sample_bias\n",
    "    if idx == (length_y - 1):\n",
    "        idx = 0\n",
    "\n",
    "    if y[idx] == 1:\n",
    "        if np.random.rand() >= 0.5:  # add this sample with some probability\n",
    "            y = np.append(y, y[idx])\n",
    "            X = np.append(X, np.reshape(X[idx, :], newshape=(1, num_features)), axis=0)\n",
    "            num_alg += 1\n",
    "        else:\n",
    "            idx += 1\n",
    "    else:\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data: remove the mean and variance in each sample\n",
    "num_splits = 2   # do not change\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=num_splits, test_size=test_size)\n",
    "\n",
    "idx, _ = sss.split(X, y);\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "X_train = preprocessing.scale(X_train, axis=1, with_mean=True, with_std=True)\n",
    "X_test = preprocessing.scale(X_test, axis=1, with_mean=True, with_std=True)\n",
    "\n",
    "# convert numpy arrays to pytorch tensors\n",
    "train_set_size = X_train.shape\n",
    "test_set_size = X_test.shape\n",
    "X_train, X_test = torch.from_numpy(X_train), torch.from_numpy(X_test)\n",
    "y_train, y_test = torch.from_numpy(y_train), torch.from_numpy(y_test)\n",
    "\n",
    "# convert pytorch tensors to pytorch TensorDataset\n",
    "train_set = utils.TensorDataset(X_train, y_train)\n",
    "test_set = utils.TensorDataset(X_test, y_test)\n",
    "\n",
    "# create DataLoaders\n",
    "train_loader = utils.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = utils.DataLoader(test_set, batch_size=test_set_size[0], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLANet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(CLANet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc5 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc6 = nn.Linear(hidden_size, hidden_size)     # previously, this was output_size\n",
    "        self.relu6 = nn.ReLU()                             # previously, this was the line which was commented out\n",
    "        self.fc7 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu7 = nn.ReLU()\n",
    "        self.fc8 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu8 = nn.ReLU()\n",
    "        self.fc9 = nn.Linear(hidden_size, output_size)\n",
    "#         self.relu9 = nn.ReLU()\n",
    "#         self.fc10 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu10 = nn.ReLU()\n",
    "#         self.fc11 = nn.Linear(hidden_size, hidden_size)\n",
    "#         self.relu11 = nn.ReLU()\n",
    "#         self.fc12 = nn.Linear(hidden_size, output_size)\n",
    "        self.sig1 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.fc5(out)\n",
    "        out = self.relu5(out)\n",
    "        out = self.fc6(out)\n",
    "        out = self.relu6(out)\n",
    "        out = self.fc7(out)\n",
    "        out = self.relu7(out)\n",
    "        out = self.fc8(out)\n",
    "        out = self.relu8(out)\n",
    "        out = self.fc9(out)\n",
    "#         out = self.relu9(out)\n",
    "#         out = self.fc10(out)\n",
    "#         out = self.relu10(out)\n",
    "#         out = self.fc11(out)\n",
    "#         out = self.relu11(out)\n",
    "#         out = self.fc12(out)\n",
    "        out = self.sig1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CLANet(input_size, hidden_size, output_size)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, nesterov=True, momentum=1, dampening=0)\n",
    "model.double();     # cast model parameters to double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()     # training mode\n",
    "training_loss = []\n",
    "avg_error = 0\n",
    "avg_error_vec = []\n",
    "best_avg_error = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: %d/%d\" % (epoch+1, num_epochs))\n",
    "\n",
    "    for i, (samples, labels) in enumerate(train_loader):\n",
    "        samples = Variable(samples)\n",
    "        labels = Variable(labels)\n",
    "        output = model(samples)                # forward pass\n",
    "        output = torch.flatten(output)         # resize predicted labels\n",
    "        labels = labels.type(torch.DoubleTensor)\n",
    "        \n",
    "        loss = criterion(output, labels)  # calculate loss\n",
    "        optimizer.zero_grad()     # clear gradient\n",
    "        loss.backward()           # calculate gradients\n",
    "        optimizer.step()          # update weights\n",
    "        \n",
    "        # calculate and print error\n",
    "        out = output\n",
    "\n",
    "        for j in range(0, out.size()[0]):\n",
    "            if out[j] < 0.5:\n",
    "                out[j] = 0\n",
    "            else:\n",
    "                out[j] = 1\n",
    "        error = 1 - torch.sum(output == labels).item() / labels.size()[0]\n",
    "        avg_error += error\n",
    "        training_loss.append(loss.data.numpy())\n",
    "        print(\"  Iteration: %d/%d, Loss: %g, Error: %0.4f\" % \n",
    "              (i+1, np.ceil(X_train.size()[0] / batch_size).astype(int), loss.item(), error))\n",
    "    \n",
    "    avg_error = avg_error / np.ceil(X_train.size()[0] / batch_size)\n",
    "    avg_error_vec.append(avg_error)\n",
    "    print(\"Average Error for this Epoch: %0.4f\" % avg_error)\n",
    "\n",
    "    if avg_error < best_avg_error:\n",
    "        print(\"found a better model!\")\n",
    "        best_avg_error = avg_error\n",
    "        best_model = copy.deepcopy(model)\n",
    "    \n",
    "    avg_error = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.linspace(start=1, stop=100, num=100), avg_error_vec)\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Average Training Error\")\n",
    "plt.title(\"Average Training Error for Epochs=1:100\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Neural Net Training Error.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n",
      "  Iteration: 1/17, Loss: 0.622625, Error: 0.3400\n",
      "  Iteration: 2/17, Loss: 0.411956, Error: 0.1900\n",
      "  Iteration: 3/17, Loss: 0.504927, Error: 0.2500\n",
      "  Iteration: 4/17, Loss: 0.609038, Error: 0.2700\n",
      "  Iteration: 5/17, Loss: 0.495922, Error: 0.2400\n",
      "  Iteration: 6/17, Loss: 0.428102, Error: 0.1900\n",
      "  Iteration: 7/17, Loss: 0.543123, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.533241, Error: 0.2700\n",
      "  Iteration: 9/17, Loss: 0.424661, Error: 0.2100\n",
      "  Iteration: 10/17, Loss: 0.494133, Error: 0.2500\n",
      "  Iteration: 11/17, Loss: 0.577836, Error: 0.2600\n",
      "  Iteration: 12/17, Loss: 0.464019, Error: 0.1800\n",
      "  Iteration: 13/17, Loss: 0.527645, Error: 0.2800\n",
      "  Iteration: 14/17, Loss: 0.479384, Error: 0.2500\n",
      "  Iteration: 15/17, Loss: 0.459471, Error: 0.2100\n",
      "  Iteration: 16/17, Loss: 0.495459, Error: 0.2700\n",
      "  Iteration: 17/17, Loss: 0.438126, Error: 0.2742\n",
      "Average Error for this Epoch: 0.2461\n",
      "found a better model!\n",
      "Epoch: 2/100\n",
      "  Iteration: 1/17, Loss: 0.488148, Error: 0.2800\n",
      "  Iteration: 2/17, Loss: 0.552724, Error: 0.2500\n",
      "  Iteration: 3/17, Loss: 0.609088, Error: 0.3200\n",
      "  Iteration: 4/17, Loss: 0.528083, Error: 0.2400\n",
      "  Iteration: 5/17, Loss: 0.46691, Error: 0.2300\n",
      "  Iteration: 6/17, Loss: 0.475664, Error: 0.2200\n",
      "  Iteration: 7/17, Loss: 0.535243, Error: 0.2600\n",
      "  Iteration: 8/17, Loss: 0.382772, Error: 0.1800\n",
      "  Iteration: 9/17, Loss: 0.408286, Error: 0.1700\n",
      "  Iteration: 10/17, Loss: 0.525201, Error: 0.2500\n",
      "  Iteration: 11/17, Loss: 0.476247, Error: 0.2600\n",
      "  Iteration: 12/17, Loss: 0.64003, Error: 0.3300\n",
      "  Iteration: 13/17, Loss: 0.471297, Error: 0.2100\n",
      "  Iteration: 14/17, Loss: 0.490783, Error: 0.2400\n",
      "  Iteration: 15/17, Loss: 0.532923, Error: 0.2900\n",
      "  Iteration: 16/17, Loss: 0.41707, Error: 0.1800\n",
      "  Iteration: 17/17, Loss: 0.552755, Error: 0.2742\n",
      "Average Error for this Epoch: 0.2461\n",
      "Epoch: 3/100\n",
      "  Iteration: 1/17, Loss: 0.487444, Error: 0.2500\n",
      "  Iteration: 2/17, Loss: 0.560328, Error: 0.2900\n",
      "  Iteration: 3/17, Loss: 0.498076, Error: 0.2200\n",
      "  Iteration: 4/17, Loss: 0.540879, Error: 0.2700\n",
      "  Iteration: 5/17, Loss: 0.516063, Error: 0.2300\n",
      "  Iteration: 6/17, Loss: 0.490969, Error: 0.2300\n",
      "  Iteration: 7/17, Loss: 0.458555, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.525962, Error: 0.3200\n",
      "  Iteration: 9/17, Loss: 0.461953, Error: 0.1700\n",
      "  Iteration: 10/17, Loss: 0.422729, Error: 0.1800\n",
      "  Iteration: 11/17, Loss: 0.439347, Error: 0.2200\n",
      "  Iteration: 12/17, Loss: 0.522987, Error: 0.2900\n",
      "  Iteration: 13/17, Loss: 0.529946, Error: 0.2400\n",
      "  Iteration: 14/17, Loss: 0.664175, Error: 0.3600\n",
      "  Iteration: 15/17, Loss: 0.46561, Error: 0.2000\n",
      "  Iteration: 16/17, Loss: 0.472998, Error: 0.2600\n",
      "  Iteration: 17/17, Loss: 0.45993, Error: 0.1613\n",
      "Average Error for this Epoch: 0.2436\n",
      "found a better model!\n",
      "Epoch: 4/100\n",
      "  Iteration: 1/17, Loss: 0.480383, Error: 0.2300\n",
      "  Iteration: 2/17, Loss: 0.50626, Error: 0.2200\n",
      "  Iteration: 3/17, Loss: 0.392069, Error: 0.1800\n",
      "  Iteration: 4/17, Loss: 0.494158, Error: 0.2600\n",
      "  Iteration: 5/17, Loss: 0.59253, Error: 0.2800\n",
      "  Iteration: 6/17, Loss: 0.482594, Error: 0.2500\n",
      "  Iteration: 7/17, Loss: 0.495625, Error: 0.2400\n",
      "  Iteration: 8/17, Loss: 0.473937, Error: 0.2700\n",
      "  Iteration: 9/17, Loss: 0.570812, Error: 0.2900\n",
      "  Iteration: 10/17, Loss: 0.565642, Error: 0.2800\n",
      "  Iteration: 11/17, Loss: 0.50848, Error: 0.2200\n",
      "  Iteration: 12/17, Loss: 0.445853, Error: 0.2500\n",
      "  Iteration: 13/17, Loss: 0.551718, Error: 0.2800\n",
      "  Iteration: 14/17, Loss: 0.538895, Error: 0.3000\n",
      "  Iteration: 15/17, Loss: 0.580877, Error: 0.2400\n",
      "  Iteration: 16/17, Loss: 0.364946, Error: 0.1500\n",
      "  Iteration: 17/17, Loss: 0.481288, Error: 0.2258\n",
      "Average Error for this Epoch: 0.2450\n",
      "Epoch: 5/100\n",
      "  Iteration: 1/17, Loss: 0.401804, Error: 0.1800\n",
      "  Iteration: 2/17, Loss: 0.50104, Error: 0.2500\n",
      "  Iteration: 3/17, Loss: 0.608755, Error: 0.2900\n",
      "  Iteration: 4/17, Loss: 0.452538, Error: 0.2200\n",
      "  Iteration: 5/17, Loss: 0.450383, Error: 0.2200\n",
      "  Iteration: 6/17, Loss: 0.540505, Error: 0.2400\n",
      "  Iteration: 7/17, Loss: 0.627065, Error: 0.2700\n",
      "  Iteration: 8/17, Loss: 0.505021, Error: 0.2800\n",
      "  Iteration: 9/17, Loss: 0.453612, Error: 0.2200\n",
      "  Iteration: 10/17, Loss: 0.460756, Error: 0.2100\n",
      "  Iteration: 11/17, Loss: 0.454968, Error: 0.2500\n",
      "  Iteration: 12/17, Loss: 0.579792, Error: 0.2900\n",
      "  Iteration: 13/17, Loss: 0.442546, Error: 0.2200\n",
      "  Iteration: 14/17, Loss: 0.556884, Error: 0.2900\n",
      "  Iteration: 15/17, Loss: 0.420574, Error: 0.2200\n",
      "  Iteration: 16/17, Loss: 0.563088, Error: 0.2600\n",
      "  Iteration: 17/17, Loss: 0.522336, Error: 0.2742\n",
      "Average Error for this Epoch: 0.2461\n",
      "Epoch: 6/100\n",
      "  Iteration: 1/17, Loss: 0.475078, Error: 0.2200\n",
      "  Iteration: 2/17, Loss: 0.48362, Error: 0.2700\n",
      "  Iteration: 3/17, Loss: 0.447517, Error: 0.1500\n",
      "  Iteration: 4/17, Loss: 0.553011, Error: 0.2800\n",
      "  Iteration: 5/17, Loss: 0.487955, Error: 0.2400\n",
      "  Iteration: 6/17, Loss: 0.588541, Error: 0.2900\n",
      "  Iteration: 7/17, Loss: 0.458365, Error: 0.2200\n",
      "  Iteration: 8/17, Loss: 0.502679, Error: 0.2700\n",
      "  Iteration: 9/17, Loss: 0.510813, Error: 0.2800\n",
      "  Iteration: 10/17, Loss: 0.480441, Error: 0.2300\n",
      "  Iteration: 11/17, Loss: 0.581079, Error: 0.3300\n",
      "  Iteration: 12/17, Loss: 0.455717, Error: 0.2200\n",
      "  Iteration: 13/17, Loss: 0.451176, Error: 0.2000\n",
      "  Iteration: 14/17, Loss: 0.537225, Error: 0.2600\n",
      "  Iteration: 15/17, Loss: 0.543533, Error: 0.2300\n",
      "  Iteration: 16/17, Loss: 0.471602, Error: 0.2300\n",
      "  Iteration: 17/17, Loss: 0.507788, Error: 0.2581\n",
      "Average Error for this Epoch: 0.2458\n",
      "Epoch: 7/100\n",
      "  Iteration: 1/17, Loss: 0.511223, Error: 0.2400\n",
      "  Iteration: 2/17, Loss: 0.631128, Error: 0.3800\n",
      "  Iteration: 3/17, Loss: 0.4532, Error: 0.1600\n",
      "  Iteration: 4/17, Loss: 0.492865, Error: 0.2200\n",
      "  Iteration: 5/17, Loss: 0.534037, Error: 0.2600\n",
      "  Iteration: 6/17, Loss: 0.624228, Error: 0.3500\n",
      "  Iteration: 7/17, Loss: 0.465871, Error: 0.2100\n",
      "  Iteration: 8/17, Loss: 0.509825, Error: 0.2300\n",
      "  Iteration: 9/17, Loss: 0.51816, Error: 0.2300\n",
      "  Iteration: 10/17, Loss: 0.487502, Error: 0.2300\n",
      "  Iteration: 11/17, Loss: 0.553241, Error: 0.2600\n",
      "  Iteration: 12/17, Loss: 0.478346, Error: 0.2500\n",
      "  Iteration: 13/17, Loss: 0.467986, Error: 0.3000\n",
      "  Iteration: 14/17, Loss: 0.528587, Error: 0.3000\n",
      "  Iteration: 15/17, Loss: 0.419293, Error: 0.1900\n",
      "  Iteration: 16/17, Loss: 0.421903, Error: 0.1800\n",
      "  Iteration: 17/17, Loss: 0.396426, Error: 0.1452\n",
      "Average Error for this Epoch: 0.2432\n",
      "found a better model!\n",
      "Epoch: 8/100\n",
      "  Iteration: 1/17, Loss: 0.431675, Error: 0.2100\n",
      "  Iteration: 2/17, Loss: 0.561943, Error: 0.2900\n",
      "  Iteration: 3/17, Loss: 0.538433, Error: 0.2900\n",
      "  Iteration: 4/17, Loss: 0.526352, Error: 0.2800\n",
      "  Iteration: 5/17, Loss: 0.373118, Error: 0.1700\n",
      "  Iteration: 6/17, Loss: 0.515161, Error: 0.2200\n",
      "  Iteration: 7/17, Loss: 0.505348, Error: 0.2700\n",
      "  Iteration: 8/17, Loss: 0.436147, Error: 0.2000\n",
      "  Iteration: 9/17, Loss: 0.581898, Error: 0.2900\n",
      "  Iteration: 10/17, Loss: 0.61427, Error: 0.3200\n",
      "  Iteration: 11/17, Loss: 0.412092, Error: 0.2200\n",
      "  Iteration: 12/17, Loss: 0.572348, Error: 0.2900\n",
      "  Iteration: 13/17, Loss: 0.475247, Error: 0.2200\n",
      "  Iteration: 14/17, Loss: 0.51549, Error: 0.2700\n",
      "  Iteration: 15/17, Loss: 0.425568, Error: 0.1600\n",
      "  Iteration: 16/17, Loss: 0.59622, Error: 0.2700\n",
      "  Iteration: 17/17, Loss: 0.42237, Error: 0.1774\n",
      "Average Error for this Epoch: 0.2440\n",
      "Epoch: 9/100\n",
      "  Iteration: 1/17, Loss: 0.51989, Error: 0.2800\n",
      "  Iteration: 2/17, Loss: 0.467621, Error: 0.2400\n",
      "  Iteration: 3/17, Loss: 0.503679, Error: 0.2700\n",
      "  Iteration: 4/17, Loss: 0.478427, Error: 0.2400\n",
      "  Iteration: 5/17, Loss: 0.618912, Error: 0.2500\n",
      "  Iteration: 6/17, Loss: 0.470159, Error: 0.2500\n",
      "  Iteration: 7/17, Loss: 0.575097, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.614491, Error: 0.2800\n",
      "  Iteration: 9/17, Loss: 0.468785, Error: 0.2200\n",
      "  Iteration: 10/17, Loss: 0.446779, Error: 0.1900\n",
      "  Iteration: 11/17, Loss: 0.544208, Error: 0.3100\n",
      "  Iteration: 12/17, Loss: 0.52382, Error: 0.2500\n",
      "  Iteration: 13/17, Loss: 0.455522, Error: 0.2400\n",
      "  Iteration: 14/17, Loss: 0.494652, Error: 0.2600\n",
      "  Iteration: 15/17, Loss: 0.431016, Error: 0.2000\n",
      "  Iteration: 16/17, Loss: 0.465105, Error: 0.2300\n",
      "  Iteration: 17/17, Loss: 0.427443, Error: 0.1935\n",
      "Average Error for this Epoch: 0.2443\n",
      "Epoch: 10/100\n",
      "  Iteration: 1/17, Loss: 0.456565, Error: 0.2100\n",
      "  Iteration: 2/17, Loss: 0.583806, Error: 0.3300\n",
      "  Iteration: 3/17, Loss: 0.463273, Error: 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 4/17, Loss: 0.528029, Error: 0.2800\n",
      "  Iteration: 5/17, Loss: 0.42453, Error: 0.2000\n",
      "  Iteration: 6/17, Loss: 0.553176, Error: 0.2600\n",
      "  Iteration: 7/17, Loss: 0.4854, Error: 0.2700\n",
      "  Iteration: 8/17, Loss: 0.50308, Error: 0.2200\n",
      "  Iteration: 9/17, Loss: 0.516301, Error: 0.2100\n",
      "  Iteration: 10/17, Loss: 0.601661, Error: 0.3200\n",
      "  Iteration: 11/17, Loss: 0.484163, Error: 0.2400\n",
      "  Iteration: 12/17, Loss: 0.524353, Error: 0.2600\n",
      "  Iteration: 13/17, Loss: 0.545525, Error: 0.3000\n",
      "  Iteration: 14/17, Loss: 0.458203, Error: 0.2200\n",
      "  Iteration: 15/17, Loss: 0.494264, Error: 0.2300\n",
      "  Iteration: 16/17, Loss: 0.475658, Error: 0.2100\n",
      "  Iteration: 17/17, Loss: 0.39547, Error: 0.1452\n",
      "Average Error for this Epoch: 0.2432\n",
      "found a better model!\n",
      "Epoch: 11/100\n",
      "  Iteration: 1/17, Loss: 0.576151, Error: 0.2900\n",
      "  Iteration: 2/17, Loss: 0.498855, Error: 0.2500\n",
      "  Iteration: 3/17, Loss: 0.454486, Error: 0.2000\n",
      "  Iteration: 4/17, Loss: 0.562767, Error: 0.2200\n",
      "  Iteration: 5/17, Loss: 0.489956, Error: 0.2500\n",
      "  Iteration: 6/17, Loss: 0.56505, Error: 0.2500\n",
      "  Iteration: 7/17, Loss: 0.506856, Error: 0.2700\n",
      "  Iteration: 8/17, Loss: 0.489426, Error: 0.2300\n",
      "  Iteration: 9/17, Loss: 0.602462, Error: 0.3400\n",
      "  Iteration: 10/17, Loss: 0.531489, Error: 0.2600\n",
      "  Iteration: 11/17, Loss: 0.411577, Error: 0.1900\n",
      "  Iteration: 12/17, Loss: 0.493688, Error: 0.2600\n",
      "  Iteration: 13/17, Loss: 0.553901, Error: 0.3000\n",
      "  Iteration: 14/17, Loss: 0.457659, Error: 0.2000\n",
      "  Iteration: 15/17, Loss: 0.40332, Error: 0.1800\n",
      "  Iteration: 16/17, Loss: 0.454194, Error: 0.2400\n",
      "  Iteration: 17/17, Loss: 0.469906, Error: 0.2419\n",
      "Average Error for this Epoch: 0.2454\n",
      "Epoch: 12/100\n",
      "  Iteration: 1/17, Loss: 0.48737, Error: 0.1900\n",
      "  Iteration: 2/17, Loss: 0.494675, Error: 0.2400\n",
      "  Iteration: 3/17, Loss: 0.606335, Error: 0.3400\n",
      "  Iteration: 4/17, Loss: 0.468613, Error: 0.2400\n",
      "  Iteration: 5/17, Loss: 0.47934, Error: 0.2300\n",
      "  Iteration: 6/17, Loss: 0.453125, Error: 0.2100\n",
      "  Iteration: 7/17, Loss: 0.577127, Error: 0.2600\n",
      "  Iteration: 8/17, Loss: 0.498375, Error: 0.2300\n",
      "  Iteration: 9/17, Loss: 0.517911, Error: 0.2500\n",
      "  Iteration: 10/17, Loss: 0.568459, Error: 0.3300\n",
      "  Iteration: 11/17, Loss: 0.518031, Error: 0.2700\n",
      "  Iteration: 12/17, Loss: 0.573789, Error: 0.3000\n",
      "  Iteration: 13/17, Loss: 0.439171, Error: 0.2000\n",
      "  Iteration: 14/17, Loss: 0.452953, Error: 0.2100\n",
      "  Iteration: 15/17, Loss: 0.455408, Error: 0.2400\n",
      "  Iteration: 16/17, Loss: 0.482421, Error: 0.2200\n",
      "  Iteration: 17/17, Loss: 0.435604, Error: 0.1935\n",
      "Average Error for this Epoch: 0.2443\n",
      "Epoch: 13/100\n",
      "  Iteration: 1/17, Loss: 0.461213, Error: 0.2100\n",
      "  Iteration: 2/17, Loss: 0.408105, Error: 0.2000\n",
      "  Iteration: 3/17, Loss: 0.560171, Error: 0.3100\n",
      "  Iteration: 4/17, Loss: 0.596673, Error: 0.3100\n",
      "  Iteration: 5/17, Loss: 0.552595, Error: 0.2600\n",
      "  Iteration: 6/17, Loss: 0.363689, Error: 0.1700\n",
      "  Iteration: 7/17, Loss: 0.522071, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.416548, Error: 0.1900\n",
      "  Iteration: 9/17, Loss: 0.524066, Error: 0.2600\n",
      "  Iteration: 10/17, Loss: 0.470277, Error: 0.2000\n",
      "  Iteration: 11/17, Loss: 0.515634, Error: 0.2900\n",
      "  Iteration: 12/17, Loss: 0.539651, Error: 0.2800\n",
      "  Iteration: 13/17, Loss: 0.585436, Error: 0.3400\n",
      "  Iteration: 14/17, Loss: 0.604661, Error: 0.3000\n",
      "  Iteration: 15/17, Loss: 0.523872, Error: 0.2400\n",
      "  Iteration: 16/17, Loss: 0.447473, Error: 0.1700\n",
      "  Iteration: 17/17, Loss: 0.404907, Error: 0.1613\n",
      "Average Error for this Epoch: 0.2436\n",
      "Epoch: 14/100\n",
      "  Iteration: 1/17, Loss: 0.384315, Error: 0.1500\n",
      "  Iteration: 2/17, Loss: 0.517532, Error: 0.2000\n",
      "  Iteration: 3/17, Loss: 0.437057, Error: 0.2100\n",
      "  Iteration: 4/17, Loss: 0.492656, Error: 0.2500\n",
      "  Iteration: 5/17, Loss: 0.510752, Error: 0.2500\n",
      "  Iteration: 6/17, Loss: 0.589566, Error: 0.2900\n",
      "  Iteration: 7/17, Loss: 0.593063, Error: 0.2800\n",
      "  Iteration: 8/17, Loss: 0.554964, Error: 0.2800\n",
      "  Iteration: 9/17, Loss: 0.474253, Error: 0.2300\n",
      "  Iteration: 10/17, Loss: 0.468535, Error: 0.2300\n",
      "  Iteration: 11/17, Loss: 0.511257, Error: 0.2900\n",
      "  Iteration: 12/17, Loss: 0.497381, Error: 0.2200\n",
      "  Iteration: 13/17, Loss: 0.534736, Error: 0.2700\n",
      "  Iteration: 14/17, Loss: 0.401253, Error: 0.1900\n",
      "  Iteration: 15/17, Loss: 0.534427, Error: 0.3000\n",
      "  Iteration: 16/17, Loss: 0.539363, Error: 0.3000\n",
      "  Iteration: 17/17, Loss: 0.487208, Error: 0.2258\n",
      "Average Error for this Epoch: 0.2450\n",
      "Epoch: 15/100\n",
      "  Iteration: 1/17, Loss: 0.480567, Error: 0.2400\n",
      "  Iteration: 2/17, Loss: 0.539208, Error: 0.2600\n",
      "  Iteration: 3/17, Loss: 0.461339, Error: 0.2200\n",
      "  Iteration: 4/17, Loss: 0.586037, Error: 0.3100\n",
      "  Iteration: 5/17, Loss: 0.43525, Error: 0.1600\n",
      "  Iteration: 6/17, Loss: 0.524661, Error: 0.2900\n",
      "  Iteration: 7/17, Loss: 0.45022, Error: 0.1800\n",
      "  Iteration: 8/17, Loss: 0.482494, Error: 0.2400\n",
      "  Iteration: 9/17, Loss: 0.498161, Error: 0.2200\n",
      "  Iteration: 10/17, Loss: 0.590939, Error: 0.3200\n",
      "  Iteration: 11/17, Loss: 0.492828, Error: 0.2400\n",
      "  Iteration: 12/17, Loss: 0.430087, Error: 0.1900\n",
      "  Iteration: 13/17, Loss: 0.469644, Error: 0.2300\n",
      "  Iteration: 14/17, Loss: 0.565655, Error: 0.3000\n",
      "  Iteration: 15/17, Loss: 0.479057, Error: 0.2300\n",
      "  Iteration: 16/17, Loss: 0.46651, Error: 0.2200\n",
      "  Iteration: 17/17, Loss: 0.629874, Error: 0.3710\n",
      "Average Error for this Epoch: 0.2483\n",
      "Epoch: 16/100\n",
      "  Iteration: 1/17, Loss: 0.445108, Error: 0.2300\n",
      "  Iteration: 2/17, Loss: 0.564456, Error: 0.2700\n",
      "  Iteration: 3/17, Loss: 0.509064, Error: 0.3000\n",
      "  Iteration: 4/17, Loss: 0.487473, Error: 0.2500\n",
      "  Iteration: 5/17, Loss: 0.496574, Error: 0.2100\n",
      "  Iteration: 6/17, Loss: 0.510214, Error: 0.2300\n",
      "  Iteration: 7/17, Loss: 0.519707, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.476798, Error: 0.2500\n",
      "  Iteration: 9/17, Loss: 0.55818, Error: 0.2700\n",
      "  Iteration: 10/17, Loss: 0.501531, Error: 0.2200\n",
      "  Iteration: 11/17, Loss: 0.43286, Error: 0.2000\n",
      "  Iteration: 12/17, Loss: 0.533869, Error: 0.2700\n",
      "  Iteration: 13/17, Loss: 0.453048, Error: 0.2400\n",
      "  Iteration: 14/17, Loss: 0.588848, Error: 0.2900\n",
      "  Iteration: 15/17, Loss: 0.378098, Error: 0.1800\n",
      "  Iteration: 16/17, Loss: 0.505756, Error: 0.2200\n",
      "  Iteration: 17/17, Loss: 0.615474, Error: 0.3226\n",
      "Average Error for this Epoch: 0.2472\n",
      "Epoch: 17/100\n",
      "  Iteration: 1/17, Loss: 0.520257, Error: 0.2600\n",
      "  Iteration: 2/17, Loss: 0.429024, Error: 0.1600\n",
      "  Iteration: 3/17, Loss: 0.544878, Error: 0.3000\n",
      "  Iteration: 4/17, Loss: 0.579496, Error: 0.2700\n",
      "  Iteration: 5/17, Loss: 0.469981, Error: 0.2400\n",
      "  Iteration: 6/17, Loss: 0.513162, Error: 0.2900\n",
      "  Iteration: 7/17, Loss: 0.460354, Error: 0.2100\n",
      "  Iteration: 8/17, Loss: 0.515822, Error: 0.2600\n",
      "  Iteration: 9/17, Loss: 0.463649, Error: 0.2100\n",
      "  Iteration: 10/17, Loss: 0.455861, Error: 0.2200\n",
      "  Iteration: 11/17, Loss: 0.487425, Error: 0.2800\n",
      "  Iteration: 12/17, Loss: 0.501622, Error: 0.2600\n",
      "  Iteration: 13/17, Loss: 0.478195, Error: 0.2500\n",
      "  Iteration: 14/17, Loss: 0.512385, Error: 0.2300\n",
      "  Iteration: 15/17, Loss: 0.53514, Error: 0.2300\n",
      "  Iteration: 16/17, Loss: 0.560164, Error: 0.2600\n",
      "  Iteration: 17/17, Loss: 0.509297, Error: 0.2419\n",
      "Average Error for this Epoch: 0.2454\n",
      "Epoch: 18/100\n",
      "  Iteration: 1/17, Loss: 0.504194, Error: 0.2300\n",
      "  Iteration: 2/17, Loss: 0.594597, Error: 0.3200\n",
      "  Iteration: 3/17, Loss: 0.494681, Error: 0.2500\n",
      "  Iteration: 4/17, Loss: 0.472898, Error: 0.2300\n",
      "  Iteration: 5/17, Loss: 0.449563, Error: 0.2000\n",
      "  Iteration: 6/17, Loss: 0.498896, Error: 0.2700\n",
      "  Iteration: 7/17, Loss: 0.547351, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.478946, Error: 0.2200\n",
      "  Iteration: 9/17, Loss: 0.399175, Error: 0.1600\n",
      "  Iteration: 10/17, Loss: 0.550958, Error: 0.3000\n",
      "  Iteration: 11/17, Loss: 0.493702, Error: 0.2300\n",
      "  Iteration: 12/17, Loss: 0.52582, Error: 0.2700\n",
      "  Iteration: 13/17, Loss: 0.476501, Error: 0.2500\n",
      "  Iteration: 14/17, Loss: 0.483933, Error: 0.2100\n",
      "  Iteration: 15/17, Loss: 0.530906, Error: 0.2600\n",
      "  Iteration: 16/17, Loss: 0.552396, Error: 0.3000\n",
      "  Iteration: 17/17, Loss: 0.465586, Error: 0.2097\n",
      "Average Error for this Epoch: 0.2447\n",
      "Epoch: 19/100\n",
      "  Iteration: 1/17, Loss: 0.602489, Error: 0.3100\n",
      "  Iteration: 2/17, Loss: 0.4855, Error: 0.2500\n",
      "  Iteration: 3/17, Loss: 0.435036, Error: 0.1800\n",
      "  Iteration: 4/17, Loss: 0.483734, Error: 0.2000\n",
      "  Iteration: 5/17, Loss: 0.411962, Error: 0.2000\n",
      "  Iteration: 6/17, Loss: 0.42103, Error: 0.2100\n",
      "  Iteration: 7/17, Loss: 0.488117, Error: 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 8/17, Loss: 0.49234, Error: 0.2700\n",
      "  Iteration: 9/17, Loss: 0.557936, Error: 0.3300\n",
      "  Iteration: 10/17, Loss: 0.511948, Error: 0.2700\n",
      "  Iteration: 11/17, Loss: 0.495477, Error: 0.2500\n",
      "  Iteration: 12/17, Loss: 0.508989, Error: 0.2300\n",
      "  Iteration: 13/17, Loss: 0.530157, Error: 0.2200\n",
      "  Iteration: 14/17, Loss: 0.575233, Error: 0.2600\n",
      "  Iteration: 15/17, Loss: 0.509041, Error: 0.2500\n",
      "  Iteration: 16/17, Loss: 0.480794, Error: 0.2200\n",
      "  Iteration: 17/17, Loss: 0.569989, Error: 0.3226\n",
      "Average Error for this Epoch: 0.2472\n",
      "Epoch: 20/100\n",
      "  Iteration: 1/17, Loss: 0.496491, Error: 0.2400\n",
      "  Iteration: 2/17, Loss: 0.462284, Error: 0.2500\n",
      "  Iteration: 3/17, Loss: 0.43273, Error: 0.2300\n",
      "  Iteration: 4/17, Loss: 0.503928, Error: 0.2100\n",
      "  Iteration: 5/17, Loss: 0.479755, Error: 0.2300\n",
      "  Iteration: 6/17, Loss: 0.563279, Error: 0.2600\n",
      "  Iteration: 7/17, Loss: 0.471959, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.491287, Error: 0.2600\n",
      "  Iteration: 9/17, Loss: 0.476646, Error: 0.2500\n",
      "  Iteration: 10/17, Loss: 0.524167, Error: 0.2700\n",
      "  Iteration: 11/17, Loss: 0.598748, Error: 0.3500\n",
      "  Iteration: 12/17, Loss: 0.443017, Error: 0.1700\n",
      "  Iteration: 13/17, Loss: 0.471384, Error: 0.1900\n",
      "  Iteration: 14/17, Loss: 0.533307, Error: 0.2700\n",
      "  Iteration: 15/17, Loss: 0.592528, Error: 0.3300\n",
      "  Iteration: 16/17, Loss: 0.525063, Error: 0.2100\n",
      "  Iteration: 17/17, Loss: 0.446134, Error: 0.1774\n",
      "Average Error for this Epoch: 0.2440\n",
      "Epoch: 21/100\n",
      "  Iteration: 1/17, Loss: 0.381311, Error: 0.1500\n",
      "  Iteration: 2/17, Loss: 0.584467, Error: 0.2800\n",
      "  Iteration: 3/17, Loss: 0.473359, Error: 0.2500\n",
      "  Iteration: 4/17, Loss: 0.549693, Error: 0.2300\n",
      "  Iteration: 5/17, Loss: 0.509915, Error: 0.2800\n",
      "  Iteration: 6/17, Loss: 0.459972, Error: 0.2400\n",
      "  Iteration: 7/17, Loss: 0.499747, Error: 0.2200\n",
      "  Iteration: 8/17, Loss: 0.540613, Error: 0.2900\n",
      "  Iteration: 9/17, Loss: 0.546984, Error: 0.2700\n",
      "  Iteration: 10/17, Loss: 0.548493, Error: 0.2900\n",
      "  Iteration: 11/17, Loss: 0.526602, Error: 0.2600\n",
      "  Iteration: 12/17, Loss: 0.428095, Error: 0.2000\n",
      "  Iteration: 13/17, Loss: 0.47596, Error: 0.2300\n",
      "  Iteration: 14/17, Loss: 0.50397, Error: 0.2500\n",
      "  Iteration: 15/17, Loss: 0.560755, Error: 0.2600\n",
      "  Iteration: 16/17, Loss: 0.476715, Error: 0.2500\n",
      "  Iteration: 17/17, Loss: 0.446014, Error: 0.2097\n",
      "Average Error for this Epoch: 0.2447\n",
      "Epoch: 22/100\n",
      "  Iteration: 1/17, Loss: 0.42549, Error: 0.2100\n",
      "  Iteration: 2/17, Loss: 0.501371, Error: 0.2200\n",
      "  Iteration: 3/17, Loss: 0.496127, Error: 0.2200\n",
      "  Iteration: 4/17, Loss: 0.492656, Error: 0.2200\n",
      "  Iteration: 5/17, Loss: 0.458433, Error: 0.2100\n",
      "  Iteration: 6/17, Loss: 0.556797, Error: 0.2800\n",
      "  Iteration: 7/17, Loss: 0.571548, Error: 0.3000\n",
      "  Iteration: 8/17, Loss: 0.52985, Error: 0.2900\n",
      "  Iteration: 9/17, Loss: 0.580573, Error: 0.3100\n",
      "  Iteration: 10/17, Loss: 0.485947, Error: 0.2100\n",
      "  Iteration: 11/17, Loss: 0.583642, Error: 0.3100\n",
      "  Iteration: 12/17, Loss: 0.449455, Error: 0.2200\n",
      "  Iteration: 13/17, Loss: 0.536575, Error: 0.2700\n",
      "  Iteration: 14/17, Loss: 0.468051, Error: 0.2200\n",
      "  Iteration: 15/17, Loss: 0.416685, Error: 0.2100\n",
      "  Iteration: 16/17, Loss: 0.462595, Error: 0.2400\n",
      "  Iteration: 17/17, Loss: 0.528039, Error: 0.2258\n",
      "Average Error for this Epoch: 0.2450\n",
      "Epoch: 23/100\n",
      "  Iteration: 1/17, Loss: 0.461171, Error: 0.2500\n",
      "  Iteration: 2/17, Loss: 0.494406, Error: 0.2500\n",
      "  Iteration: 3/17, Loss: 0.497837, Error: 0.2100\n",
      "  Iteration: 4/17, Loss: 0.392036, Error: 0.1600\n",
      "  Iteration: 5/17, Loss: 0.52675, Error: 0.2900\n",
      "  Iteration: 6/17, Loss: 0.55048, Error: 0.2600\n",
      "  Iteration: 7/17, Loss: 0.439012, Error: 0.1900\n",
      "  Iteration: 8/17, Loss: 0.599145, Error: 0.2300\n",
      "  Iteration: 9/17, Loss: 0.409398, Error: 0.2300\n",
      "  Iteration: 10/17, Loss: 0.459714, Error: 0.1700\n",
      "  Iteration: 11/17, Loss: 0.57006, Error: 0.2900\n",
      "  Iteration: 12/17, Loss: 0.590616, Error: 0.2900\n",
      "  Iteration: 13/17, Loss: 0.447237, Error: 0.2300\n",
      "  Iteration: 14/17, Loss: 0.507479, Error: 0.2100\n",
      "  Iteration: 15/17, Loss: 0.551491, Error: 0.3500\n",
      "  Iteration: 16/17, Loss: 0.546057, Error: 0.3200\n",
      "  Iteration: 17/17, Loss: 0.484337, Error: 0.2419\n",
      "Average Error for this Epoch: 0.2454\n",
      "Epoch: 24/100\n",
      "  Iteration: 1/17, Loss: 0.556565, Error: 0.2900\n",
      "  Iteration: 2/17, Loss: 0.487077, Error: 0.2500\n",
      "  Iteration: 3/17, Loss: 0.451849, Error: 0.2100\n",
      "  Iteration: 4/17, Loss: 0.491147, Error: 0.2500\n",
      "  Iteration: 5/17, Loss: 0.552542, Error: 0.2800\n",
      "  Iteration: 6/17, Loss: 0.471899, Error: 0.2600\n",
      "  Iteration: 7/17, Loss: 0.540719, Error: 0.2900\n",
      "  Iteration: 8/17, Loss: 0.526645, Error: 0.2500\n",
      "  Iteration: 9/17, Loss: 0.454252, Error: 0.2300\n",
      "  Iteration: 10/17, Loss: 0.537033, Error: 0.2300\n",
      "  Iteration: 11/17, Loss: 0.498448, Error: 0.2600\n",
      "  Iteration: 12/17, Loss: 0.494361, Error: 0.2400\n",
      "  Iteration: 13/17, Loss: 0.467739, Error: 0.2000\n",
      "  Iteration: 14/17, Loss: 0.552848, Error: 0.2500\n",
      "  Iteration: 15/17, Loss: 0.490777, Error: 0.2000\n",
      "  Iteration: 16/17, Loss: 0.43285, Error: 0.2100\n",
      "  Iteration: 17/17, Loss: 0.542626, Error: 0.2903\n",
      "Average Error for this Epoch: 0.2465\n",
      "Epoch: 25/100\n",
      "  Iteration: 1/17, Loss: 0.520685, Error: 0.2400\n",
      "  Iteration: 2/17, Loss: 0.565669, Error: 0.2700\n",
      "  Iteration: 3/17, Loss: 0.537402, Error: 0.2500\n",
      "  Iteration: 4/17, Loss: 0.512401, Error: 0.1900\n",
      "  Iteration: 5/17, Loss: 0.474803, Error: 0.2700\n",
      "  Iteration: 6/17, Loss: 0.513704, Error: 0.2400\n",
      "  Iteration: 7/17, Loss: 0.482228, Error: 0.2300\n",
      "  Iteration: 8/17, Loss: 0.527695, Error: 0.3000\n",
      "  Iteration: 9/17, Loss: 0.482715, Error: 0.2300\n",
      "  Iteration: 10/17, Loss: 0.622646, Error: 0.3300\n",
      "  Iteration: 11/17, Loss: 0.405068, Error: 0.1800\n",
      "  Iteration: 12/17, Loss: 0.499915, Error: 0.2500\n",
      "  Iteration: 13/17, Loss: 0.405348, Error: 0.2100\n",
      "  Iteration: 14/17, Loss: 0.447945, Error: 0.2400\n",
      "  Iteration: 15/17, Loss: 0.469618, Error: 0.1900\n",
      "  Iteration: 16/17, Loss: 0.522376, Error: 0.2500\n",
      "  Iteration: 17/17, Loss: 0.569293, Error: 0.3387\n",
      "Average Error for this Epoch: 0.2476\n",
      "Epoch: 26/100\n",
      "  Iteration: 1/17, Loss: 0.53307, Error: 0.2600\n",
      "  Iteration: 2/17, Loss: 0.418738, Error: 0.1900\n",
      "  Iteration: 3/17, Loss: 0.524633, Error: 0.2900\n",
      "  Iteration: 4/17, Loss: 0.551656, Error: 0.2700\n",
      "  Iteration: 5/17, Loss: 0.493229, Error: 0.2500\n",
      "  Iteration: 6/17, Loss: 0.490288, Error: 0.2800\n",
      "  Iteration: 7/17, Loss: 0.671151, Error: 0.3400\n",
      "  Iteration: 8/17, Loss: 0.448723, Error: 0.2300\n",
      "  Iteration: 9/17, Loss: 0.488198, Error: 0.2400\n",
      "  Iteration: 10/17, Loss: 0.466957, Error: 0.2300\n",
      "  Iteration: 11/17, Loss: 0.421163, Error: 0.1700\n",
      "  Iteration: 12/17, Loss: 0.463497, Error: 0.2000\n",
      "  Iteration: 13/17, Loss: 0.492588, Error: 0.2300\n",
      "  Iteration: 14/17, Loss: 0.555647, Error: 0.2600\n",
      "  Iteration: 15/17, Loss: 0.515273, Error: 0.2000\n",
      "  Iteration: 16/17, Loss: 0.47035, Error: 0.2600\n",
      "  Iteration: 17/17, Loss: 0.545187, Error: 0.2903\n",
      "Average Error for this Epoch: 0.2465\n",
      "Epoch: 27/100\n",
      "  Iteration: 1/17, Loss: 0.502232, Error: 0.2300\n",
      "  Iteration: 2/17, Loss: 0.537607, Error: 0.2200\n",
      "  Iteration: 3/17, Loss: 0.535525, Error: 0.2600\n",
      "  Iteration: 4/17, Loss: 0.566054, Error: 0.2900\n",
      "  Iteration: 5/17, Loss: 0.43598, Error: 0.2100\n",
      "  Iteration: 6/17, Loss: 0.576472, Error: 0.2800\n",
      "  Iteration: 7/17, Loss: 0.600504, Error: 0.3000\n",
      "  Iteration: 8/17, Loss: 0.514671, Error: 0.2600\n",
      "  Iteration: 9/17, Loss: 0.519621, Error: 0.2600\n",
      "  Iteration: 10/17, Loss: 0.494133, Error: 0.2800\n",
      "  Iteration: 11/17, Loss: 0.433659, Error: 0.2500\n",
      "  Iteration: 12/17, Loss: 0.506909, Error: 0.2700\n",
      "  Iteration: 13/17, Loss: 0.471962, Error: 0.2800\n",
      "  Iteration: 14/17, Loss: 0.430779, Error: 0.1800\n",
      "  Iteration: 15/17, Loss: 0.439463, Error: 0.1900\n",
      "  Iteration: 16/17, Loss: 0.43863, Error: 0.1700\n",
      "  Iteration: 17/17, Loss: 0.546738, Error: 0.2419\n",
      "Average Error for this Epoch: 0.2454\n",
      "Epoch: 28/100\n",
      "  Iteration: 1/17, Loss: 0.660053, Error: 0.3300\n",
      "  Iteration: 2/17, Loss: 0.445671, Error: 0.2400\n",
      "  Iteration: 3/17, Loss: 0.416103, Error: 0.1900\n",
      "  Iteration: 4/17, Loss: 0.547553, Error: 0.2800\n",
      "  Iteration: 5/17, Loss: 0.525737, Error: 0.2700\n",
      "  Iteration: 6/17, Loss: 0.470411, Error: 0.2300\n",
      "  Iteration: 7/17, Loss: 0.452452, Error: 0.1800\n",
      "  Iteration: 8/17, Loss: 0.570544, Error: 0.3200\n",
      "  Iteration: 9/17, Loss: 0.489682, Error: 0.2600\n",
      "  Iteration: 10/17, Loss: 0.514717, Error: 0.2100\n",
      "  Iteration: 11/17, Loss: 0.505225, Error: 0.2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Iteration: 12/17, Loss: 0.488957, Error: 0.2200\n",
      "  Iteration: 13/17, Loss: 0.523457, Error: 0.2600\n",
      "  Iteration: 14/17, Loss: 0.52456, Error: 0.2600\n",
      "  Iteration: 15/17, Loss: 0.482592, Error: 0.2300\n",
      "  Iteration: 16/17, Loss: 0.437422, Error: 0.2400\n",
      "  Iteration: 17/17, Loss: 0.464585, Error: 0.2419\n",
      "Average Error for this Epoch: 0.2454\n",
      "Epoch: 29/100\n",
      "  Iteration: 1/17, Loss: 0.46703, Error: 0.2400\n",
      "  Iteration: 2/17, Loss: 0.468001, Error: 0.2300\n",
      "  Iteration: 3/17, Loss: 0.466934, Error: 0.2100\n",
      "  Iteration: 4/17, Loss: 0.5656, Error: 0.2600\n",
      "  Iteration: 5/17, Loss: 0.600441, Error: 0.3300\n",
      "  Iteration: 6/17, Loss: 0.475842, Error: 0.2700\n",
      "  Iteration: 7/17, Loss: 0.437418, Error: 0.2200\n",
      "  Iteration: 8/17, Loss: 0.507081, Error: 0.2800\n",
      "  Iteration: 9/17, Loss: 0.505665, Error: 0.2100\n",
      "  Iteration: 10/17, Loss: 0.479805, Error: 0.1600\n",
      "  Iteration: 11/17, Loss: 0.494215, Error: 0.2100\n",
      "  Iteration: 12/17, Loss: 0.615408, Error: 0.3300\n",
      "  Iteration: 13/17, Loss: 0.578672, Error: 0.3000\n",
      "  Iteration: 14/17, Loss: 0.431817, Error: 0.2300\n",
      "  Iteration: 15/17, Loss: 0.460997, Error: 0.2500\n",
      "  Iteration: 16/17, Loss: 0.510742, Error: 0.2400\n",
      "  Iteration: 17/17, Loss: 0.447596, Error: 0.1774\n",
      "Average Error for this Epoch: 0.2440\n",
      "Epoch: 30/100\n",
      "  Iteration: 1/17, Loss: 0.478658, Error: 0.2300\n",
      "  Iteration: 2/17, Loss: 0.535142, Error: 0.2800\n",
      "  Iteration: 3/17, Loss: 0.48108, Error: 0.2200\n",
      "  Iteration: 4/17, Loss: 0.59718, Error: 0.3400\n",
      "  Iteration: 5/17, Loss: 0.342703, Error: 0.1600\n",
      "  Iteration: 6/17, Loss: 0.52637, Error: 0.2900\n",
      "  Iteration: 7/17, Loss: 0.518523, Error: 0.2500\n",
      "  Iteration: 8/17, Loss: 0.528254, Error: 0.2200\n",
      "  Iteration: 9/17, Loss: 0.533181, Error: 0.2800\n",
      "  Iteration: 10/17, Loss: 0.595764, Error: 0.2800\n",
      "  Iteration: 11/17, Loss: 0.385642, Error: 0.1600\n",
      "  Iteration: 12/17, Loss: 0.47429, Error: 0.2200\n",
      "  Iteration: 13/17, Loss: 0.524427, Error: 0.3000\n",
      "  Iteration: 14/17, Loss: 0.525739, Error: 0.2000\n",
      "  Iteration: 15/17, Loss: 0.530755, Error: 0.2900\n",
      "  Iteration: 16/17, Loss: 0.525928, Error: 0.2500\n",
      "  Iteration: 17/17, Loss: 0.386357, Error: 0.1774\n",
      "Average Error for this Epoch: 0.2440\n",
      "Epoch: 31/100\n",
      "  Iteration: 1/17, Loss: 0.392778, Error: 0.1800\n",
      "  Iteration: 2/17, Loss: 0.569783, Error: 0.2600\n",
      "  Iteration: 3/17, Loss: 0.527304, Error: 0.2600\n",
      "  Iteration: 4/17, Loss: 0.407691, Error: 0.1600\n",
      "  Iteration: 5/17, Loss: 0.492408, Error: 0.2600\n",
      "  Iteration: 6/17, Loss: 0.428971, Error: 0.1900\n",
      "  Iteration: 7/17, Loss: 0.546243, Error: 0.2700\n",
      "  Iteration: 8/17, Loss: 0.523527, Error: 0.2800\n",
      "  Iteration: 9/17, Loss: 0.509384, Error: 0.2800\n",
      "  Iteration: 10/17, Loss: 0.494848, Error: 0.2100\n",
      "  Iteration: 11/17, Loss: 0.513184, Error: 0.2700\n",
      "  Iteration: 12/17, Loss: 0.457032, Error: 0.2000\n",
      "  Iteration: 13/17, Loss: 0.441863, Error: 0.2200\n",
      "  Iteration: 14/17, Loss: 0.553357, Error: 0.3200\n",
      "  Iteration: 15/17, Loss: 0.538453, Error: 0.2500\n",
      "  Iteration: 16/17, Loss: 0.651614, Error: 0.3000\n",
      "  Iteration: 17/17, Loss: 0.475384, Error: 0.2742\n",
      "Average Error for this Epoch: 0.2461\n",
      "Epoch: 32/100\n",
      "  Iteration: 1/17, Loss: 0.51984, Error: 0.2700\n",
      "  Iteration: 2/17, Loss: 0.476115, Error: 0.2100\n",
      "  Iteration: 3/17, Loss: 0.517462, Error: 0.2700\n",
      "  Iteration: 4/17, Loss: 0.581495, Error: 0.3000\n",
      "  Iteration: 5/17, Loss: 0.453038, Error: 0.1900\n",
      "  Iteration: 6/17, Loss: 0.424022, Error: 0.2300\n",
      "  Iteration: 7/17, Loss: 0.431184, Error: 0.2300\n",
      "  Iteration: 8/17, Loss: 0.399631, Error: 0.1800\n",
      "  Iteration: 9/17, Loss: 0.473164, Error: 0.2300\n",
      "  Iteration: 10/17, Loss: 0.543735, Error: 0.2800\n",
      "  Iteration: 11/17, Loss: 0.516242, Error: 0.2800\n",
      "  Iteration: 12/17, Loss: 0.574318, Error: 0.2700\n",
      "  Iteration: 13/17, Loss: 0.698287, Error: 0.3300\n",
      "  Iteration: 14/17, Loss: 0.426626, Error: 0.1500\n",
      "  Iteration: 15/17, Loss: 0.524639, Error: 0.2900\n",
      "  Iteration: 16/17, Loss: 0.551092, Error: 0.2900\n",
      "  Iteration: 17/17, Loss: 0.374659, Error: 0.1290\n",
      "Average Error for this Epoch: 0.2429\n",
      "found a better model!\n",
      "Epoch: 33/100\n",
      "  Iteration: 1/17, Loss: 0.424136, Error: 0.1800\n",
      "  Iteration: 2/17, Loss: 0.449291, Error: 0.1800\n",
      "  Iteration: 3/17, Loss: 0.467436, Error: 0.2600\n",
      "  Iteration: 4/17, Loss: 0.520501, Error: 0.2700\n",
      "  Iteration: 5/17, Loss: 0.509964, Error: 0.2100\n",
      "  Iteration: 6/17, Loss: 0.468969, Error: 0.2300\n",
      "  Iteration: 7/17, Loss: 0.531932, Error: 0.3000\n",
      "  Iteration: 8/17, Loss: 0.490362, Error: 0.2300\n",
      "  Iteration: 9/17, Loss: 0.468109, Error: 0.2300\n",
      "  Iteration: 10/17, Loss: 0.539383, Error: 0.2100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-8f09f892240f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# clear gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# calculate gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_model.train()     # training mode\n",
    "training_loss = []\n",
    "avg_error = 0\n",
    "avg_error_vec = []\n",
    "best_avg_error = 1\n",
    "\n",
    "# update learning rate\n",
    "for p in optimizer.param_groups:\n",
    "    p[\"lr\"] = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: %d/%d\" % (epoch+1, num_epochs))\n",
    "\n",
    "    for i, (samples, labels) in enumerate(train_loader):\n",
    "        samples = Variable(samples)\n",
    "        labels = Variable(labels)\n",
    "        output = best_model(samples)                # forward pass\n",
    "        output = torch.flatten(output)         # resize predicted labels\n",
    "        labels = labels.type(torch.DoubleTensor)\n",
    "        \n",
    "        loss = criterion(output, labels)  # calculate loss\n",
    "        optimizer.zero_grad()     # clear gradient\n",
    "        loss.backward()           # calculate gradients\n",
    "        optimizer.step()          # update weights\n",
    "        \n",
    "        # calculate and print error\n",
    "        out = output\n",
    "\n",
    "        for j in range(0, out.size()[0]):\n",
    "            if out[j] < 0.5:\n",
    "                out[j] = 0\n",
    "            else:\n",
    "                out[j] = 1\n",
    "        error = 1 - torch.sum(output == labels).item() / labels.size()[0]\n",
    "        avg_error += error\n",
    "        training_loss.append(loss.data.numpy())\n",
    "        print(\"  Iteration: %d/%d, Loss: %g, Error: %0.4f\" % \n",
    "              (i+1, np.ceil(X_train.size()[0] / batch_size).astype(int), loss.item(), error))\n",
    "    \n",
    "    avg_error = avg_error / np.ceil(X_train.size()[0] / batch_size)\n",
    "    avg_error_vec.append(avg_error)\n",
    "    print(\"Average Error for this Epoch: %0.4f\" % avg_error)\n",
    "\n",
    "    if avg_error < best_avg_error:\n",
    "        print(\"found a better model!\")\n",
    "        best_avg_error = avg_error\n",
    "        bester_model = copy.deepcopy(model)\n",
    "    \n",
    "    avg_error = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set Error: 0.2332\n"
     ]
    }
   ],
   "source": [
    "best_model.eval()\n",
    "\n",
    "for i, (samples, labels) in enumerate(test_loader):\n",
    "    samples = Variable(samples)\n",
    "    labels = Variable(labels)\n",
    "    predictions = best_model(samples)\n",
    "    predictions = torch.flatten(predictions)\n",
    "    labels = labels.type(torch.DoubleTensor)\n",
    "\n",
    "    for j in range(0, predictions.size()[0]):\n",
    "        if predictions[j] < 0.5:\n",
    "            predictions[j] = 0\n",
    "        else:\n",
    "            predictions[j] = 1\n",
    "    \n",
    "    error = 1 - torch.sum(predictions == labels).item() / labels.size()[0]\n",
    "    \n",
    "    print(\"Testing set Error: %0.4f\" % error)\n",
    "    \n",
    "model_path = \"./torch_model_2_18_19_lr=\" + str(learning_rate) + \"_dict.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Evaluate previous models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alliot/anaconda3/lib/python3.6/site-packages/torch/serialization.py:400: UserWarning: Couldn't retrieve source code for container of type CLANet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "storage has wrong size: expected -8422397943574246465 got 850",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a314ca55584b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# model = CLANet(input_size, hidden_size, output_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model.load_state_dict(torch.load(\"torch_model_2_18_19_lr=0.01_dict.pt\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"best_model_on_test_set.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# cast model parameters to double\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: storage has wrong size: expected -8422397943574246465 got 850"
     ]
    }
   ],
   "source": [
    "model = CLANet(input_size, hidden_size, output_size)\n",
    "model.load_state_dict(torch.load(\"torch_model_2_18_19_lr=0.01_dict.pt\"))\n",
    "model.double()     # cast model parameters to double\n",
    "model.eval()\n",
    "\n",
    "for i, (samples, labels) in enumerate(test_loader):\n",
    "    samples = Variable(samples)\n",
    "    labels = Variable(labels)\n",
    "    predictions = model(samples)\n",
    "    predictions = torch.flatten(predictions)\n",
    "    labels = labels.type(torch.DoubleTensor)\n",
    "\n",
    "    for j in range(0, predictions.size()[0]):\n",
    "        if predictions[j] < 0.5:\n",
    "            predictions[j] = 0\n",
    "        else:\n",
    "            predictions[j] = 1\n",
    "    \n",
    "    error = 1 - torch.sum(predictions == labels).item() / labels.size()[0]\n",
    "    \n",
    "    print(\"Testing set Error: %0.4f\" % error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
