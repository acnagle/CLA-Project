{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network for CLA Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "import numpy as np\n",
    "import errno\n",
    "import os\n",
    "import sys\n",
    "import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)  # prints a full matrix rather than an abbreviated matrix\n",
    "\n",
    "# read in data\n",
    "\n",
    "# define data and destination paths\n",
    "dest_path = \"/Users/Alliot/Documents/CLA-Project/Data/all-data-no-na/neural-network/\"\n",
    "data_path = \"/Users/Alliot/Documents/CLA-Project/Data/data-sets/\"\n",
    "\n",
    "# if dest_path does not exist, create it\n",
    "if not os.path.exists(dest_path):\n",
    "    try:\n",
    "        os.makedirs(dest_path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "# load data sets\n",
    "data_set = \"data_2017_summer\"\n",
    "X = np.load(data_path + data_set + \".npy\")\n",
    "y = np.load(data_path + data_set + \"_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulate data set. labels are converted to -1, +1 for binary classification; samples are removed uniformly \n",
    "# from the data set so that the disproportionately large number of negative samples (no algae) does \n",
    "# not bias the model.\n",
    "\n",
    "num_alg = 0  # count the number of algae instances\n",
    "num_no_alg = 0  # count the number of no algae instances\n",
    "\n",
    "# Convert labels to binary: -1 for no algae and 1 for algae\n",
    "for i in range(0, len(y)):\n",
    "    if y[i] == 0:\n",
    "        y[i] = -1\n",
    "        num_no_alg += 1\n",
    "    if y[i] == 1 or y[i] == 2:\n",
    "        y[i] = 1\n",
    "        num_alg += 1\n",
    "        \n",
    "        \n",
    "# shrink the data set by randomly removing occurences of no algae until the number of no algae samples equals the\n",
    "# number of algae samples minus the sample_bias\n",
    "# idx = 0  # index for the data set\n",
    "# sample_bias = 14  # adjust the difference in the number of the two types of samples (no_alg and alg)\n",
    "# while num_no_alg != (num_alg - sample_bias):\n",
    "#     # circle through the data set until the difference of num_no_alg and num_alg equals\n",
    "#     # the value specified by sample_bias\n",
    "#     if idx == (len(y) - 1):\n",
    "#         idx = 0\n",
    "\n",
    "#     if y[idx] == -1:\n",
    "#         if np.random.rand() >= 0.5:  # remove this sample with some probability\n",
    "#             y = np.delete(y, obj=idx)\n",
    "#             X = np.delete(X, obj=idx, axis=Constants.ROWS)\n",
    "#             num_no_alg -= 1\n",
    "#         else:\n",
    "#             idx += 1\n",
    "#     else:\n",
    "#         idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process and split data set\n",
    "X = preprocessing.scale(X, axis=1)  # standardize data: remove the mean and variance in each sample\n",
    "\n",
    "num_splits = 2\n",
    "test_size = 0.2\n",
    "sss = model_selection.StratifiedShuffleSplit(n_splits=num_splits, test_size=test_size)\n",
    "\n",
    "idx, _ = sss.split(X, y);\n",
    "train_idx = idx[0]\n",
    "test_idx = idx[1]\n",
    "X_train, X_test = X[train_idx], X[test_idx]\n",
    "y_train, y_test = y[train_idx], y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1066/1066 [==============================] - 1s 655us/step - loss: -8.6279 - acc: 0.0028\n",
      "Epoch 2/10\n",
      "1066/1066 [==============================] - 0s 85us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1066/1066 [==============================] - 0s 84us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1066/1066 [==============================] - 0s 83us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1066/1066 [==============================] - 0s 103us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1066/1066 [==============================] - 0s 104us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1066/1066 [==============================] - 0s 97us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1066/1066 [==============================] - 0s 91us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1066/1066 [==============================] - 0s 88us/step - loss: -9.0116 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1066/1066 [==============================] - 0s 87us/step - loss: -9.0116 - acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.],\n",
       "       [-0.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural network model\n",
    "\n",
    "num_features = X.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(num_features * 2, input_shape=(num_features,), activation=tf.nn.relu, use_bias=True))\n",
    "model.add(Dense(1, input_shape=(num_features * 2,), activation=tf.nn.relu, use_bias=True))\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"sgd\",\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
